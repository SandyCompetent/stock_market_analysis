{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Advanced Stock Price Forecasting with LSTM\n",
    "\n",
    "This notebook provides a comprehensive approach to stock price forecasting using Long Short-Term Memory (LSTM) neural networks. Unlike simple demonstrations, this implementation includes:\n",
    "\n",
    "- **Parameterized inputs** for any stock ticker and date range\n",
    "- **Feature engineering** with technical indicators (SMA, RSI)\n",
    "- **Baseline comparison** to evaluate model effectiveness\n",
    "- **Critical performance analysis** including directional accuracy\n",
    "- **Practical insights** and limitations discussion\n",
    "\n",
    "## Parameters\n",
    "Modify these parameters to analyze different stocks and time periods:\n"
   ],
   "id": "3a5a318cb229f3a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T00:06:44.065906Z",
     "start_time": "2025-07-22T00:06:44.063201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Stock Analysis Parameters\n",
    "STOCK_TICKER = 'MRK'  # Change this to any stock ticker (e.g., 'MSFT', 'GOOGL', 'TSLA')\n",
    "START_DATE = '2009-01-01'  # Start date for historical data\n",
    "END_DATE = '2014-12-31'    # End date for historical data\n",
    "\n",
    "# Model Parameters\n",
    "SEQUENCE_LENGTH = 30  # Number of days to look back for prediction\n",
    "TEST_SIZE = 0.2      # Proportion of data for testing\n",
    "EPOCHS = 50          # Number of training epochs\n",
    "BATCH_SIZE = 32      # Batch size for training\n"
   ],
   "id": "929461c802bda67c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Import Required Libraries\n",
   "id": "3678d0024d9bb02a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T00:06:44.377379Z",
     "start_time": "2025-07-22T00:06:44.375383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install yfinance\n",
    "# !pip install scikit-learn\n",
    "# !pip install tensorflow\n",
    "# !pip install pandas_ta\n",
    "# !pip install scipy-stubs\n",
    "# !pip install pandas-stubs"
   ],
   "id": "c2e66a40f32a01cc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T00:06:45.831518Z",
     "start_time": "2025-07-22T00:06:44.598247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "import warnings\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "# Set style and suppress warnings\n",
    "plt.style.use('seaborn-v0_8')\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Analysis target: {STOCK_TICKER} from {START_DATE} to {END_DATE}\")\n"
   ],
   "id": "73b86b7d1adf76d5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 00:06:44.935544: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-22 00:06:44.945276: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753142804.956893   21186 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753142804.960149   21186 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753142804.968554   21186 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753142804.968566   21186 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753142804.968568   21186 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753142804.968569   21186 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-22 00:06:44.971893: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "Analysis target: MRK from 2009-01-01 to 2014-12-31\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T00:06:46.181370Z",
     "start_time": "2025-07-22T00:06:46.104505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "id": "227c3c481ac052f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T00:06:46.392727Z",
     "start_time": "2025-07-22T00:06:46.390130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Enable GPU memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n"
   ],
   "id": "b7162314f075e060",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T00:06:46.644248Z",
     "start_time": "2025-07-22T00:06:46.642186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n"
   ],
   "id": "ba764e721f13bd07",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T00:06:46.897571Z",
     "start_time": "2025-07-22T00:06:46.894844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_news_dataframe(df: pd.DataFrame, file_path: str = \"stock_data.csv\") -> bool:\n",
    "    \"\"\"\n",
    "    Saves the news DataFrame to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to save.\n",
    "        file_path (str): The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the save was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"News DataFrame saved to {file_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Failed to save news DataFrame: {e}\")\n",
    "        return False\n"
   ],
   "id": "637d1d7701e8615",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Data Retrieval & Preprocessing\n",
    "\n",
    "We use yfinance to automatically handle historical price adjustments for stock splits and dividends, ensuring our data reflects true historical performance.\n"
   ],
   "id": "98e8c93e82d6538"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T00:06:47.415358Z",
     "start_time": "2025-07-22T00:06:47.053355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_name = \"MRK_full_sorted_data.csv\"\n",
    "\n",
    "def fetch_static_stock_data():\n",
    "    \"\"\"\n",
    "    Fetch stock data using yfinance with automatic adjustment for splits and dividends\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the data from the CSV file\n",
    "        # index_col=0: Sets the first column (our timestamps) as the DataFrame index.\n",
    "        # parse_dates=True: Converts the index column into datetime objects for time series analysis.\n",
    "        df = pd.read_csv(file_name, index_col=0, parse_dates=True)\n",
    "\n",
    "        print(f\"✅ Data loaded successfully from '{file_name}'\")\n",
    "\n",
    "        # Display the first few rows to confirm it's loaded correctly\n",
    "        print(\"\\n--- First 5 Rows ---\")\n",
    "        print(df.head())\n",
    "\n",
    "        # You can also check the data types to ensure the index is a datetime\n",
    "        print(\"\\n--- Data Info ---\")\n",
    "        df.info()\n",
    "\n",
    "        return df\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ Error: The file '{file_name}' was not found.\")\n",
    "        print(\"Please make sure the CSV file is in the same folder as your script.\")\n",
    "\n",
    "def fetch_stock_data(ticker, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch stock data using yfinance with automatic adjustment for splits and dividends\n",
    "    \"\"\"\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        data = stock.history(start=start_date, end=end_date, interval='90m')\n",
    "        # data = stock.h\n",
    "        # istory(period='max', interval='1d')\n",
    "\n",
    "        if data.empty:\n",
    "            raise ValueError(f\"No data found for ticker {ticker}\")\n",
    "\n",
    "        print(f\"Successfully fetched {len(data)} days of data for {ticker}\")\n",
    "        print(f\"Date range: {data.index[0].strftime('%Y-%m-%d')} to {data.index[-1].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Fetch the stock data\n",
    "# stock_data = fetch_stock_data(STOCK_TICKER, START_DATE, END_DATE)\n",
    "stock_data = fetch_static_stock_data()\n",
    "print(type(stock_data))\n",
    "\n",
    "# save_news_dataframe(df=stock_data, file_path=\"stock_data_nvda.csv\")\n",
    "\n",
    "if stock_data is not None:\n",
    "    print(\"\\nStock data overview:\")\n",
    "    print(stock_data.head())\n",
    "    print(f\"\\nData shape: {stock_data.shape}\")\n",
    "    print(f\"Missing values: {stock_data.isnull().sum().sum()}\")\n"
   ],
   "id": "3371502fedc4d1c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded successfully from 'MRK_full_sorted_data.csv'\n",
      "\n",
      "--- First 5 Rows ---\n",
      "                        High      Low    Close  Volume\n",
      "Date                                                  \n",
      "2009-01-02 08:21:00  16.2320  16.2320  16.2320     104\n",
      "2009-01-02 08:36:00  16.2374  16.2320  16.2320     209\n",
      "2009-01-02 08:38:00  16.2374  16.2320  16.2320     209\n",
      "2009-01-02 08:39:00  16.2320  16.2320  16.2320     104\n",
      "2009-01-02 08:46:00  16.3721  16.3721  16.3721    1347\n",
      "\n",
      "--- Data Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 621481 entries, 2009-01-02 08:21:00 to 2014-12-31 19:47:00\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   High    621481 non-null  float64\n",
      " 1   Low     621481 non-null  float64\n",
      " 2   Close   621481 non-null  float64\n",
      " 3   Volume  621481 non-null  int64  \n",
      "dtypes: float64(3), int64(1)\n",
      "memory usage: 23.7 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "Stock data overview:\n",
      "                        High      Low    Close  Volume\n",
      "Date                                                  \n",
      "2009-01-02 08:21:00  16.2320  16.2320  16.2320     104\n",
      "2009-01-02 08:36:00  16.2374  16.2320  16.2320     209\n",
      "2009-01-02 08:38:00  16.2374  16.2320  16.2320     209\n",
      "2009-01-02 08:39:00  16.2320  16.2320  16.2320     104\n",
      "2009-01-02 08:46:00  16.3721  16.3721  16.3721    1347\n",
      "\n",
      "Data shape: (621481, 4)\n",
      "Missing values: 0\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Feature Engineering with Technical Indicators\n",
    "\n",
    "Instead of using only closing prices, we'll engineer additional features that provide more context to our model:\n",
    "\n",
    "- **7-day Simple Moving Average (SMA)**: Smooths out price fluctuations\n",
    "- **Relative Strength Index (RSI)**: Measures momentum and identifies overbought/oversold conditions\n"
   ],
   "id": "845bf0cbb2f98329"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T00:06:47.739012Z",
     "start_time": "2025-07-22T00:06:47.643618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_technical_indicators(data):\n",
    "    \"\"\"\n",
    "    Calculate technical indicators for enhanced feature set\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "\n",
    "    # 7-day Simple Moving Average\n",
    "    df['SMA_7'] = df['Close'].rolling(window=7).mean()\n",
    "\n",
    "    # Relative Strength Index (RSI)\n",
    "    def calculate_rsi(prices, window=14):\n",
    "        delta = prices.diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "        rs = gain / loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        return rsi\n",
    "\n",
    "    df['RSI'] = calculate_rsi(df['Close'])\n",
    "\n",
    "    # Price change percentage\n",
    "    df['Price_Change_Pct'] = df['Close'].pct_change()\n",
    "\n",
    "    # Volume moving average\n",
    "    df['Volume_MA'] = df['Volume'].rolling(window=7).mean()\n",
    "\n",
    "    # High-Low spread\n",
    "    df['HL_Spread'] = (df['High'] - df['Low']) / df['Close']\n",
    "\n",
    "    # # Bollinger Bands\n",
    "    # df.ta.bbands(close='Close', length=20, append=True)\n",
    "    #\n",
    "    # # Moving Average Convergence Divergence (MACD)\n",
    "    # df.ta.macd(close='Close', append=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Calculate technical indicators\n",
    "enhanced_data = calculate_technical_indicators(stock_data)\n",
    "\n",
    "# Remove rows with NaN values (due to rolling calculations)\n",
    "enhanced_data = enhanced_data.dropna()\n",
    "\n",
    "print(f\"Enhanced dataset shape: {enhanced_data.shape}\")\n",
    "print(\"\\nNew features added:\")\n",
    "print(enhanced_data[['Close', 'SMA_7', 'RSI', 'Price_Change_Pct', 'HL_Spread']].head(10))\n"
   ],
   "id": "2d945c65c1724c49",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced dataset shape: (621462, 9)\n",
      "\n",
      "New features added:\n",
      "                       Close      SMA_7        RSI  Price_Change_Pct  \\\n",
      "Date                                                                   \n",
      "2009-01-02 09:24:00  16.3775  16.301300  72.884555          0.005624   \n",
      "2009-01-02 09:26:00  16.3775  16.313614  72.884555          0.000000   \n",
      "2009-01-02 09:30:00  16.4927  16.342386  80.096975          0.007034   \n",
      "2009-01-02 09:31:00  16.4959  16.371614  80.242952          0.000194   \n",
      "2009-01-02 09:32:00  16.5336  16.407000  81.814346          0.002285   \n",
      "2009-01-02 09:33:00  16.5606  16.446243  76.115267          0.001633   \n",
      "2009-01-02 09:34:00  16.5821  16.488557  85.929794          0.001298   \n",
      "2009-01-02 09:35:00  16.5888  16.518743  98.248459          0.000404   \n",
      "2009-01-02 09:36:00  16.5363  16.541429  83.952328         -0.003165   \n",
      "2009-01-02 09:37:00  16.5444  16.548814  84.304690          0.000490   \n",
      "\n",
      "                     HL_Spread  \n",
      "Date                            \n",
      "2009-01-02 09:24:00   0.000000  \n",
      "2009-01-02 09:26:00   0.000000  \n",
      "2009-01-02 09:30:00   0.009471  \n",
      "2009-01-02 09:31:00   0.001958  \n",
      "2009-01-02 09:32:00   0.004560  \n",
      "2009-01-02 09:33:00   0.005199  \n",
      "2009-01-02 09:34:00   0.001948  \n",
      "2009-01-02 09:35:00   0.002918  \n",
      "2009-01-02 09:36:00   0.004269  \n",
      "2009-01-02 09:37:00   0.002932  \n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Data Visualization\n",
   "id": "4b02e0794f22fe0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T00:12:54.163279Z",
     "start_time": "2025-07-22T00:06:47.857683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle(f'{STOCK_TICKER} Stock Analysis with Technical Indicators', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Price and SMA\n",
    "axes[0, 0].plot(enhanced_data.index, enhanced_data['Close'], label='Close Price', alpha=0.7)\n",
    "axes[0, 0].plot(enhanced_data.index, enhanced_data['SMA_7'], label='7-day SMA', color='red')\n",
    "axes[0, 0].set_title('Stock Price with 7-day SMA')\n",
    "axes[0, 0].set_ylabel('Price ($)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# RSI\n",
    "axes[0, 1].plot(enhanced_data.index, enhanced_data['RSI'], color='purple')\n",
    "axes[0, 1].axhline(y=70, color='r', linestyle='--', alpha=0.7, label='Overbought (70)')\n",
    "axes[0, 1].axhline(y=30, color='g', linestyle='--', alpha=0.7, label='Oversold (30)')\n",
    "axes[0, 1].set_title('Relative Strength Index (RSI)')\n",
    "axes[0, 1].set_ylabel('RSI')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Volume\n",
    "axes[1, 0].bar(enhanced_data.index, enhanced_data['Volume'], alpha=0.6, color='orange')\n",
    "axes[1, 0].plot(enhanced_data.index, enhanced_data['Volume_MA'], color='red', label='Volume MA')\n",
    "axes[1, 0].set_title('Trading Volume')\n",
    "axes[1, 0].set_ylabel('Volume')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Price change distribution\n",
    "axes[1, 1].hist(enhanced_data['Price_Change_Pct'].dropna(), bins=50, alpha=0.7, color='green')\n",
    "axes[1, 1].set_title('Daily Price Change Distribution')\n",
    "axes[1, 1].set_xlabel('Price Change (%)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display correlation matrix\n",
    "features_for_correlation = ['Close', 'SMA_7', 'RSI', 'Volume', 'HL_Spread']\n",
    "# features_for_correlation = ['Close', 'SMA_7', 'RSI', 'Volume', 'HL_Spread', 'BBL_20_2.0','MACD_12_26_9']\n",
    "correlation_matrix = enhanced_data[features_for_correlation].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.2f')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "686b21c6f29a884b",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 38\u001B[0m\n\u001B[1;32m     35\u001B[0m axes[\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mgrid(\u001B[38;5;28;01mTrue\u001B[39;00m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.3\u001B[39m)\n\u001B[1;32m     37\u001B[0m plt\u001B[38;5;241m.\u001B[39mtight_layout()\n\u001B[0;32m---> 38\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m# Display correlation matrix\u001B[39;00m\n\u001B[1;32m     41\u001B[0m features_for_correlation \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mClose\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSMA_7\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRSI\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVolume\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHL_Spread\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py:614\u001B[0m, in \u001B[0;36mshow\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    570\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    571\u001B[0m \u001B[38;5;124;03mDisplay all open figures.\u001B[39;00m\n\u001B[1;32m    572\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    611\u001B[0m \u001B[38;5;124;03mexplicitly there.\u001B[39;00m\n\u001B[1;32m    612\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    613\u001B[0m _warn_if_gui_out_of_main_thread()\n\u001B[0;32m--> 614\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_get_backend_mod\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/stock_market_analysis/lib/python3.10/site-packages/matplotlib_inline/backend_inline.py:90\u001B[0m, in \u001B[0;36mshow\u001B[0;34m(close, block)\u001B[0m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     89\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m figure_manager \u001B[38;5;129;01min\u001B[39;00m Gcf\u001B[38;5;241m.\u001B[39mget_all_fig_managers():\n\u001B[0;32m---> 90\u001B[0m         \u001B[43mdisplay\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     91\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfigure_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcanvas\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfigure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_fetch_figure_metadata\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfigure_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcanvas\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfigure\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     95\u001B[0m     show\u001B[38;5;241m.\u001B[39m_to_draw \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/.virtualenvs/stock_market_analysis/lib/python3.10/site-packages/IPython/core/display_functions.py:298\u001B[0m, in \u001B[0;36mdisplay\u001B[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001B[0m\n\u001B[1;32m    296\u001B[0m     publish_display_data(data\u001B[38;5;241m=\u001B[39mobj, metadata\u001B[38;5;241m=\u001B[39mmetadata, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    297\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 298\u001B[0m     format_dict, md_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexclude\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    299\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m format_dict:\n\u001B[1;32m    300\u001B[0m         \u001B[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001B[39;00m\n\u001B[1;32m    301\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/stock_market_analysis/lib/python3.10/site-packages/IPython/core/formatters.py:238\u001B[0m, in \u001B[0;36mDisplayFormatter.format\u001B[0;34m(self, obj, include, exclude)\u001B[0m\n\u001B[1;32m    236\u001B[0m md \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    237\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 238\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mformatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m    240\u001B[0m     \u001B[38;5;66;03m# FIXME: log the exception\u001B[39;00m\n\u001B[1;32m    241\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/stock_market_analysis/lib/python3.10/site-packages/decorator.py:235\u001B[0m, in \u001B[0;36mdecorate.<locals>.fun\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kwsyntax:\n\u001B[1;32m    234\u001B[0m     args, kw \u001B[38;5;241m=\u001B[39m fix(args, kw, sig)\n\u001B[0;32m--> 235\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcaller\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mextras\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/stock_market_analysis/lib/python3.10/site-packages/IPython/core/formatters.py:282\u001B[0m, in \u001B[0;36mcatch_format_error\u001B[0;34m(method, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001B[39;00m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 282\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m:\n\u001B[1;32m    284\u001B[0m     \u001B[38;5;66;03m# don't warn on NotImplementedErrors\u001B[39;00m\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_return(\u001B[38;5;28;01mNone\u001B[39;00m, args[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[0;32m~/.virtualenvs/stock_market_analysis/lib/python3.10/site-packages/IPython/core/formatters.py:402\u001B[0m, in \u001B[0;36mBaseFormatter.__call__\u001B[0;34m(self, obj)\u001B[0m\n\u001B[1;32m    400\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    401\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 402\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mprinter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    403\u001B[0m \u001B[38;5;66;03m# Finally look for special method names\u001B[39;00m\n\u001B[1;32m    404\u001B[0m method \u001B[38;5;241m=\u001B[39m get_real_method(obj, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_method)\n",
      "File \u001B[0;32m~/.virtualenvs/stock_market_analysis/lib/python3.10/site-packages/IPython/core/pylabtools.py:170\u001B[0m, in \u001B[0;36mprint_figure\u001B[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001B[0m\n\u001B[1;32m    167\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend_bases\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FigureCanvasBase\n\u001B[1;32m    168\u001B[0m     FigureCanvasBase(fig)\n\u001B[0;32m--> 170\u001B[0m \u001B[43mfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcanvas\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprint_figure\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbytes_io\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    171\u001B[0m data \u001B[38;5;241m=\u001B[39m bytes_io\u001B[38;5;241m.\u001B[39mgetvalue()\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fmt \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msvg\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py:2184\u001B[0m, in \u001B[0;36mFigureCanvasBase.print_figure\u001B[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001B[0m\n\u001B[1;32m   2180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   2181\u001B[0m     \u001B[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001B[39;00m\n\u001B[1;32m   2182\u001B[0m     \u001B[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001B[39;00m\n\u001B[1;32m   2183\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m cbook\u001B[38;5;241m.\u001B[39m_setattr_cm(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfigure, dpi\u001B[38;5;241m=\u001B[39mdpi):\n\u001B[0;32m-> 2184\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43mprint_method\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2185\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2186\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfacecolor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfacecolor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2187\u001B[0m \u001B[43m            \u001B[49m\u001B[43medgecolor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medgecolor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2188\u001B[0m \u001B[43m            \u001B[49m\u001B[43morientation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morientation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2189\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbbox_inches_restore\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_bbox_inches_restore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2190\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2191\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   2192\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m bbox_inches \u001B[38;5;129;01mand\u001B[39;00m restore_bbox:\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py:2040\u001B[0m, in \u001B[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   2036\u001B[0m     optional_kws \u001B[38;5;241m=\u001B[39m {  \u001B[38;5;66;03m# Passed by print_figure for other renderers.\u001B[39;00m\n\u001B[1;32m   2037\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdpi\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfacecolor\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124medgecolor\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124morientation\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   2038\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbbox_inches_restore\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m   2039\u001B[0m     skip \u001B[38;5;241m=\u001B[39m optional_kws \u001B[38;5;241m-\u001B[39m {\u001B[38;5;241m*\u001B[39minspect\u001B[38;5;241m.\u001B[39msignature(meth)\u001B[38;5;241m.\u001B[39mparameters}\n\u001B[0;32m-> 2040\u001B[0m     print_method \u001B[38;5;241m=\u001B[39m functools\u001B[38;5;241m.\u001B[39mwraps(meth)(\u001B[38;5;28;01mlambda\u001B[39;00m \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: \u001B[43mmeth\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2041\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m{\u001B[49m\u001B[43mk\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mskip\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   2042\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# Let third-parties do as they see fit.\u001B[39;00m\n\u001B[1;32m   2043\u001B[0m     print_method \u001B[38;5;241m=\u001B[39m meth\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py:481\u001B[0m, in \u001B[0;36mFigureCanvasAgg.print_png\u001B[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001B[0m\n\u001B[1;32m    434\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mprint_png\u001B[39m(\u001B[38;5;28mself\u001B[39m, filename_or_obj, \u001B[38;5;241m*\u001B[39m, metadata\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, pil_kwargs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    435\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    436\u001B[0m \u001B[38;5;124;03m    Write the figure to a PNG file.\u001B[39;00m\n\u001B[1;32m    437\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    479\u001B[0m \u001B[38;5;124;03m        *metadata*, including the default 'Software' key.\u001B[39;00m\n\u001B[1;32m    480\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 481\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_print_pil\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename_or_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpng\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpil_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py:429\u001B[0m, in \u001B[0;36mFigureCanvasAgg._print_pil\u001B[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001B[0m\n\u001B[1;32m    424\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_print_pil\u001B[39m(\u001B[38;5;28mself\u001B[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    425\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    426\u001B[0m \u001B[38;5;124;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001B[39;00m\n\u001B[1;32m    427\u001B[0m \u001B[38;5;124;03m    *pil_kwargs* and *metadata* are forwarded).\u001B[39;00m\n\u001B[1;32m    428\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 429\u001B[0m     \u001B[43mFigureCanvasAgg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    430\u001B[0m     mpl\u001B[38;5;241m.\u001B[39mimage\u001B[38;5;241m.\u001B[39mimsave(\n\u001B[1;32m    431\u001B[0m         filename_or_obj, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuffer_rgba(), \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m=\u001B[39mfmt, origin\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mupper\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    432\u001B[0m         dpi\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfigure\u001B[38;5;241m.\u001B[39mdpi, metadata\u001B[38;5;241m=\u001B[39mmetadata, pil_kwargs\u001B[38;5;241m=\u001B[39mpil_kwargs)\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py:382\u001B[0m, in \u001B[0;36mFigureCanvasAgg.draw\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;66;03m# Acquire a lock on the shared font cache.\u001B[39;00m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtoolbar\u001B[38;5;241m.\u001B[39m_wait_cursor_for_draw_cm() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtoolbar\n\u001B[1;32m    381\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m nullcontext()):\n\u001B[0;32m--> 382\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfigure\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    383\u001B[0m     \u001B[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001B[39;00m\n\u001B[1;32m    384\u001B[0m     \u001B[38;5;66;03m# don't forget to call the superclass.\u001B[39;00m\n\u001B[1;32m    385\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mdraw()\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py:94\u001B[0m, in \u001B[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001B[0;34m(artist, renderer, *args, **kwargs)\u001B[0m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(draw)\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdraw_wrapper\u001B[39m(artist, renderer, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m---> 94\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43martist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     95\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m renderer\u001B[38;5;241m.\u001B[39m_rasterizing:\n\u001B[1;32m     96\u001B[0m         renderer\u001B[38;5;241m.\u001B[39mstop_rasterizing()\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py:71\u001B[0m, in \u001B[0;36mallow_rasterization.<locals>.draw_wrapper\u001B[0;34m(artist, renderer)\u001B[0m\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m         renderer\u001B[38;5;241m.\u001B[39mstart_filter()\n\u001B[0;32m---> 71\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43martist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     73\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/figure.py:3257\u001B[0m, in \u001B[0;36mFigure.draw\u001B[0;34m(self, renderer)\u001B[0m\n\u001B[1;32m   3254\u001B[0m             \u001B[38;5;66;03m# ValueError can occur when resizing a window.\u001B[39;00m\n\u001B[1;32m   3256\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpatch\u001B[38;5;241m.\u001B[39mdraw(renderer)\n\u001B[0;32m-> 3257\u001B[0m     \u001B[43mmimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_draw_list_compositing_images\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3258\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43martists\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msuppressComposite\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3260\u001B[0m     renderer\u001B[38;5;241m.\u001B[39mclose_group(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfigure\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   3261\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py:134\u001B[0m, in \u001B[0;36m_draw_list_compositing_images\u001B[0;34m(renderer, parent, artists, suppress_composite)\u001B[0m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m not_composite \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m has_images:\n\u001B[1;32m    133\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m artists:\n\u001B[0;32m--> 134\u001B[0m         \u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;66;03m# Composite any adjacent images together\u001B[39;00m\n\u001B[1;32m    137\u001B[0m     image_group \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py:71\u001B[0m, in \u001B[0;36mallow_rasterization.<locals>.draw_wrapper\u001B[0;34m(artist, renderer)\u001B[0m\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m         renderer\u001B[38;5;241m.\u001B[39mstart_filter()\n\u001B[0;32m---> 71\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43martist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     73\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py:3216\u001B[0m, in \u001B[0;36m_AxesBase.draw\u001B[0;34m(self, renderer)\u001B[0m\n\u001B[1;32m   3213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m artists_rasterized:\n\u001B[1;32m   3214\u001B[0m     _draw_rasterized(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_figure(root\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m), artists_rasterized, renderer)\n\u001B[0;32m-> 3216\u001B[0m \u001B[43mmimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_draw_list_compositing_images\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3217\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43martists\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_figure\u001B[49m\u001B[43m(\u001B[49m\u001B[43mroot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msuppressComposite\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3219\u001B[0m renderer\u001B[38;5;241m.\u001B[39mclose_group(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maxes\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   3220\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstale \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py:134\u001B[0m, in \u001B[0;36m_draw_list_compositing_images\u001B[0;34m(renderer, parent, artists, suppress_composite)\u001B[0m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m not_composite \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m has_images:\n\u001B[1;32m    133\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m artists:\n\u001B[0;32m--> 134\u001B[0m         \u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;66;03m# Composite any adjacent images together\u001B[39;00m\n\u001B[1;32m    137\u001B[0m     image_group \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py:71\u001B[0m, in \u001B[0;36mallow_rasterization.<locals>.draw_wrapper\u001B[0;34m(artist, renderer)\u001B[0m\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m         renderer\u001B[38;5;241m.\u001B[39mstart_filter()\n\u001B[0;32m---> 71\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43martist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     73\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/legend.py:763\u001B[0m, in \u001B[0;36mLegend.draw\u001B[0;34m(self, renderer)\u001B[0m\n\u001B[1;32m    760\u001B[0m     Shadow(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlegendPatch, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shadow_props)\u001B[38;5;241m.\u001B[39mdraw(renderer)\n\u001B[1;32m    762\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlegendPatch\u001B[38;5;241m.\u001B[39mdraw(renderer)\n\u001B[0;32m--> 763\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_legend_box\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    765\u001B[0m renderer\u001B[38;5;241m.\u001B[39mclose_group(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlegend\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    766\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstale \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py:38\u001B[0m, in \u001B[0;36m_prevent_rasterization.<locals>.draw_wrapper\u001B[0;34m(artist, renderer, *args, **kwargs)\u001B[0m\n\u001B[1;32m     35\u001B[0m     renderer\u001B[38;5;241m.\u001B[39mstop_rasterizing()\n\u001B[1;32m     36\u001B[0m     renderer\u001B[38;5;241m.\u001B[39m_rasterizing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m---> 38\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43martist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/offsetbox.py:380\u001B[0m, in \u001B[0;36mOffsetBox.draw\u001B[0;34m(self, renderer)\u001B[0m\n\u001B[1;32m    375\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    376\u001B[0m \u001B[38;5;124;03mUpdate the location of children if necessary and draw them\u001B[39;00m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;124;03mto the given *renderer*.\u001B[39;00m\n\u001B[1;32m    378\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    379\u001B[0m bbox, offsets \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_bbox_and_child_offsets(renderer)\n\u001B[0;32m--> 380\u001B[0m px, py \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_offset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbbox\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    381\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m c, (ox, oy) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_visible_children(), offsets):\n\u001B[1;32m    382\u001B[0m     c\u001B[38;5;241m.\u001B[39mset_offset((px \u001B[38;5;241m+\u001B[39m ox, py \u001B[38;5;241m+\u001B[39m oy))\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/offsetbox.py:60\u001B[0m, in \u001B[0;36m_compat_get_offset.<locals>.get_offset\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     56\u001B[0m params \u001B[38;5;241m=\u001B[39m _api\u001B[38;5;241m.\u001B[39mselect_matching_signature(sigs, \u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     57\u001B[0m bbox \u001B[38;5;241m=\u001B[39m (params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbbox\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbbox\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m params \u001B[38;5;28;01melse\u001B[39;00m\n\u001B[1;32m     58\u001B[0m         Bbox\u001B[38;5;241m.\u001B[39mfrom_bounds(\u001B[38;5;241m-\u001B[39mparams[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxdescent\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;241m-\u001B[39mparams[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mydescent\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m     59\u001B[0m                          params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwidth\u001B[39m\u001B[38;5;124m\"\u001B[39m], params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheight\u001B[39m\u001B[38;5;124m\"\u001B[39m]))\n\u001B[0;32m---> 60\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmeth\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mself\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbbox\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrenderer\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/offsetbox.py:306\u001B[0m, in \u001B[0;36mOffsetBox.get_offset\u001B[0;34m(self, bbox, renderer)\u001B[0m\n\u001B[1;32m    291\u001B[0m \u001B[38;5;129m@_compat_get_offset\u001B[39m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mget_offset\u001B[39m(\u001B[38;5;28mself\u001B[39m, bbox, renderer):\n\u001B[1;32m    293\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    294\u001B[0m \u001B[38;5;124;03m    Return the offset as a tuple (x, y).\u001B[39;00m\n\u001B[1;32m    295\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    303\u001B[0m \u001B[38;5;124;03m    renderer : `.RendererBase` subclass\u001B[39;00m\n\u001B[1;32m    304\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m    305\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m--> 306\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_offset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbbox\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwidth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbbox\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43mbbox\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43mbbox\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43my0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    307\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_offset)\n\u001B[1;32m    308\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_offset)\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/legend.py:721\u001B[0m, in \u001B[0;36mLegend._findoffset\u001B[0;34m(self, width, height, xdescent, ydescent, renderer)\u001B[0m\n\u001B[1;32m    718\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Helper function to locate the legend.\"\"\"\u001B[39;00m\n\u001B[1;32m    720\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loc \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:  \u001B[38;5;66;03m# \"best\".\u001B[39;00m\n\u001B[0;32m--> 721\u001B[0m     x, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_find_best_position\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwidth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    722\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loc \u001B[38;5;129;01min\u001B[39;00m Legend\u001B[38;5;241m.\u001B[39mcodes\u001B[38;5;241m.\u001B[39mvalues():  \u001B[38;5;66;03m# Fixed location.\u001B[39;00m\n\u001B[1;32m    723\u001B[0m     bbox \u001B[38;5;241m=\u001B[39m Bbox\u001B[38;5;241m.\u001B[39mfrom_bounds(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, width, height)\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/legend.py:1153\u001B[0m, in \u001B[0;36mLegend._find_best_position\u001B[0;34m(self, width, height, renderer)\u001B[0m\n\u001B[1;32m   1149\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39misaxes  \u001B[38;5;66;03m# always holds, as this is only called internally\u001B[39;00m\n\u001B[1;32m   1151\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[0;32m-> 1153\u001B[0m bboxes, lines, offsets \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_auto_legend_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1155\u001B[0m bbox \u001B[38;5;241m=\u001B[39m Bbox\u001B[38;5;241m.\u001B[39mfrom_bounds(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, width, height)\n\u001B[1;32m   1157\u001B[0m candidates \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/legend.py:960\u001B[0m, in \u001B[0;36mLegend._auto_legend_data\u001B[0;34m(self, renderer)\u001B[0m\n\u001B[1;32m    956\u001B[0m     lines\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m    957\u001B[0m         artist\u001B[38;5;241m.\u001B[39mget_transform()\u001B[38;5;241m.\u001B[39mtransform_path(artist\u001B[38;5;241m.\u001B[39mget_path()))\n\u001B[1;32m    958\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(artist, Rectangle):\n\u001B[1;32m    959\u001B[0m     bboxes\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m--> 960\u001B[0m         \u001B[43martist\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_bbox\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformed\u001B[49m\u001B[43m(\u001B[49m\u001B[43martist\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_data_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    961\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(artist, Patch):\n\u001B[1;32m    962\u001B[0m     lines\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m    963\u001B[0m         artist\u001B[38;5;241m.\u001B[39mget_transform()\u001B[38;5;241m.\u001B[39mtransform_path(artist\u001B[38;5;241m.\u001B[39mget_path()))\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/transforms.py:465\u001B[0m, in \u001B[0;36mBboxBase.transformed\u001B[0;34m(self, transform)\u001B[0m\n\u001B[1;32m    461\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    462\u001B[0m \u001B[38;5;124;03mConstruct a `Bbox` by statically transforming this one by *transform*.\u001B[39;00m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    464\u001B[0m pts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_points()\n\u001B[0;32m--> 465\u001B[0m ll, ul, lr \u001B[38;5;241m=\u001B[39m \u001B[43mtransform\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    466\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43mpts\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mpts\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpts\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mpts\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpts\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Bbox([ll, [lr[\u001B[38;5;241m0\u001B[39m], ul[\u001B[38;5;241m1\u001B[39m]]])\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/transforms.py:1495\u001B[0m, in \u001B[0;36mTransform.transform\u001B[0;34m(self, values)\u001B[0m\n\u001B[1;32m   1492\u001B[0m values \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mreshape((\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_dims))\n\u001B[1;32m   1494\u001B[0m \u001B[38;5;66;03m# Transform the values\u001B[39;00m\n\u001B[0;32m-> 1495\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform_affine\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform_non_affine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# Convert the result back to the shape of the input values.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/transforms.py:2410\u001B[0m, in \u001B[0;36mCompositeGenericTransform.transform_affine\u001B[0;34m(self, values)\u001B[0m\n\u001B[1;32m   2408\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mtransform_affine\u001B[39m(\u001B[38;5;28mself\u001B[39m, values):\n\u001B[1;32m   2409\u001B[0m     \u001B[38;5;66;03m# docstring inherited\u001B[39;00m\n\u001B[0;32m-> 2410\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_affine\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtransform(values)\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/transforms.py:2436\u001B[0m, in \u001B[0;36mCompositeGenericTransform.get_affine\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2434\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_b\u001B[38;5;241m.\u001B[39mget_affine()\n\u001B[1;32m   2435\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2436\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Affine2D(np\u001B[38;5;241m.\u001B[39mdot(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_b\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_affine\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mget_matrix(),\n\u001B[1;32m   2437\u001B[0m                            \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_a\u001B[38;5;241m.\u001B[39mget_affine()\u001B[38;5;241m.\u001B[39mget_matrix()))\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/transforms.py:2436\u001B[0m, in \u001B[0;36mCompositeGenericTransform.get_affine\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2434\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_b\u001B[38;5;241m.\u001B[39mget_affine()\n\u001B[1;32m   2435\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2436\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mAffine2D\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_b\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_affine\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_matrix\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2437\u001B[0m \u001B[43m                           \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_a\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_affine\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_matrix\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/transforms.py:1896\u001B[0m, in \u001B[0;36mAffine2D.__init__\u001B[0;34m(self, matrix, **kwargs)\u001B[0m\n\u001B[1;32m   1886\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, matrix\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1887\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1888\u001B[0m \u001B[38;5;124;03m    Initialize an Affine transform from a 3x3 numpy float array::\u001B[39;00m\n\u001B[1;32m   1889\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1894\u001B[0m \u001B[38;5;124;03m    If *matrix* is None, initialize with the identity transform.\u001B[39;00m\n\u001B[1;32m   1895\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1896\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1897\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m matrix \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1898\u001B[0m         \u001B[38;5;66;03m# A bit faster than np.identity(3).\u001B[39;00m\n\u001B[1;32m   1899\u001B[0m         matrix \u001B[38;5;241m=\u001B[39m IdentityTransform\u001B[38;5;241m.\u001B[39m_mtx\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/transforms.py:1770\u001B[0m, in \u001B[0;36mAffineBase.__init__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1769\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m-> 1770\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1771\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inverted \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Data Scaling and Preparation\n",
    "\n",
    "**Why MinMaxScaler is crucial for LSTMs:**\n",
    "\n",
    "LSTM networks use activation functions like tanh and sigmoid that work optimally with inputs in specific ranges (typically 0-1 or -1 to 1). Without proper scaling:\n",
    "- **Gradient problems**: Large input values can cause vanishing or exploding gradients\n",
    "- **Slow convergence**: The network takes longer to learn patterns\n",
    "- **Poor performance**: Features with larger scales dominate the learning process\n",
    "\n",
    "MinMaxScaler transforms all features to the same scale (0-1), ensuring equal importance during training.\n"
   ],
   "id": "caf299c12a675bfb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def prepare_lstm_data(data, sequence_length, test_size):\n",
    "    \"\"\"\n",
    "    Prepare data for LSTM training with multiple features\n",
    "    \"\"\"\n",
    "    # Select features for the model\n",
    "    feature_columns = ['Close', 'SMA_7', 'RSI', 'Volume', 'HL_Spread']\n",
    "    # feature_columns = ['Close', 'SMA_7', 'RSI', 'Volume', 'HL_Spread', 'BBL_20_2.0','MACD_12_26_9']\n",
    "    features = data[feature_columns].values\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "    # Create sequences\n",
    "    X, y = [], []\n",
    "    for i in range(sequence_length, len(scaled_features)):\n",
    "        X.append(scaled_features[i-sequence_length:i])  # All features for sequence\n",
    "        y.append(scaled_features[i, 0])  # Only Close price as target\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "\n",
    "    # Split into train and test sets\n",
    "    split_index = int(len(X) * (1 - test_size))\n",
    "\n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, scaler, feature_columns\n",
    "\n",
    "# Prepare the data\n",
    "X_train, X_test, y_train, y_test, scaler, feature_names = prepare_lstm_data(\n",
    "    enhanced_data, SEQUENCE_LENGTH, TEST_SIZE\n",
    ")\n",
    "\n",
    "print(f\"Training data shape: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"Testing data shape: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "print(f\"Features used: {feature_names}\")\n",
    "print(f\"Sequence length: {SEQUENCE_LENGTH} days\")\n"
   ],
   "id": "73e65f9435a9fc78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Train-Test Split Discussion\n",
    "\n",
    "**Current Approach: 80-20 Split**\n",
    "We're using a standard 80-20 split where the most recent 20% of data serves as our test set.\n",
    "\n",
    "**Why Walk-Forward Validation is Often Better for Time Series:**\n",
    "\n",
    "1. **Temporal Integrity**: Walk-forward validation respects the time-ordered nature of financial data\n",
    "2. **Realistic Testing**: It simulates real-world trading where you only have past data to predict future prices\n",
    "3. **Robust Evaluation**: Multiple test periods provide better performance estimates\n",
    "4. **Overfitting Detection**: Helps identify if the model works consistently across different market conditions\n",
    "\n",
    "**Implementation Note**: For production systems, consider implementing walk-forward validation with multiple train-test cycles, retraining the model periodically as new data becomes available.\n"
   ],
   "id": "8e87fb07cb46fa88"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. LSTM Model Architecture\n",
   "id": "9f2a63df8a66f1aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def build_lstm_model(input_shape):\n",
    "    \"\"\"\n",
    "    Build a stacked LSTM model with dropout layers for regularization\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # First LSTM layer with return_sequences=True to stack layers\n",
    "        LSTM(units=100, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        # Second LSTM layer\n",
    "        LSTM(units=100, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        # Third LSTM layer (final layer doesn't return sequences)\n",
    "        LSTM(units=50),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        # Dense output layer\n",
    "        Dense(units=1, activation='linear')\n",
    "    ])\n",
    "\n",
    "    # Compile with Adam optimizer and MSE loss\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Build the model\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "model = build_lstm_model(input_shape)\n",
    "\n",
    "# Display model architecture\n",
    "print(\"LSTM Model Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# Calculate total parameters\n",
    "total_params = model.count_params()\n",
    "print(f\"\\nTotal trainable parameters: {total_params:,}\")\n"
   ],
   "id": "cceaa37e49c035f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8. Model Training with Callbacks\n",
   "id": "a9e5a194bc642379"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Define callbacks for better training\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=0.0001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"Starting training for {EPOCHS} epochs...\")\n",
    "print(f\"Training samples: {len(X_train)}, Validation samples: {int(len(X_train) * 0.2)}\")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")\n"
   ],
   "id": "1b2d510374414f4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 9. Training Performance Analysis\n",
   "id": "42155def3f183a7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "ax1.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
    "ax1.set_title('Model Loss During Training')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss (MSE)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# MAE plot\n",
    "ax2.plot(history.history['mae'], label='Training MAE', color='blue')\n",
    "ax2.plot(history.history['val_mae'], label='Validation MAE', color='red')\n",
    "ax2.set_title('Model MAE During Training')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Mean Absolute Error')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for overfitting\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "overfitting_ratio = final_val_loss / final_train_loss\n",
    "\n",
    "print(f\"Final Training Loss: {final_train_loss:.6f}\")\n",
    "print(f\"Final Validation Loss: {final_val_loss:.6f}\")\n",
    "print(f\"Overfitting Ratio (Val/Train): {overfitting_ratio:.2f}\")\n",
    "\n",
    "if overfitting_ratio > 1.2:\n",
    "    print(\"⚠️  Warning: Model may be overfitting (validation loss > 1.2x training loss)\")\n",
    "elif overfitting_ratio < 1.1:\n",
    "    print(\"✅ Good: Model shows minimal overfitting\")\n",
    "else:\n",
    "    print(\"✅ Acceptable: Model shows reasonable generalization\")\n"
   ],
   "id": "ec9b69a960529d9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 10. Model Predictions and Baseline Comparison\n",
   "id": "b2da87cf70ea38a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Make predictions\n",
    "train_predictions = model.predict(X_train, verbose=0)\n",
    "test_predictions = model.predict(X_test, verbose=0)\n",
    "\n",
    "# Create a scaler for inverse transformation (only for Close price)\n",
    "close_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "close_scaler.fit(enhanced_data[['Close']].values)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "train_predictions_scaled = close_scaler.inverse_transform(train_predictions)\n",
    "test_predictions_scaled = close_scaler.inverse_transform(test_predictions.reshape(-1, 1))\n",
    "y_train_scaled = close_scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "y_test_scaled = close_scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Create baseline predictions (naive forecast: tomorrow = today)\n",
    "# For test set, baseline is the previous day's actual price\n",
    "baseline_predictions = np.roll(y_test_scaled, 1)\n",
    "baseline_predictions[0] = y_test_scaled[0]  # Handle first prediction\n",
    "\n",
    "print(\"Predictions completed!\")\n",
    "print(f\"Train predictions shape: {train_predictions_scaled.shape}\")\n",
    "print(f\"Test predictions shape: {test_predictions_scaled.shape}\")\n",
    "print(f\"Baseline predictions shape: {baseline_predictions.shape}\")\n"
   ],
   "id": "13e1be90fd846d85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 11. Performance Metrics and Baseline Comparison\n",
   "id": "be7a103d10f06921"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_metrics(actual, predicted, model_name):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive performance metrics\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "\n",
    "    # Mean Absolute Percentage Error\n",
    "    mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "\n",
    "    # Directional Accuracy\n",
    "    actual_direction = np.diff(actual.flatten()) > 0\n",
    "    predicted_direction = np.diff(predicted.flatten()) > 0\n",
    "    directional_accuracy = np.mean(actual_direction == predicted_direction) * 100\n",
    "\n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape,\n",
    "        'Directional_Accuracy': directional_accuracy\n",
    "    }\n",
    "\n",
    "# Calculate metrics for both models\n",
    "lstm_metrics = calculate_metrics(y_test_scaled, test_predictions_scaled, 'LSTM')\n",
    "baseline_metrics = calculate_metrics(y_test_scaled, baseline_predictions, 'Naive Baseline')\n",
    "\n",
    "# Create comparison DataFrame\n",
    "metrics_df = pd.DataFrame([lstm_metrics, baseline_metrics])\n",
    "metrics_df = metrics_df.round(4)\n",
    "\n",
    "print(\"📊 PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "print(metrics_df.to_string(index=False))\n",
    "\n",
    "# Calculate improvement over baseline\n",
    "rmse_improvement = ((baseline_metrics['RMSE'] - lstm_metrics['RMSE']) / baseline_metrics['RMSE']) * 100\n",
    "directional_improvement = lstm_metrics['Directional_Accuracy'] - baseline_metrics['Directional_Accuracy']\n",
    "\n",
    "print(f\"\\n📈 MODEL EFFECTIVENESS\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"RMSE Improvement over Baseline: {rmse_improvement:.2f}%\")\n",
    "print(f\"Directional Accuracy Improvement: {directional_improvement:.2f} percentage points\")\n",
    "\n",
    "if rmse_improvement > 10:\n",
    "    print(\"✅ LSTM shows significant improvement over naive baseline\")\n",
    "elif rmse_improvement > 0:\n",
    "    print(\"✅ LSTM shows modest improvement over naive baseline\")\n",
    "else:\n",
    "    print(\"⚠️  LSTM does not outperform naive baseline - consider model refinement\")\n"
   ],
   "id": "e3c143ccffb11b96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 12. Comprehensive Visualization\n",
   "id": "7d5148a63b2a1842"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create comprehensive prediction visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "fig.suptitle(f'{STOCK_TICKER} Stock Price Prediction Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Full prediction comparison\n",
    "test_dates = enhanced_data.index[-len(y_test_scaled):]\n",
    "\n",
    "axes[0, 0].plot(test_dates, y_test_scaled, label='Actual Price', color='blue', linewidth=2)\n",
    "axes[0, 0].plot(test_dates, test_predictions_scaled, label='LSTM Prediction', color='red', linewidth=2, alpha=0.8)\n",
    "axes[0, 0].plot(test_dates, baseline_predictions, label='Naive Baseline', color='green', linewidth=1, linestyle='--')\n",
    "axes[0, 0].set_title('Stock Price Predictions vs Actual')\n",
    "axes[0, 0].set_ylabel('Price ($)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Prediction errors\n",
    "lstm_errors = y_test_scaled.flatten() - test_predictions_scaled.flatten()\n",
    "baseline_errors = y_test_scaled.flatten() - baseline_predictions.flatten()\n",
    "\n",
    "axes[0, 1].hist(lstm_errors, bins=30, alpha=0.7, label='LSTM Errors', color='red')\n",
    "axes[0, 1].hist(baseline_errors, bins=30, alpha=0.7, label='Baseline Errors', color='green')\n",
    "axes[0, 1].set_title('Prediction Error Distribution')\n",
    "axes[0, 1].set_xlabel('Prediction Error ($)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Scatter plot: Actual vs Predicted\n",
    "axes[1, 0].scatter(y_test_scaled, test_predictions_scaled, alpha=0.6, color='red', label='LSTM')\n",
    "axes[1, 0].scatter(y_test_scaled, baseline_predictions, alpha=0.6, color='green', label='Baseline')\n",
    "min_price = min(y_test_scaled.min(), test_predictions_scaled.min())\n",
    "max_price = max(y_test_scaled.max(), test_predictions_scaled.max())\n",
    "axes[1, 0].plot([min_price, max_price], [min_price, max_price], 'k--', alpha=0.8, label='Perfect Prediction')\n",
    "axes[1, 0].set_title('Actual vs Predicted Prices')\n",
    "axes[1, 0].set_xlabel('Actual Price ($)')\n",
    "axes[1, 0].set_ylabel('Predicted Price ($)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Directional accuracy over time\n",
    "window_size = 20\n",
    "lstm_directions = np.diff(test_predictions_scaled.flatten()) > 0\n",
    "actual_directions = np.diff(y_test_scaled.flatten()) > 0\n",
    "rolling_accuracy = []\n",
    "\n",
    "for i in range(window_size, len(lstm_directions)):\n",
    "    window_accuracy = np.mean(lstm_directions[i-window_size:i] == actual_directions[i-window_size:i]) * 100\n",
    "    rolling_accuracy.append(window_accuracy)\n",
    "\n",
    "rolling_dates = test_dates[window_size+1:]\n",
    "axes[1, 1].plot(rolling_dates, rolling_accuracy, color='purple', linewidth=2)\n",
    "axes[1, 1].axhline(y=50, color='red', linestyle='--', alpha=0.7, label='Random Chance')\n",
    "axes[1, 1].set_title(f'Rolling Directional Accuracy ({window_size}-day window)')\n",
    "axes[1, 1].set_ylabel('Accuracy (%)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(f'{STOCK_TICKER}_lstm_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"\\n📊 Analysis chart saved as '{STOCK_TICKER}_lstm_analysis.png'\")\n"
   ],
   "id": "54705f50b6d9caf1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 13. Critical Analysis & Insights\n",
    "\n",
    "This section provides a thorough evaluation of our LSTM model's performance and practical implications.\n"
   ],
   "id": "5949d9cfaf4b39f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Detailed performance analysis\n",
    "print(\"🔍 CRITICAL ANALYSIS OF LSTM PERFORMANCE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Statistical Significance\n",
    "from scipy import stats\n",
    "\n",
    "lstm_abs_errors = np.abs(lstm_errors)\n",
    "baseline_abs_errors = np.abs(baseline_errors)\n",
    "\n",
    "# Paired t-test to check if LSTM errors are significantly different\n",
    "t_stat, p_value = stats.ttest_rel(lstm_abs_errors, baseline_abs_errors)\n",
    "\n",
    "print(f\"\\n📊 STATISTICAL SIGNIFICANCE\")\n",
    "print(f\"Paired t-test p-value: {p_value:.6f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"✅ LSTM performance is statistically significantly different from baseline\")\n",
    "else:\n",
    "    print(\"⚠️  LSTM performance is not statistically significantly different from baseline\")\n",
    "\n",
    "# 2. Directional Accuracy Analysis\n",
    "print(f\"\\n🎯 DIRECTIONAL ACCURACY BREAKDOWN\")\n",
    "print(f\"LSTM Directional Accuracy: {lstm_metrics['Directional_Accuracy']:.2f}%\")\n",
    "print(f\"Baseline Directional Accuracy: {baseline_metrics['Directional_Accuracy']:.2f}%\")\n",
    "\n",
    "if lstm_metrics['Directional_Accuracy'] > 55:\n",
    "    print(\"✅ Strong directional prediction capability\")\n",
    "elif lstm_metrics['Directional_Accuracy'] > 50:\n",
    "    print(\"✅ Modest directional prediction capability\")\n",
    "else:\n",
    "    print(\"⚠️  Poor directional prediction - worse than random\")\n",
    "\n",
    "# 3. Volatility Analysis\n",
    "actual_volatility = np.std(y_test_scaled)\n",
    "predicted_volatility = np.std(test_predictions_scaled)\n",
    "volatility_ratio = predicted_volatility / actual_volatility\n",
    "\n",
    "print(f\"\\n📈 VOLATILITY ANALYSIS\")\n",
    "print(f\"Actual Price Volatility: ${actual_volatility:.2f}\")\n",
    "print(f\"Predicted Price Volatility: ${predicted_volatility:.2f}\")\n",
    "print(f\"Volatility Ratio (Pred/Actual): {volatility_ratio:.2f}\")\n",
    "\n",
    "if 0.8 <= volatility_ratio <= 1.2:\n",
    "    print(\"✅ Model captures volatility well\")\n",
    "elif volatility_ratio < 0.8:\n",
    "    print(\"⚠️  Model underestimates volatility (too conservative)\")\n",
    "else:\n",
    "    print(\"⚠️  Model overestimates volatility (too aggressive)\")\n",
    "\n",
    "# 4. Trend Following Analysis\n",
    "y_test_float32 = y_test_scaled.flatten().astype('float32')\n",
    "predictions_float32 = test_predictions_scaled.flatten().astype('float32')\n",
    "\n",
    "actual_trend = np.polyfit(range(len(y_test_float32)), y_test_float32, 1)[0]\n",
    "predicted_trend = np.polyfit(range(len(predictions_float32)), predictions_float32, 1)[0]\n",
    "\n",
    "print(f\"\\n📊 TREND ANALYSIS\")\n",
    "print(f\"Actual Trend ($/day): {actual_trend:.4f}\")\n",
    "print(f\"Predicted Trend ($/day): {predicted_trend:.4f}\")\n",
    "print(f\"Trend Capture Ratio: {predicted_trend/actual_trend:.2f}\" if actual_trend != 0 else \"Trend Capture: N/A (flat trend)\")\n",
    "\n",
    "# 5. Error Analysis by Market Conditions\n",
    "price_changes = np.diff(y_test_scaled.flatten())\n",
    "up_days = price_changes > 0\n",
    "down_days = price_changes < 0\n",
    "\n",
    "if len(price_changes) > 1:\n",
    "    up_day_errors = lstm_errors[1:][up_days]\n",
    "    down_day_errors = lstm_errors[1:][down_days]\n",
    "\n",
    "    print(f\"\\n📊 PERFORMANCE BY MARKET CONDITION\")\n",
    "    if len(up_day_errors) > 0:\n",
    "        print(f\"Average error on up days: ${np.mean(np.abs(up_day_errors)):.2f}\")\n",
    "    if len(down_day_errors) > 0:\n",
    "        print(f\"Average error on down days: ${np.mean(np.abs(down_day_errors)):.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n"
   ],
   "id": "e7796b3979d5f8b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 14. Model Limitations & Real-World Considerations\n",
    "\n",
    "### 🚨 **Critical Limitations**\n",
    "\n",
    "1. **Historical Bias**: The model is trained exclusively on past data and assumes historical patterns will continue\n",
    "\n",
    "2. **Black Swan Events**: Cannot predict unprecedented market events (crashes, pandemics, geopolitical crises)\n",
    "\n",
    "3. **Market Regime Changes**: May fail when market dynamics fundamentally shift\n",
    "\n",
    "4. **Feature Limitations**: Only uses price and volume data - ignores fundamental analysis, news sentiment, macroeconomic factors\n",
    "\n",
    "5. **Overfitting Risk**: Complex models may memorize noise rather than learn genuine patterns\n",
    "\n",
    "6. **Transaction Costs**: Real trading involves spreads, commissions, and slippage not accounted for in predictions\n",
    "\n",
    "7. **Market Impact**: Large trades based on model predictions could move prices, invalidating the predictions\n",
    "\n",
    "### ⚖️ **Regulatory and Ethical Considerations**\n",
    "\n",
    "- **Not Financial Advice**: This model is for educational purposes only\n",
    "- **Risk Management**: Never risk more than you can afford to lose\n",
    "- **Diversification**: Don't rely on a single model or asset\n",
    "- **Continuous Monitoring**: Model performance can degrade over time\n"
   ],
   "id": "fb8034cd244ecc01"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 15. Next Steps for Model Improvement\n",
    "\n",
    "### 🔧 **Immediate Improvements**\n",
    "\n",
    "1. **Hyperparameter Tuning**:\n",
    "   - Grid search for optimal LSTM units, dropout rates, learning rates\n",
    "   - Experiment with different sequence lengths\n",
    "   - Try different optimizers (RMSprop, AdaGrad)\n",
    "\n",
    "2. **Alternative Architectures**:\n",
    "   - **GRU (Gated Recurrent Unit)**: Often performs similarly to LSTM with fewer parameters\n",
    "   - **Bidirectional LSTM**: Processes sequences in both directions\n",
    "   - **Attention Mechanisms**: Focus on most relevant time steps\n",
    "   - **Transformer Models**: State-of-the-art for sequence modeling\n",
    "\n",
    "3. **Enhanced Features**:\n",
    "   - **More Technical Indicators**: MACD, Bollinger Bands, Stochastic Oscillator\n",
    "   - **Market Sentiment**: VIX (fear index), put/call ratios\n",
    "   - **Fundamental Data**: P/E ratios, earnings, revenue growth\n",
    "   - **Macroeconomic Indicators**: Interest rates, inflation, GDP growth\n",
    "\n",
    "### 🚀 **Advanced Enhancements**\n",
    "\n",
    "4. **Multi-Asset Models**:\n",
    "   - Include correlated assets (sector ETFs, commodities)\n",
    "   - Cross-asset attention mechanisms\n",
    "\n",
    "5. **News and Sentiment Integration**:\n",
    "   - Natural Language Processing on financial news\n",
    "   - Social media sentiment analysis\n",
    "   - Earnings call transcripts analysis\n",
    "\n",
    "6. **Ensemble Methods**:\n",
    "   - Combine multiple models (LSTM + Random Forest + Linear Regression)\n",
    "   - Weighted voting based on recent performance\n",
    "\n",
    "7. **Online Learning**:\n",
    "   - Continuously update model with new data\n",
    "   - Adaptive learning rates based on market conditions\n",
    "\n",
    "### 📊 **Validation Improvements**\n",
    "\n",
    "8. **Walk-Forward Validation**:\n",
    "   - Multiple train-test cycles\n",
    "   - Out-of-sample testing across different market conditions\n",
    "\n",
    "9. **Risk-Adjusted Metrics**:\n",
    "   - Sharpe ratio, Sortino ratio\n",
    "   - Maximum drawdown analysis\n",
    "   - Value at Risk (VaR) calculations\n"
   ],
   "id": "d4cfd66169426025"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Final summary and recommendations\n",
    "print(\"🎯 FINAL RECOMMENDATIONS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if rmse_improvement > 15 and lstm_metrics['Directional_Accuracy'] > 55:\n",
    "    print(\"✅ STRONG MODEL: Consider for further development\")\n",
    "    print(\"   → Focus on hyperparameter tuning and feature engineering\")\n",
    "    print(\"   → Implement walk-forward validation\")\n",
    "    print(\"   → Add risk management components\")\n",
    "\n",
    "elif rmse_improvement > 5 and lstm_metrics['Directional_Accuracy'] > 50:\n",
    "    print(\"✅ PROMISING MODEL: Needs refinement\")\n",
    "    print(\"   → Try alternative architectures (GRU, Attention)\")\n",
    "    print(\"   → Add more features (sentiment, fundamentals)\")\n",
    "    print(\"   → Implement ensemble methods\")\n",
    "\n",
    "else:\n",
    "    print(\"⚠️  WEAK MODEL: Significant improvements needed\")\n",
    "    print(\"   → Reconsider feature selection\")\n",
    "    print(\"   → Try completely different approaches\")\n",
    "    print(\"   → Consider if this asset is predictable with current methods\")\n",
    "\n",
    "print(f\"\\n📈 MODEL PERFORMANCE SUMMARY FOR {STOCK_TICKER}\")\n",
    "print(f\"   RMSE: ${lstm_metrics['RMSE']:.2f}\")\n",
    "print(f\"   Directional Accuracy: {lstm_metrics['Directional_Accuracy']:.1f}%\")\n",
    "print(f\"   Improvement over Baseline: {rmse_improvement:.1f}%\")\n",
    "\n",
    "print(\"\\n⚠️  REMEMBER: This is for educational purposes only.\")\n",
    "print(\"   Always conduct thorough backtesting and risk assessment\")\n",
    "print(\"   before considering any real-world application.\")\n",
    "\n",
    "print(\"\\n🎉 Analysis Complete! Thank you for using this comprehensive LSTM stock forecasting notebook.\")\n"
   ],
   "id": "81293fb43c3b5165",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c86a04ebc8b6cc7c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
