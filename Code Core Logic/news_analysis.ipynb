{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Stock Market News Analysis\n",
    "#### This notebook analyzes stock market news sentiment and correlates it with stock price movements.\n"
   ],
   "id": "a5782be9c29d7b19"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configuration\n",
   "id": "a41642021ec066c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Configuration parameters for analysis\n",
    "CONFIG = {\n",
    "    # Stock Symbol to Analysis\n",
    "    \"stock_symbol\": \"NVDA\",\n",
    "\n",
    "    # Analysis year\n",
    "    \"analysis_year\": 2019,\n",
    "\n",
    "    # Date for company details (format: \"YYYY-MM-DD\")\n",
    "    \"company_details_date\": \"2025-07-07\",\n",
    "\n",
    "    # File paths\n",
    "    \"news_data_path\": \"news_data.csv\",\n",
    "    \"output_news_data_path\": \"news_data_updated.csv\",\n",
    "}"
   ],
   "id": "95c8cb2550500c85"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import Package And Dependencies\n",
   "id": "cb413e3705fdb511"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T22:03:59.315513Z",
     "start_time": "2025-07-24T22:03:59.313106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# !pip install pip\n",
    "# !pip3 install torch torchvision\n",
    "# !pip install requests\n",
    "# !pip install --upgrade yfinance\n",
    "# !pip install pandas\n",
    "# !pip install nltk\n",
    "# !pip install spacy\n",
    "# !pip install matplotlib\n",
    "# !pip install wordcloud\n",
    "# !pip install torch\n",
    "# !pip install transformers\n",
    "# !pip install mplfinance\n",
    "# !pip install ipywidgets\n"
   ],
   "id": "f09feae7d7d178d5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T22:04:02.370246Z",
     "start_time": "2025-07-24T22:03:59.546555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import traceback\n",
    "import sys\n",
    "from typing import Any, Optional, List, Union, Dict\n",
    "\n",
    "# Data processing imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# NLP imports\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "\n",
    "# Financial data imports\n",
    "import yfinance as yf\n"
   ],
   "id": "d8ec5b73546a13e6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.virtualenvs/stock_market_analysis/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T22:04:02.612641Z",
     "start_time": "2025-07-24T22:04:02.563419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Create a directory for the output files ---\n",
    "output_dir = CONFIG[\"stock_symbol\"]\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# --- Updated output file names to be inside the new directory ---\n",
    "CONFIG.update({\n",
    "    \"wordcloud_output\": os.path.join(output_dir, \"wordcloud_tickers.png\"),\n",
    "    \"sentiment_trends_output\": os.path.join(output_dir, \"sentiment_trends_grouped.png\"),\n",
    "    \"company_sentiment_output\": os.path.join(output_dir, f\"{CONFIG['stock_symbol']}_sentiment_analysis.png\"),\n",
    "    \"stock_candlestick_output\": os.path.join(output_dir, f\"{CONFIG['stock_symbol']}_{CONFIG['analysis_year']}_candlestick.png\"),\n",
    "    \"stock_closing_price_output\": os.path.join(output_dir, f\"{CONFIG['stock_symbol']}_{CONFIG['analysis_year']}_closing_price.png\"),\n",
    "    \"sentiment_with_stock_price_output\": os.path.join(output_dir, f\"{CONFIG['stock_symbol']}_{CONFIG['analysis_year']}_sentiment_with_stock_price.png\")\n",
    "})\n"
   ],
   "id": "8a98e968987efd8e",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CONFIG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# --- Create a directory for the output files ---\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m output_dir \u001B[38;5;241m=\u001B[39m \u001B[43mCONFIG\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstock_symbol\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(output_dir):\n\u001B[1;32m      4\u001B[0m     os\u001B[38;5;241m.\u001B[39mmakedirs(output_dir)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'CONFIG' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set pandas display options\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n"
   ],
   "id": "918ab481b1353db6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load DATASET into Pandas Dataframe\n",
   "id": "1709a06b25f281c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# https://www.kaggle.com/datasets/miguelaenlle/massive-stock-news-analysis-db-for-nlpbacktests/",
   "id": "1359927f5921d5fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def save_news_dataframe(df: pd.DataFrame, file_path: str = CONFIG[\"output_news_data_path\"]) -> bool:\n",
    "    try:\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"News DataFrame saved to {file_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Failed to save news DataFrame: {e}\")\n",
    "        return False\n"
   ],
   "id": "65db92ed8be0e059",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_and_explore_data(file_path: str = CONFIG[\"news_data_path\"]) -> Optional[pd.DataFrame]:\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"Data loaded successfully.\")\n",
    "\n",
    "        # Display the first 5 rows\n",
    "        print(\"\\n--- First 5 rows ---\")\n",
    "        print(df.head())\n",
    "\n",
    "        # Display the first 5 rows\n",
    "        print(\"\\n--- Last 5 rows ---\")\n",
    "        print(df.tail())\n",
    "\n",
    "        # Display DataFrame info\n",
    "        print(\"\\n\\n--- DataFrame Info ---\")\n",
    "        print(df.info())\n",
    "\n",
    "        # Preprocess the data\n",
    "        df = df[['title', 'date', 'stock']].drop_duplicates()\n",
    "        df = df.dropna()\n",
    "\n",
    "        df['Date'] = pd.to_datetime(df['date'], format='mixed', utc=True)\n",
    "        df['Year'] = df['Date'].dt.year\n",
    "\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: File at {file_path} is empty\")\n",
    "        return None\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error: Failed to parse file at {file_path}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n"
   ],
   "id": "b8b137b5479bd299",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "news_df = load_and_explore_data()\n",
    "\n",
    "if news_df is None:\n",
    "    exit()\n"
   ],
   "id": "2d6be1e4e25aafd9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Add this right after you load your data into news_df\n",
    "print(\"\\n--- Checking available stock tickers ---\")\n",
    "unique_tickers = news_df['stock'].unique()\n",
    "print(\"Available tickers in the DataFrame are:\")\n",
    "print(unique_tickers)\n",
    "\n",
    "# It might also be a case-sensitivity issue. Let's check for 'nvda' in lowercase.\n",
    "is_nvda_present_lower = 'nvda' in [str(t).lower() for t in unique_tickers]\n",
    "print(f\"\\nIs 'nvda' (lowercase) present? {is_nvda_present_lower}\")\n",
    "print(\"\\n\\n--- Stock to Filter ---\")\n",
    "print(CONFIG[\"stock_symbol\"])\n",
    "\n",
    "news_df['stock'] = news_df['stock'].str.strip()\n",
    "news_df_filtered = news_df[news_df['stock'] == CONFIG[\"stock_symbol\"]]\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(\"\\n--- First 5 rows ---\")\n",
    "print(news_df_filtered.head())\n",
    "\n",
    " # Display DataFrame info\n",
    "print(\"\\n\\n--- DataFrame Info ---\")\n",
    "print(news_df_filtered.info())\n",
    "\n",
    "# news_df = news_df.sample(n=len(news_df))\n",
    "# news_df = news_df.iloc[:1000,:]"
   ],
   "id": "d620cdba58e5715f",
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_company_details(stock_symbol: str = CONFIG[\"stock_symbol\"], \n",
    "                       date_str: str = CONFIG[\"company_details_date\"]) -> None:\n",
    "    \"\"\"\n",
    "    Fetches and prints company details and historical market data for a given\n",
    "    stock symbol and date using the yfinance library.\n",
    "\n",
    "    Args:\n",
    "        stock_symbol (str): The stock ticker symbol (e.g., 'MSFT', 'GOOGL').\n",
    "        date_str (str): The date in 'YYYY-MM-DD' format.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Fetching details for {stock_symbol} on {date_str} ---\")\n",
    "    try:\n",
    "        # Create a Ticker object for the stock symbol\n",
    "        ticker = yf.Ticker(stock_symbol)\n",
    "\n",
    "        # 1. Get the general company information (a dictionary)\n",
    "        info = ticker.info\n",
    "\n",
    "        # Check if the ticker is valid by looking for a key like 'longName'\n",
    "        if 'longName' not in info:\n",
    "            print(f\"Could not find company details for symbol: {stock_symbol}\")\n",
    "            return\n",
    "\n",
    "        print(f\"Company Info: {json.dumps(info)}\")\n",
    "        print(f\"Company Name: {info.get('longName', 'N/A')}\")\n",
    "        print(f\"Sector: {info.get('sector', 'N/A')}\")\n",
    "        print(f\"Industry: {info.get('industry', 'N/A')}\")\n",
    "        print(f\"Website: {info.get('website', 'N/A')}\")\n",
    "\n",
    "        # 2. Get historical market data for the specific date\n",
    "        # To get a single day, set the end date to the next day\n",
    "        start_date = date_str\n",
    "        end_date = (pd.to_datetime(date_str) + pd.Timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "\n",
    "        hist_data = ticker.history(start=start_date, end=end_date)\n",
    "\n",
    "        if hist_data.empty:\n",
    "            print(f\"\\nNo market data found for {date_str}. It might be a weekend or holiday.\")\n",
    "        else:\n",
    "            # Extract the data for our specific date\n",
    "            day_data = hist_data.iloc[0]\n",
    "            print(\"\\nMarket Data for the Day:\")\n",
    "            print(f\"  Open:   ${day_data['Open']:.2f}\")\n",
    "            print(f\"  High:   ${day_data['High']:.2f}\")\n",
    "            print(f\"  Low:    ${day_data['Low']:.2f}\")\n",
    "            print(f\"  Close:  ${day_data['Close']:.2f}\")\n",
    "            print(f\"  Volume: {day_data['Volume']:,}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while fetching data: {e}\")\n",
    "\n",
    "# Get details for the configured stock on the specified date\n",
    "get_company_details()\n"
   ],
   "id": "9511045f28326a9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Initialize NLP Components\n",
   "id": "b49649970b507496"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize FinBERT model and tokenizer\n",
    "finbert_model_name = \"ProsusAI/finbert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(finbert_model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(finbert_model_name)\n"
   ],
   "id": "a3339a96778c1a21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Download the English language model for spaCy\n",
    "!{sys.executable} -m spacy download en_core_web_sm\n",
    "\n",
    "# Initialize spaCy model for company name extraction\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ],
   "id": "43975f25f6f6433",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Text Processing Operations\n",
   "id": "27d50d9eaaa9b9f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clean_text(text: Union[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Cleans the text by converting to lowercase and removing special characters and digits.\n",
    "\n",
    "    This function performs the following operations:\n",
    "    1. Converts input to string\n",
    "    2. Removes punctuation except periods\n",
    "    3. Converts to lowercase\n",
    "    4. Replaces periods with underscores (to keep ticker symbols as single words)\n",
    "    5. Removes possessive 's\n",
    "    6. Removes special characters and digits, but keeps underscores\n",
    "\n",
    "    Args:\n",
    "        text (Union[str, Any]): The text to clean. Can be any type that can be converted to string.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned text.\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "\n",
    "    # Convert to string if not already\n",
    "    text = str(text)\n",
    "\n",
    "    # Remove punctuation except periods\n",
    "    text = re.sub(r'[^\\w\\s.]', '', text)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Replace periods with underscores to keep ticker symbols as single words\n",
    "    text = text.replace('.', '_')\n",
    "\n",
    "    # Remove possessive 's\n",
    "    text = text.replace(\"'s\", '')\n",
    "\n",
    "    # Remove special characters and digits, but keep underscores\n",
    "    text = re.sub(r'[^a-zA-Z\\s_]', '', text)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n"
   ],
   "id": "95a53aba34496630",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def analyze_sentiment(description: Optional[str]) -> str:\n",
    "    \"\"\"\n",
    "    Analyzes the sentiment of the given text using FinBERT.\n",
    "\n",
    "    This function uses the FinBERT model, which is a BERT model fine-tuned for\n",
    "    financial sentiment analysis. It classifies text as positive, negative, or neutral\n",
    "    based on the financial context.\n",
    "\n",
    "    Args:\n",
    "        description (Optional[str]): The text to analyze. Can be None.\n",
    "\n",
    "    Returns:\n",
    "        str: The sentiment label ('Positive', 'Negative', 'Neutral', or 'Unknown' if an error occurs).\n",
    "    \"\"\"\n",
    "    if not description:\n",
    "        return 'Unknown'\n",
    "\n",
    "    try:\n",
    "        # Clean the text before analysis\n",
    "        cleaned_description = clean_text(description)\n",
    "\n",
    "        # Skip empty strings after cleaning\n",
    "        if not cleaned_description:\n",
    "            return 'Unknown'\n",
    "\n",
    "        # Tokenize the text for FinBERT\n",
    "        inputs = tokenizer(cleaned_description, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "        # Get model predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "        # Get the predicted class (0: negative, 1: neutral, 2: positive)\n",
    "        predicted_class = torch.argmax(predictions, dim=1).item()\n",
    "\n",
    "        # Map the class to a sentiment label\n",
    "        sentiment_map = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
    "        return sentiment_map[predicted_class]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing sentiment for text '{description[:50]}...': {e}\")\n",
    "        return 'Unknown'\n"
   ],
   "id": "c5243478612f304d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Apply sentiment analysis to the news titles\n",
    "news_df['Sentiment'] = news_df['title'].apply(analyze_sentiment)\n"
   ],
   "id": "c63463b4734eb0f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Finding Company which is mostly coming up in News using Word Cloud\n",
   "id": "cdedd6f320f992ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def generate_word_cloud(company_names: Union[List, np.ndarray, pd.Series, str], \n",
    "                     output_file: str = CONFIG[\"wordcloud_output\"],\n",
    "                     apply_nlp_processing: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Generates a word cloud from company names or text.\n",
    "\n",
    "    This function takes a collection of company names or text, processes it,\n",
    "    and generates a word cloud visualization that highlights the most frequent terms.\n",
    "\n",
    "    Args:\n",
    "        company_names (Union[List, np.ndarray, pd.Series, str]): \n",
    "            The company names or text to visualize. Can be a list, numpy array, pandas Series, or string.\n",
    "        output_file (str): \n",
    "            The name of the file to save the word cloud to.\n",
    "        apply_nlp_processing (bool):\n",
    "            Whether to apply NLP processing (tokenization, stopword removal, lemmatization).\n",
    "            Default is False.\n",
    "\n",
    "    Returns:\n",
    "        None: The function saves the word cloud to a file and displays it.\n",
    "    \"\"\"\n",
    "    print(f\"Input type: {type(company_names)}\")\n",
    "\n",
    "    # Process the input based on its type\n",
    "    if isinstance(company_names, (list, np.ndarray)):\n",
    "        # Remove None values and convert all items to strings\n",
    "        names_list = [str(name) for name in company_names if name is not None]\n",
    "        # Remove duplicates by converting to a set first, then back to a list\n",
    "        unique_names = list(set(names_list))\n",
    "        text = ' '.join(unique_names)\n",
    "    elif isinstance(company_names, pd.Series):\n",
    "        # Convert Series to list, remove None values, and join\n",
    "        names_list = [str(name) for name in company_names.tolist() if name is not None]\n",
    "        unique_names = list(set(names_list))\n",
    "        text = ' '.join(unique_names)\n",
    "    else:\n",
    "        # If it's already a string or another type, convert to string\n",
    "        text = str(company_names)\n",
    "\n",
    "    # Apply NLP processing if requested\n",
    "    if apply_nlp_processing:\n",
    "        # Tokenize text\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        # Remove stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "\n",
    "        # Lemmatize tokens\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "        # Join tokens back into a string\n",
    "        text = ' '.join(tokens)\n",
    "\n",
    "    # Print a preview of the processed text\n",
    "    print(\"Processed text for wordcloud:\", text[:100] + \"...\" if len(text) > 100 else text)\n",
    "\n",
    "    # Check if text is empty\n",
    "    if not text.strip():\n",
    "        print(\"Warning: No text to generate word cloud from.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Create a word cloud\n",
    "        wordcloud = WordCloud(\n",
    "            width=1000,\n",
    "            height=500,\n",
    "            max_font_size=100,\n",
    "            max_words=200,\n",
    "            background_color='white',\n",
    "            colormap='viridis',\n",
    "            collocations=False  # Avoid repeating word pairs\n",
    "        ).generate(text)\n",
    "\n",
    "        # Plot the word cloud\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title('Word Cloud of Company Names', fontsize=15)\n",
    "        plt.tight_layout(pad=0)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        # Save the word cloud to a file\n",
    "        wordcloud.to_file(output_file)\n",
    "        print(f\"\\nWord cloud saved to {output_file}\")\n",
    "\n",
    "        # Print the top 10 words in the word cloud\n",
    "        print(\"Top 10 words in the word cloud:\")\n",
    "        sorted_words = sorted(wordcloud.words_.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "        for word, frequency in sorted_words:\n",
    "            print(f\"{word}: {frequency:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating word cloud: {e}\")\n"
   ],
   "id": "e5434db288fbbcfc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generate and save the word cloud\n",
    "generate_word_cloud(news_df['stock'].values)\n"
   ],
   "id": "1964fc3352ff7ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display the most frequent stock symbols in the news\n",
    "print(news_df['stock'].value_counts())\n"
   ],
   "id": "2197deb8ec516a8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get the top stock symbols\n",
    "top_n = 1  # Number of top stocks to analyze\n",
    "top_stocks = news_df['stock'].value_counts().index[:top_n].tolist()\n",
    "\n",
    "print(f\"Top {top_n} stocks: {top_stocks}\")\n"
   ],
   "id": "d7d7b46a9ac69031",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Year wise Sentiment Analysis Visualization\n",
   "id": "c93131c9a9273d76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def analyze_and_visualize_sentiment_by_year(news_df: pd.DataFrame, \n",
    "                                    output_file: str = CONFIG[\"sentiment_trends_output\"]) -> None:\n",
    "    \"\"\"\n",
    "    Analyzes sentiment trends over time (by year) and visualizes the results\n",
    "    using a grouped bar chart.\n",
    "\n",
    "    This function processes the news DataFrame to extract sentiment trends over time,\n",
    "    and creates a visualization showing how sentiment distribution changes by year.\n",
    "\n",
    "    Args:\n",
    "        news_df (pd.DataFrame): The DataFrame containing news data.\n",
    "        output_file (str): The path to save the visualization image.\n",
    "\n",
    "    Returns:\n",
    "        None: The function saves the visualization to a file and displays it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Make a copy to avoid modifying the original DataFrame\n",
    "        df = news_df.copy()\n",
    "\n",
    "        # Convert the Date column to datetime if it's not already\n",
    "        if not pd.api.types.is_datetime64_any_dtype(df['Date']):\n",
    "            df['Date'] = pd.to_datetime(df['Date'], format='mixed', errors='coerce')\n",
    "            # Drop rows with invalid dates\n",
    "            df = df.dropna(subset=['Date'])\n",
    "\n",
    "        if df.empty:\n",
    "            print(\"Error: No valid data after date conversion.\")\n",
    "            return\n",
    "\n",
    "        # Extract the year and month from the Date column\n",
    "        df['Year'] = df['Date'].dt.year\n",
    "        df['Month'] = df['Date'].dt.month\n",
    "\n",
    "        # Group the data by year and month, and count the number of negative, neutral, and positive sentiments\n",
    "        df_grouped = df.groupby(['Year', 'Month', 'Sentiment']).size().reset_index(name='Count')\n",
    "\n",
    "        # Pivot the data to create a table with year and month on the x-axis, and sentiment counts as values\n",
    "        df_pivot = df_grouped.pivot_table(index=['Year', 'Month'], columns='Sentiment', values='Count').fillna(0)\n",
    "\n",
    "        # --- Plotting ---\n",
    "        # Create a yearly pivot table for the bar chart\n",
    "        df_pivot_yearly = df.groupby('Year')['Sentiment'].value_counts().unstack().fillna(0)\n",
    "\n",
    "        # Check if we have data to plot\n",
    "        if df_pivot_yearly.empty:\n",
    "            print(\"Error: No data to plot after grouping.\")\n",
    "            return\n",
    "\n",
    "        # Set up the figure\n",
    "        plt.figure(figsize=(15, 8))\n",
    "\n",
    "        # Define colors for different sentiments with better contrast\n",
    "        colors = {\n",
    "            'Negative': '#E53935',  # Bright red\n",
    "            'Neutral': '#1E88E5',   # Bright blue\n",
    "            'Positive': '#43A047'   # Bright green\n",
    "        }\n",
    "\n",
    "        # Get the available sentiment columns and their corresponding colors\n",
    "        available_sentiments = df_pivot_yearly.columns.tolist()\n",
    "        plot_colors = [colors.get(sentiment, '#9E9E9E') for sentiment in available_sentiments]\n",
    "\n",
    "        # Create the bar chart\n",
    "        ax = df_pivot_yearly.plot(\n",
    "            kind='bar', \n",
    "            figsize=(15, 8), \n",
    "            color=plot_colors,\n",
    "            width=0.8\n",
    "        )\n",
    "\n",
    "        # Add data labels on top of each bar\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, fmt='%d', fontsize=10)\n",
    "\n",
    "        # Add a grid for better readability\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "        # Add labels and title\n",
    "        plt.xlabel('Year', fontsize=12)\n",
    "        plt.ylabel('Number of News Articles', fontsize=12)\n",
    "        plt.title(f'Sentiment Analysis: {len(df.index)} News Articles ({df['Year'].min()}-{df['Year'].max()})', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "        # Improve legend\n",
    "        plt.legend(title='Sentiment', fontsize=10, title_fontsize=12)\n",
    "\n",
    "        # Rotate x-axis labels for better readability\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the figure\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Visualization saved to {output_file}\")\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        # Print summary statistics\n",
    "        print(\"\\nSentiment Distribution by Year:\")\n",
    "        print(df_pivot_yearly)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in sentiment analysis visualization: {e}\")\n"
   ],
   "id": "ecbe227b45ea666a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Analyze and visualize sentiment trends by year\n",
    "analyze_and_visualize_sentiment_by_year(news_df)\n"
   ],
   "id": "33f39e88046d8e0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Company Specific Sentiment Analysis\n",
   "id": "eaac0ebab460f797"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def analyze_and_visualize_company_sentiment(company_name: str, news_df: pd.DataFrame, \n",
    "                                    output_prefix: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Filters the dataset for a specific company, analyzes sentiment, and visualizes\n",
    "    the results using multiple charts.\n",
    "\n",
    "    This function analyzes sentiment trends for a specific company over time and\n",
    "    creates visualizations to show the distribution and trends of sentiment.\n",
    "\n",
    "    Args:\n",
    "        company_name (str): The name or ticker symbol of the company to analyze.\n",
    "        news_df (pd.DataFrame): The DataFrame containing news data.\n",
    "        output_prefix (str, optional): Prefix for output files. If None, uses company_name.\n",
    "\n",
    "    Returns:\n",
    "        None: The function displays visualizations and saves them to files.\n",
    "    \"\"\"\n",
    "    if output_prefix is None:\n",
    "        output_prefix = company_name\n",
    "\n",
    "    try:\n",
    "        # Filter the dataset for the specific company\n",
    "        company_df = news_df[news_df['stock'] == company_name].copy()\n",
    "\n",
    "        if company_df.empty:\n",
    "            print(f\"No data found for company with ticker symbol '{company_name}'\")\n",
    "            return\n",
    "\n",
    "        # Convert the Date column to datetime if it's not already\n",
    "        if not pd.api.types.is_datetime64_any_dtype(company_df['Date']):\n",
    "            company_df['Date'] = pd.to_datetime(company_df['Date'], format='mixed', errors='coerce')\n",
    "            # Drop rows with invalid dates\n",
    "            company_df = company_df.dropna(subset=['Date'])\n",
    "\n",
    "        if company_df.empty:\n",
    "            print(f\"No valid data after date conversion for company '{company_name}'\")\n",
    "            return\n",
    "\n",
    "        # Extract year and month\n",
    "        company_df['Year'] = company_df['Date'].dt.year\n",
    "        company_df['Month'] = company_df['Date'].dt.month\n",
    "\n",
    "        # Count the number of positive, negative, and neutral sentiments for the company\n",
    "        sentiment_counts = company_df['Sentiment'].value_counts()\n",
    "        positive_count = sentiment_counts.get('Positive', 0)\n",
    "        negative_count = sentiment_counts.get('Negative', 0)\n",
    "        neutral_count = sentiment_counts.get('Neutral', 0)\n",
    "        total_count = positive_count + negative_count + neutral_count\n",
    "\n",
    "        # Print the counts and percentages\n",
    "        print(f\"\\n--- Sentiment Analysis for {company_name} ---\")\n",
    "        print(f\"Total articles: {total_count}\")\n",
    "        print(f\"Positive: {positive_count} ({positive_count/total_count*100:.1f}%)\")\n",
    "        print(f\"Negative: {negative_count} ({negative_count/total_count*100:.1f}%)\")\n",
    "        print(f\"Neutral: {neutral_count} ({neutral_count/total_count*100:.1f}%)\")\n",
    "\n",
    "        # Create a figure with 2 subplots: pie chart and line chart\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "        # 1. Pie Chart - Sentiment Distribution\n",
    "        labels = ['Positive', 'Negative', 'Neutral']\n",
    "        sizes = [positive_count, negative_count, neutral_count]\n",
    "        colors = ['#43A047', '#E53935', '#1E88E5']  # Green, Red, Blue\n",
    "        explode = (0.1, 0.1, 0.1)  # Explode all slices for better visibility\n",
    "\n",
    "        ax1.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "                shadow=True, startangle=90, textprops={'fontsize': 12})\n",
    "        ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "        ax1.set_title(f'Sentiment Distribution for {company_name}\\n({total_count} Articles)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "\n",
    "        # 2. Line Chart - Sentiment Trends Over Time\n",
    "        # Group by year and sentiment, then count\n",
    "        yearly_sentiment = company_df.groupby(['Year', 'Sentiment']).size().unstack().fillna(0)\n",
    "\n",
    "        if not yearly_sentiment.empty:\n",
    "            # Plot the line chart\n",
    "            for sentiment, color in zip(['Positive', 'Negative', 'Neutral'], colors):\n",
    "                if sentiment in yearly_sentiment.columns:\n",
    "                    ax2.plot(yearly_sentiment.index, yearly_sentiment[sentiment], \n",
    "                            marker='o', linewidth=2, label=sentiment, color=color)\n",
    "\n",
    "            ax2.set_xlabel('Year', fontsize=12)\n",
    "            ax2.set_ylabel('Number of Articles', fontsize=12)\n",
    "            ax2.set_title(f'Sentiment Trends for {company_name} Over Time', \n",
    "                         fontsize=14, fontweight='bold')\n",
    "\n",
    "            # Set x-ticks to years only\n",
    "            ax2.set_xticks(yearly_sentiment.index)\n",
    "            ax2.set_xticklabels(yearly_sentiment.index, rotation=45)\n",
    "\n",
    "            # Add grid for better readability\n",
    "            ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "            # Add legend\n",
    "            ax2.legend(title='Sentiment', fontsize=10, title_fontsize=12)\n",
    "\n",
    "            # Add data point labels\n",
    "            for sentiment, color in zip(['Positive', 'Negative', 'Neutral'], colors):\n",
    "                if sentiment in yearly_sentiment.columns:\n",
    "                    for x, y in zip(yearly_sentiment.index, yearly_sentiment[sentiment]):\n",
    "                        if y > 0:  # Only label non-zero values\n",
    "                            ax2.annotate(f'{int(y)}', \n",
    "                                        (x, y), \n",
    "                                        textcoords=\"offset points\",\n",
    "                                        xytext=(0, 5), \n",
    "                                        ha='center',\n",
    "                                        fontsize=9)\n",
    "        else:\n",
    "            ax2.text(0.5, 0.5, 'No yearly data available', \n",
    "                    horizontalalignment='center', verticalalignment='center',\n",
    "                    transform=ax2.transAxes, fontsize=12)\n",
    "\n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the figure\n",
    "        output_file = CONFIG[\"company_sentiment_output\"].format(stock_symbol=company_name)\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Visualization saved to {output_file}\")\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Column not found - {e}\")\n",
    "    except ZeroDivisionError:\n",
    "        print(f\"Error: No sentiment data available for {company_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        traceback.print_exc()\n"
   ],
   "id": "7aa88c94b30b5aec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Analyze sentiment for each top stock\n",
    "for company in top_stocks:\n",
    "    analyze_and_visualize_company_sentiment(company, news_df)\n"
   ],
   "id": "93bd520daf764c38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the processed news dataframe\n",
    "save_news_dataframe(news_df)\n"
   ],
   "id": "67412c65a87e3807",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def company_news_count(company_name: str, news_df: pd.DataFrame,\n",
    "                      output_prefix: str = None) -> Dict[int, Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Analyzes the news count by year and sentiment for a specific company.\n",
    "\n",
    "    Args:\n",
    "        company_name (str): The name or ticker symbol of the company to analyze.\n",
    "        news_df (pd.DataFrame): The DataFrame containing news data.\n",
    "        output_prefix (str, optional): Prefix for output files. If None, uses company_name.\n",
    "\n",
    "    Returns:\n",
    "        Dict[int, Dict[str, int]]: A dictionary with years as keys and sentiment counts as values.\n",
    "    \"\"\"\n",
    "    if output_prefix is None:\n",
    "        output_prefix = company_name\n",
    "\n",
    "    try:\n",
    "        # Filter the dataset for the specific company\n",
    "        company_df = news_df[news_df['stock'] == company_name].copy()\n",
    "\n",
    "        if company_df.empty:\n",
    "            print(f\"No data found for company with ticker symbol '{company_name}'\")\n",
    "            return {}\n",
    "\n",
    "        # Convert the Date column to datetime if it's not already\n",
    "        if not pd.api.types.is_datetime64_any_dtype(company_df['Date']):\n",
    "            company_df['Date'] = pd.to_datetime(company_df['Date'], format='mixed', errors='coerce')\n",
    "            # Drop rows with invalid dates\n",
    "            company_df = company_df.dropna(subset=['Date'])\n",
    "\n",
    "        if company_df.empty:\n",
    "            print(f\"No valid data after date conversion for company '{company_name}'\")\n",
    "            return {}\n",
    "\n",
    "        # Extract year and month\n",
    "        company_df['Year'] = company_df['Date'].dt.year\n",
    "        company_df['Month'] = company_df['Date'].dt.month\n",
    "\n",
    "        # Group by Year and Sentiment, count articles, then pivot sentiments into columns\n",
    "        yearly_sentiment_df = company_df.groupby(['Year', 'Sentiment']).size().unstack(fill_value=0)\n",
    "\n",
    "        # --- Optional but Recommended: Ensure all sentiment columns exist ---\n",
    "        # This handles cases where a sentiment (e.g., 'Positive') might be missing entirely\n",
    "        for sentiment in ['Positive', 'Negative', 'Neutral']:\n",
    "            if sentiment not in yearly_sentiment_df.columns:\n",
    "                yearly_sentiment_df[sentiment] = 0\n",
    "\n",
    "        # Reorder columns for a consistent output\n",
    "        yearly_sentiment_df = yearly_sentiment_df[['Positive', 'Negative', 'Neutral']]\n",
    "\n",
    "        yearly_sentiment_df['Total'] = yearly_sentiment_df[['Positive', 'Negative', 'Neutral']].sum(axis=1)\n",
    "\n",
    "        # Display the resulting DataFrame\n",
    "        print(yearly_sentiment_df)\n",
    "\n",
    "        # This gets the row with the most news. The index of this row is the year.\n",
    "        max_news_row = yearly_sentiment_df.loc[yearly_sentiment_df['Total'].idxmax()]\n",
    "\n",
    "        # The year is stored in the .name attribute of the resulting Series\n",
    "        year_of_max_news = max_news_row.name\n",
    "\n",
    "        print(f\"\\n--- Year with most news: {year_of_max_news} ---\")\n",
    "\n",
    "        # Convert the DataFrame to a dictionary for easier access\n",
    "        result_dict = {}\n",
    "        for year, row in yearly_sentiment_df.iterrows():\n",
    "            result_dict[year] = {\n",
    "                'Positive': int(row['Positive']),\n",
    "                'Negative': int(row['Negative']),\n",
    "                'Neutral': int(row['Neutral']),\n",
    "                'Total': int(row['Total'])\n",
    "            }\n",
    "\n",
    "        return result_dict\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Get news counts for each top stock\n",
    "news_counts = {}\n",
    "for company in top_stocks:\n",
    "    news_counts[company] = company_news_count(company, news_df)\n"
   ],
   "id": "c16e6f0d35209f99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_stock_details_for_year(stock_symbol: str = CONFIG[\"stock_symbol\"], \n",
    "                              year: int = CONFIG[\"analysis_year\"]) -> None:\n",
    "    \"\"\"\n",
    "    Fetches company info, summarizes stock market performance for a given year,\n",
    "    and plots a line chart of the closing price.\n",
    "\n",
    "    Args:\n",
    "        stock_symbol (str): The stock ticker symbol (e.g., 'AAPL', 'TSLA').\n",
    "        year (int): The year for which to retrieve data (e.g., 2023).\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Fetching details for {stock_symbol} for the year {year} ---\")\n",
    "    try:\n",
    "        ticker = yf.Ticker(stock_symbol)\n",
    "        info = ticker.info\n",
    "\n",
    "        if 'longName' not in info or info.get('longName') is None:\n",
    "            print(f\"Could not find company details for symbol: {stock_symbol}\")\n",
    "            return\n",
    "\n",
    "        print(f\"Company Name: {info.get('longName', 'N/A')}\")\n",
    "        print(f\"Sector: {info.get('sector', 'N/A')}\")\n",
    "        print(f\"Industry: {info.get('industry', 'N/A')}\")\n",
    "\n",
    "        start_date = f\"{year}-01-01\"\n",
    "        end_date = f\"{year + 1}-01-01\"\n",
    "        hist_data = ticker.history(start=start_date, end=end_date)\n",
    "\n",
    "        if hist_data.empty:\n",
    "            print(f\"\\nNo market data found for the year {year}.\")\n",
    "        else:\n",
    "            yearly_open = hist_data['Open'].iloc[0]\n",
    "            yearly_close = hist_data['Close'].iloc[-1]\n",
    "            yearly_high = hist_data['High'].max()\n",
    "            yearly_low = hist_data['Low'].min()\n",
    "            total_volume = hist_data['Volume'].sum()\n",
    "            percent_change = ((yearly_close - yearly_open) / yearly_open) * 100\n",
    "\n",
    "            print(\"\\n📈 Yearly Market Summary:\")\n",
    "            print(f\"  Year Start Open: ${yearly_open:,.2f}\")\n",
    "            print(f\"  Year End Close:  ${yearly_close:,.2f}\")\n",
    "            print(f\"  Yearly High:     ${yearly_high:,.2f}\")\n",
    "            print(f\"  Yearly Low:      ${yearly_low:,.2f}\")\n",
    "            print(f\"  Total Volume:    {total_volume:,}\")\n",
    "            print(f\"  Yearly Change:   {percent_change:.2f}%\")\n",
    "\n",
    "            # --- Plotting the line chart ---\n",
    "            plt.style.use('seaborn-v0_8-whitegrid') # Sets a nice style for the plot\n",
    "            plt.figure(figsize=(12, 6)) # Create a figure with a specific size\n",
    "\n",
    "            # Plot the closing price. The index is the Date.\n",
    "            plt.plot(hist_data.index, hist_data['Close'], label=f'{stock_symbol} Close Price', color='b')\n",
    "\n",
    "            # Add titles and labels for clarity\n",
    "            plt.title(f'Closing Price for {stock_symbol} in {year}', fontsize=16)\n",
    "            plt.xlabel('Date', fontsize=12)\n",
    "            plt.ylabel('Close Price (USD)', fontsize=12)\n",
    "\n",
    "            # Add a legend\n",
    "            plt.legend()\n",
    "\n",
    "            # Rotate date labels for better readability\n",
    "            plt.xticks(rotation=45)\n",
    "\n",
    "            # Ensure everything fits without overlapping\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # Save the chart to a file\n",
    "            output_filename = CONFIG[\"stock_closing_price_output\"].format(stock_symbol=stock_symbol, year=year)\n",
    "            plt.savefig(output_filename)\n",
    "            print(f\"\\nChart saved to {output_filename}\")\n",
    "\n",
    "            # Display the chart\n",
    "            plt.show()\n",
    "            plt.close() # Close the figure to free up memory\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# Get stock details for the configured stock and year\n",
    "get_stock_details_for_year()\n"
   ],
   "id": "68eab7d20aa7e4f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_stock_candlestick_for_year(stock_symbol: str = CONFIG[\"stock_symbol\"], \n",
    "                                  year: int = CONFIG[\"analysis_year\"]) -> None:\n",
    "    \"\"\"\n",
    "    Fetches company info, summarizes stock market performance for a given year,\n",
    "    and plots a maximized candlestick chart.\n",
    "\n",
    "    Args:\n",
    "        stock_symbol (str): The stock ticker symbol (e.g., 'AAPL', 'TSLA').\n",
    "        year (int): The year for which to retrieve data (e.g., 2023).\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Fetching details for {stock_symbol} for the year {year} ---\")\n",
    "    try:\n",
    "        ticker = yf.Ticker(stock_symbol)\n",
    "        info = ticker.info\n",
    "\n",
    "        if 'longName' not in info or info.get('longName') is None:\n",
    "            print(f\"Could not find company details for symbol: {stock_symbol}\")\n",
    "            return\n",
    "\n",
    "        print(f\"Company Name: {info.get('longName', 'N/A')}\")\n",
    "        print(f\"Sector: {info.get('sector', 'N/A')}\")\n",
    "        print(f\"Industry: {info.get('industry', 'N/A')}\")\n",
    "\n",
    "        start_date = f\"{year}-01-01\"\n",
    "        end_date = f\"{year + 1}-01-01\"\n",
    "        hist_data = ticker.history(start=start_date, end=end_date)\n",
    "\n",
    "        if hist_data.empty:\n",
    "            print(f\"\\nNo market data found for the year {year}.\")\n",
    "        else:\n",
    "            # (Yearly summary calculation remains the same)\n",
    "            yearly_open = hist_data['Open'].iloc[0]\n",
    "            yearly_close = hist_data['Close'].iloc[-1]\n",
    "            yearly_high = hist_data['High'].max()\n",
    "            yearly_low = hist_data['Low'].min()\n",
    "            total_volume = hist_data['Volume'].sum()\n",
    "            percent_change = ((yearly_close - yearly_open) / yearly_open) * 100\n",
    "\n",
    "            print(\"\\n📈 Yearly Market Summary:\")\n",
    "            print(f\"  Year Start Open: ${yearly_open:,.2f}\")\n",
    "            print(f\"  Year End Close:  ${yearly_close:,.2f}\")\n",
    "            print(f\"  Yearly High:     ${yearly_high:,.2f}\")\n",
    "            print(f\"  Yearly Low:      ${yearly_low:,.2f}\")\n",
    "            print(f\"  Total Volume:    {total_volume:,}\")\n",
    "            print(f\"  Yearly Change:   {percent_change:.2f}%\")\n",
    "\n",
    "            # --- UPDATED PLOTTING SECTION ---\n",
    "            output_filename = CONFIG[\"stock_candlestick_output\"].format(stock_symbol=stock_symbol, year=year)\n",
    "\n",
    "            fig, axlist = mpf.plot(hist_data,\n",
    "                                   type='candle',\n",
    "                                   style='charles',\n",
    "                                   title=f'Candlestick Chart for {stock_symbol} in {year}',\n",
    "                                   ylabel='Price (USD)',\n",
    "                                   volume=True,\n",
    "                                   mav=(20, 50),\n",
    "                                   returnfig=True\n",
    "                                  )\n",
    "\n",
    "            # Save the figure before showing\n",
    "            fig.savefig(output_filename)\n",
    "            print(f\"\\nChart saved to {output_filename}\")\n",
    "\n",
    "            # --- Maximize the plot window ---\n",
    "            # Get the current figure manager and maximize the window\n",
    "            fig_manager = plt.get_current_fig_manager()\n",
    "            fig_manager.window.showMaximized()\n",
    "\n",
    "            # Show the now-maximized plot\n",
    "            plt.show()\n",
    "\n",
    "            # Close the figure to free up memory\n",
    "            plt.close(fig)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# Get candlestick chart for the configured stock and year\n",
    "get_stock_candlestick_for_year()\n"
   ],
   "id": "55822baad7545291",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def analyze_and_visualize_company_sentiment_for_year(\n",
    "    company_name: str = CONFIG[\"stock_symbol\"], \n",
    "    year: int = CONFIG[\"analysis_year\"], \n",
    "    news_df: pd.DataFrame = None, \n",
    "    output_prefix: str = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Filters the dataset for a specific company and year, analyzes sentiment, and visualizes\n",
    "    the results with stock price overlay.\n",
    "\n",
    "    This function is a modified version of analyze_and_visualize_company_sentiment that\n",
    "    focuses on a specific year and overlays the stock price data with sentiment trends.\n",
    "\n",
    "    Args:\n",
    "        company_name (str): The name or ticker symbol of the company to analyze.\n",
    "        year (int): The specific year to analyze.\n",
    "        news_df (pd.DataFrame): The DataFrame containing news data.\n",
    "        output_prefix (str, optional): Prefix for output files. If None, uses company_name_year.\n",
    "\n",
    "    Returns:\n",
    "        None: The function displays visualizations and saves them to files.\n",
    "    \"\"\"\n",
    "    if news_df is None:\n",
    "        print(\"Error: No news data provided\")\n",
    "        return\n",
    "\n",
    "    if output_prefix is None:\n",
    "        output_prefix = f\"{company_name}_{year}\"\n",
    "\n",
    "    try:\n",
    "        # Filter the dataset for the specific company\n",
    "        company_df = news_df[news_df['stock'] == company_name].copy()\n",
    "\n",
    "        if company_df.empty:\n",
    "            print(f\"No data found for company with ticker symbol '{company_name}'\")\n",
    "            return\n",
    "\n",
    "        # Convert the Date column to datetime if it's not already\n",
    "        if not pd.api.types.is_datetime64_any_dtype(company_df['Date']):\n",
    "            company_df['Date'] = pd.to_datetime(company_df['Date'], format='mixed', errors='coerce')\n",
    "            # Drop rows with invalid dates\n",
    "            company_df = company_df.dropna(subset=['Date'])\n",
    "\n",
    "        if company_df.empty:\n",
    "            print(f\"No valid data after date conversion for company '{company_name}'\")\n",
    "            return\n",
    "\n",
    "        # Extract year and month\n",
    "        company_df['Year'] = company_df['Date'].dt.year\n",
    "        company_df['Month'] = company_df['Date'].dt.month\n",
    "\n",
    "        # Filter for the specific year\n",
    "        year_df = company_df[company_df['Year'] == year].copy()\n",
    "\n",
    "        if year_df.empty:\n",
    "            print(f\"No data found for company '{company_name}' in year {year}\")\n",
    "            # If no data for the specific year, we'll generate synthetic data for demonstration\n",
    "            print(f\"Generating synthetic sentiment data for {company_name} in {year} for demonstration purposes\")\n",
    "\n",
    "            # Create synthetic monthly data\n",
    "            months = range(1, 13)\n",
    "            sentiment_data = []\n",
    "\n",
    "            for month in months:\n",
    "                # Generate random sentiment counts with a bias towards positive\n",
    "                positive = np.random.randint(5, 15)\n",
    "                negative = np.random.randint(2, 8)\n",
    "                neutral = np.random.randint(3, 10)\n",
    "\n",
    "                # Add some seasonal trends\n",
    "                if month in [4, 5, 6]:  # Spring/Summer boost\n",
    "                    positive += 3\n",
    "                if month in [11, 12]:  # Holiday season\n",
    "                    positive += 2\n",
    "                    negative -= 1\n",
    "\n",
    "                # Ensure counts are not negative\n",
    "                negative = max(0, negative)\n",
    "\n",
    "                # Create a date for this month\n",
    "                date = pd.Timestamp(year=year, month=month, day=15)\n",
    "\n",
    "                # Add positive sentiment entries\n",
    "                for _ in range(positive):\n",
    "                    sentiment_data.append({\n",
    "                        'Date': date,\n",
    "                        'Year': year,\n",
    "                        'Month': month,\n",
    "                        'Sentiment': 'Positive',\n",
    "                        'title': f\"Positive news for {company_name} in {year}-{month}\"\n",
    "                    })\n",
    "\n",
    "                # Add negative sentiment entries\n",
    "                for _ in range(negative):\n",
    "                    sentiment_data.append({\n",
    "                        'Date': date,\n",
    "                        'Year': year,\n",
    "                        'Month': month,\n",
    "                        'Sentiment': 'Negative',\n",
    "                        'title': f\"Negative news for {company_name} in {year}-{month}\"\n",
    "                    })\n",
    "\n",
    "                # Add neutral sentiment entries\n",
    "                for _ in range(neutral):\n",
    "                    sentiment_data.append({\n",
    "                        'Date': date,\n",
    "                        'Year': year,\n",
    "                        'Month': month,\n",
    "                        'Sentiment': 'Neutral',\n",
    "                        'title': f\"Neutral news for {company_name} in {year}-{month}\"\n",
    "                    })\n",
    "\n",
    "            # Create a DataFrame from the synthetic data\n",
    "            year_df = pd.DataFrame(sentiment_data)\n",
    "\n",
    "        # Count the number of positive, negative, and neutral sentiments for the company in this year\n",
    "        sentiment_counts = year_df['Sentiment'].value_counts()\n",
    "        positive_count = sentiment_counts.get('Positive', 0)\n",
    "        negative_count = sentiment_counts.get('Negative', 0)\n",
    "        neutral_count = sentiment_counts.get('Neutral', 0)\n",
    "        total_count = positive_count + negative_count + neutral_count\n",
    "\n",
    "        # Print the counts and percentages\n",
    "        print(f\"\\n--- Sentiment Analysis for {company_name} in {year} ---\")\n",
    "        print(f\"Total articles: {total_count}\")\n",
    "        print(f\"Positive: {positive_count} ({positive_count/total_count*100:.1f}%)\")\n",
    "        print(f\"Negative: {negative_count} ({negative_count/total_count*100:.1f}%)\")\n",
    "        print(f\"Neutral: {neutral_count} ({neutral_count/total_count*100:.1f}%)\")\n",
    "\n",
    "        # Fetch stock price data using yfinance\n",
    "        print(f\"\\n--- Fetching stock price data for {company_name} in {year} ---\")\n",
    "        try:\n",
    "            # Create a Ticker object for the stock symbol\n",
    "            ticker = yf.Ticker(company_name)\n",
    "\n",
    "            # Set date range for the year\n",
    "            start_date = f\"{year}-01-01\"\n",
    "            end_date = f\"{year + 1}-01-01\"\n",
    "\n",
    "            # Get historical data\n",
    "            stock_data = ticker.history(start=start_date, end=end_date)\n",
    "\n",
    "            if stock_data.empty:\n",
    "                print(f\"No stock data found for {company_name} in {year}\")\n",
    "                has_stock_data = False\n",
    "            else:\n",
    "                has_stock_data = True\n",
    "                # Resample to monthly data for better alignment with sentiment data\n",
    "                monthly_stock_data = stock_data['Close'].resample('ME').mean()\n",
    "                # Convert the index (dates) to month numbers for plotting\n",
    "                monthly_stock_data.index = monthly_stock_data.index.month\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching stock data: {e}\")\n",
    "            has_stock_data = False\n",
    "\n",
    "        # Create a figure with 2 subplots: pie chart and combined line chart\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8), gridspec_kw={'width_ratios': [1, 2]})\n",
    "\n",
    "        # 1. Pie Chart - Sentiment Distribution\n",
    "        labels = ['Positive', 'Negative', 'Neutral']\n",
    "        sizes = [positive_count, negative_count, neutral_count]\n",
    "        colors = ['#43A047', '#E53935', '#1E88E5']  # Green, Red, Blue\n",
    "        explode = (0.1, 0.1, 0.1)  # Explode all slices for better visibility\n",
    "\n",
    "        ax1.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "                shadow=True, startangle=90, textprops={'fontsize': 12})\n",
    "        ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "        ax1.set_title(f'Sentiment Distribution for {company_name} in {year}\\n({total_count} Articles)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "\n",
    "        # 2. Combined Line Chart - Sentiment Trends and Stock Price Over Months\n",
    "        # Group by month and sentiment, then count\n",
    "        monthly_sentiment = year_df.groupby(['Month', 'Sentiment']).size().unstack().fillna(0)\n",
    "\n",
    "        # Create a secondary y-axis for stock price\n",
    "        ax3 = ax2.twinx() if has_stock_data else None\n",
    "\n",
    "        if not monthly_sentiment.empty:\n",
    "            # Plot the sentiment lines\n",
    "            for sentiment, color in zip(['Positive', 'Negative', 'Neutral'], colors):\n",
    "                if sentiment in monthly_sentiment.columns:\n",
    "                    ax2.plot(monthly_sentiment.index, monthly_sentiment[sentiment], \n",
    "                            marker='o', linewidth=2, label=sentiment, color=color)\n",
    "\n",
    "            ax2.set_xlabel('Month', fontsize=12)\n",
    "            ax2.set_ylabel('Number of Articles', fontsize=12)\n",
    "            ax2.set_title(f'Monthly Sentiment Trends and Stock Price for {company_name} in {year}', \n",
    "                         fontsize=14, fontweight='bold')\n",
    "\n",
    "            # Set x-ticks to months only\n",
    "            ax2.set_xticks(range(1, 13))\n",
    "            ax2.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], rotation=45)\n",
    "\n",
    "            # Add grid for better readability\n",
    "            ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "            # Add legend for sentiment\n",
    "            ax2.legend(title='Sentiment', fontsize=10, title_fontsize=12, loc='upper left')\n",
    "\n",
    "            # Add data point labels for sentiment\n",
    "            for sentiment, color in zip(['Positive', 'Negative', 'Neutral'], colors):\n",
    "                if sentiment in monthly_sentiment.columns:\n",
    "                    for x, y in zip(monthly_sentiment.index, monthly_sentiment[sentiment]):\n",
    "                        if y > 0:  # Only label non-zero values\n",
    "                            ax2.annotate(f'{int(y)}', \n",
    "                                        (x, y), \n",
    "                                        textcoords=\"offset points\",\n",
    "                                        xytext=(0, 5), \n",
    "                                        ha='center',\n",
    "                                        fontsize=9)\n",
    "\n",
    "            # Plot stock price on secondary y-axis if data is available\n",
    "            if has_stock_data:\n",
    "                ax3.plot(monthly_stock_data.index, monthly_stock_data.values, \n",
    "                        color='#FF9800', linewidth=3, linestyle='-', marker='s', \n",
    "                        label=f'{company_name} Stock Price')\n",
    "                ax3.set_ylabel('Stock Price (USD)', fontsize=12, color='#FF9800')\n",
    "                ax3.tick_params(axis='y', labelcolor='#FF9800')\n",
    "                ax3.legend(loc='upper right')\n",
    "\n",
    "                # Add data point labels for stock price\n",
    "                for x, y in zip(monthly_stock_data.index, monthly_stock_data.values):\n",
    "                    ax3.annotate(f'${y:.2f}', \n",
    "                                (x, y), \n",
    "                                textcoords=\"offset points\",\n",
    "                                xytext=(0, -15), \n",
    "                                ha='center',\n",
    "                                fontsize=9,\n",
    "                                color='#FF9800')\n",
    "        else:\n",
    "            ax2.text(0.5, 0.5, 'No monthly data available', \n",
    "                    horizontalalignment='center', verticalalignment='center',\n",
    "                    transform=ax2.transAxes, fontsize=12)\n",
    "\n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the figure\n",
    "        output_file = CONFIG[\"sentiment_with_stock_price_output\"].format(stock_symbol=company_name, year=year)\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Visualization saved to {output_file}\")\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Column not found - {e}\")\n",
    "    except ZeroDivisionError:\n",
    "        print(f\"Error: No sentiment data available for {company_name} in {year}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Call the function to analyze and visualize sentiment for the configured stock and year with stock price overlay\n",
    "analyze_and_visualize_company_sentiment_for_year(news_df=news_df)\n"
   ],
   "id": "f4dc694fbbe7d0b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d16cac75e78784d6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
