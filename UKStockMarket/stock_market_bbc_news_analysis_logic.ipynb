{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ccb797-a8ad-4ba5-8662-d444d47306f6",
   "metadata": {},
   "source": [
    "# Import Package And Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "id": "8794d706-b6ea-40d8-aca9-1f2a931c1070",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:20:36.768815Z",
     "start_time": "2025-07-07T20:20:36.767032Z"
    }
   },
   "source": [
    "# !pip install requests\n",
    "# !pip install pandas\n",
    "# !pip install beautifulsoup4\n",
    "# !pip install --upgrade yfinance\n",
    "# !pip install nltk\n",
    "# !pip install spacy\n",
    "# !pip install matplotlib\n",
    "# !pip install wordcloud\n",
    "# !pip install vaderSentiment\n",
    "# !pip install -U textblob"
   ],
   "outputs": [],
   "execution_count": 118
  },
  {
   "cell_type": "code",
   "id": "045f4880-f9f3-45ab-abd4-6d331c85e232",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:20:36.781551Z",
     "start_time": "2025-07-07T20:20:36.780013Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import json\n",
    "import re"
   ],
   "outputs": [],
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "id": "cefa3c41-a375-4c23-84e2-49d79c244f08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:20:36.790086Z",
     "start_time": "2025-07-07T20:20:36.788360Z"
    }
   },
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ],
   "outputs": [],
   "execution_count": 120
  },
  {
   "cell_type": "markdown",
   "id": "d9702460-2bf4-47cd-aa70-c42a0fec50f3",
   "metadata": {},
   "source": [
    "# Load DATASET into Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "id": "2bf6c7af-146a-439d-b552-66576c34d4f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:20:36.798088Z",
     "start_time": "2025-07-07T20:20:36.796575Z"
    }
   },
   "source": "# https://www.kaggle.com/code/gpreda/bbc-news-rss-feeds?scriptVersionId=211092399",
   "outputs": [],
   "execution_count": 121
  },
  {
   "cell_type": "code",
   "id": "10dfd0bf-5258-47d4-a301-a3e089a087f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:20:36.806165Z",
     "start_time": "2025-07-07T20:20:36.804281Z"
    }
   },
   "source": [
    "def save_dataframe(df: pd.DataFrame, file_path: str = 'bbc_news_updated.csv',) -> None:\n",
    "    try:\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"News DataFrame saved to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Failed to save news DataFrame: {e}\")"
   ],
   "outputs": [],
   "execution_count": 122
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load SpaCy Model",
   "id": "f71ca5eef195eca2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:20:37.114075Z",
     "start_time": "2025-07-07T20:20:36.812457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "except OSError:\n",
    "    print(\"Spacy model 'en_core_web_sm' not found. Please run:\")\n",
    "    print(\"python -m spacy download en_core_web_sm\")\n",
    "    exit()"
   ],
   "id": "ecf5e07603feb5af",
   "outputs": [],
   "execution_count": 123
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Data",
   "id": "d6c1679faeb267df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:20:37.211396Z",
     "start_time": "2025-07-07T20:20:37.122508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    df = pd.read_csv('bbc_news_updated.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"The file 'bbc_news_updated.csv' was not found.\")\n",
    "    exit()"
   ],
   "id": "7dd197c41f973daa",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extract Company Names",
   "id": "abeb670b2f376095"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:20:37.221124Z",
     "start_time": "2025-07-07T20:20:37.218812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_company_names(text):\n",
    "    \"\"\"\n",
    "    Extracts company names (entities with label 'ORG') from a given text.\n",
    "    \"\"\"\n",
    "    # Process the text with Spacy\n",
    "    doc = nlp(text)\n",
    "    # Extract entities labeled as 'ORG' (Organization)\n",
    "    companies = [ent.text for ent in doc.ents if ent.label_ == 'ORG']\n",
    "    # Return a comma-separated string of unique company names\n",
    "    return \", \".join(list(set(companies)))"
   ],
   "id": "9be22e5489930bf8",
   "outputs": [],
   "execution_count": 125
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load / Save Company Data into JSON",
   "id": "e74c5a78b7f2deb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:20:37.230154Z",
     "start_time": "2025-07-07T20:20:37.228149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_company_search_history(file_path: str = 'company_date.json') -> dict:\n",
    "    try:\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            return json.load(json_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Failed to load company search history: {e}\")\n",
    "        return {}"
   ],
   "id": "2d5b32cd2a2043a3",
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:20:37.239001Z",
     "start_time": "2025-07-07T20:20:37.236882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_company_search_history(file_path: str = 'company_date.json') -> None:\n",
    "    \"\"\"\n",
    "    Saves the company search history to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the JSON file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'w') as json_file:\n",
    "            json.dump(company_search_history, json_file, indent=4)\n",
    "        print(f\"Company search history saved to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Failed to save company search history: {e}\")"
   ],
   "id": "a473e7031379e1f0",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:20:37.247595Z",
     "start_time": "2025-07-07T20:20:37.245274Z"
    }
   },
   "cell_type": "code",
   "source": "company_search_history = load_company_search_history()",
   "id": "5ea412ab0dae4111",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Failed to load company search history: [Errno 2] No such file or directory: 'company_date.json'\n"
     ]
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get Stock Symbol",
   "id": "a25eab23c2aaec9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:20:37.260858Z",
     "start_time": "2025-07-07T20:20:37.257891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_random_user_agent() -> str:\n",
    "    \"\"\"\n",
    "    Generates a random User-Agent string.\n",
    "\n",
    "    Returns:\n",
    "        str: A random User-Agent string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Common OS and browser combinations. Expand this list as needed.\n",
    "    os_list = [\n",
    "        (\"Windows NT 10.0; Win64; x64\", \"Windows\"),\n",
    "        (\"Macintosh; Intel Mac OS X 10_15_7\", \"Mac\"),\n",
    "        (\"X11; Linux x86_64\", \"Linux\"),\n",
    "        (\"X11; Ubuntu; Linux x86_64\", \"Ubuntu\"),\n",
    "        (\"X11; CrOS x86_64 14541.0.0\", \"ChromeOS\"),\n",
    "        (\"iPhone; CPU iPhone OS 16_0 like Mac OS X\", \"iOS\"),\n",
    "        (\"Android 10; Mobile\", \"Android\"),\n",
    "    ]\n",
    "\n",
    "    browser_list = [\n",
    "        (\"Chrome\", \"Chrome/{major_version}.{minor_version}.{build_version}.{patch_version} Safari/537.36\"),\n",
    "        (\"Firefox\", \"Firefox/{major_version}.{minor_version}\"),\n",
    "        (\"Safari\", \"Version/{major_version}.0 Safari/605.1.15\"),\n",
    "        (\"Edge\", \"Edg/{major_version}.{minor_version}.{build_version}.{patch_version}\"),\n",
    "        (\"Opera\", \"Opera/{major_version}.0 (Windows NT 10.0; Win64; x64) Presto/2.12.388 Version/12.16\"),\n",
    "    ]\n",
    "\n",
    "    os_info = random.choice(os_list)\n",
    "    browser_info = random.choice(browser_list)\n",
    "\n",
    "    os_string = os_info[0]\n",
    "    browser_name = browser_info[0]\n",
    "    browser_version_template = browser_info[1]\n",
    "\n",
    "    # Generate random version numbers.\n",
    "    major_version = random.randint(70, 115)  # Adjust range as needed\n",
    "    minor_version = random.randint(0, 9999)\n",
    "    build_version = random.randint(0, 9999)\n",
    "    patch_version = random.randint(0, 999)\n",
    "\n",
    "    # Format the browser version string\n",
    "    if browser_name == \"Safari\":\n",
    "        safari_major = random.randint(10, 16)\n",
    "        browser_version = browser_version_template.format(major_version=safari_major)\n",
    "    elif browser_name == \"Opera\":\n",
    "        browser_version = browser_version_template.format(major_version=major_version)\n",
    "    else:\n",
    "        browser_version = browser_version_template.format(\n",
    "            major_version=major_version,\n",
    "            minor_version=minor_version,\n",
    "            build_version=build_version,\n",
    "            patch_version=patch_version\n",
    "        )\n",
    "\n",
    "    user_agent = f\"Mozilla/5.0 ({os_string}) AppleWebKit/537.36 (KHTML, like Gecko) {browser_version}\"\n",
    "\n",
    "    return user_agent"
   ],
   "id": "93ca9344a0361c9",
   "outputs": [],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:20:37.271225Z",
     "start_time": "2025-07-07T20:20:37.268079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Api Count used to logging purpose to undertand how many times yahoo finance api is called\n",
    "api_count = 0\n",
    "\n",
    "max_try = 3\n",
    "\n",
    "def get_ticker(company_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves the ticker symbol for a given company name.\n",
    "\n",
    "    Args:\n",
    "        company_name (str): The name of the company.\n",
    "\n",
    "    Returns:\n",
    "        str: The ticker symbol for the company, or an empty string if not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        global max_try\n",
    "        # Check if the company name is already in the search history\n",
    "        if company_name in company_search_history:\n",
    "            return company_search_history[company_name]\n",
    "\n",
    "        # Set up the API request\n",
    "        yfinance_url = \"https://query2.finance.yahoo.com/v1/finance/search\"\n",
    "        user_agent = generate_random_user_agent()\n",
    "        params = {\n",
    "            \"q\": company_name,\n",
    "            \"quotes_count\": 1,\n",
    "            \"country\": \"United Kingdom\"\n",
    "        }\n",
    "\n",
    "        print(f\"Searching for: {params}\")\n",
    "\n",
    "        # Send the API request\n",
    "        response = requests.get(url=yfinance_url, params=params, headers={\"User-Agent\": user_agent})\n",
    "\n",
    "        # Check if the response was successful\n",
    "        if response.status_code != 200:\n",
    "            if max_try == 0:\n",
    "                print(f\"Max Try Reached: {params}\")\n",
    "                return \"\"\n",
    "            max_try -= 1\n",
    "            print(f\"Failed to retrieve data: {response.status_code}\")\n",
    "            time.sleep(10)  # Wait 10 seconds before retrying\n",
    "            return get_ticker(company_name)  # Retry the request\n",
    "\n",
    "        # Parse the response data\n",
    "        data = response.json()\n",
    "\n",
    "        # Reset Max Try\n",
    "        max_try = 3\n",
    "        # Increment the API count\n",
    "        global api_count\n",
    "        api_count += 1\n",
    "\n",
    "        # Add a delay to avoid overwhelming the API, and timeout error from api\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Check if the company was found\n",
    "        if data[\"quotes\"]:\n",
    "            company_code = data[\"quotes\"][0][\"symbol\"]\n",
    "            company_search_history[company_name] = company_code\n",
    "            return company_code\n",
    "        else:\n",
    "            company_search_history[company_name] = \"\"\n",
    "            return \"\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An exception occurred: {e}\")\n",
    "        time.sleep(10)  # Wait 10 seconds before retrying\n",
    "        return get_ticker(company_name)  # Retry the request"
   ],
   "id": "4ce04149cf0543f5",
   "outputs": [],
   "execution_count": 130
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Validate Company Name",
   "id": "cd830658696c8a52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:20:37.281027Z",
     "start_time": "2025-07-07T20:20:37.278709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_and_validate_companies(row):\n",
    "    \"\"\"\n",
    "    Processes a row of the DataFrame, validates company names,\n",
    "    and finds their stock symbols.\n",
    "    \"\"\"\n",
    "    # Get the string of company names and split it into a list\n",
    "    original_companies = str(row['company_name']).split(', ')\n",
    "\n",
    "    validated_companies = []\n",
    "    stock_symbols = []\n",
    "\n",
    "    for company in original_companies:\n",
    "        # Clean up the company name\n",
    "        company = company.strip()\n",
    "        if company:\n",
    "            # In a real application, you would call a search API here\n",
    "            global max_try\n",
    "            max_try = 3\n",
    "            symbol = get_ticker(company)\n",
    "\n",
    "            if symbol:\n",
    "                validated_companies.append(company)\n",
    "                stock_symbols.append(symbol)\n",
    "\n",
    "    # Return as comma-separated strings\n",
    "    return \", \".join(validated_companies), \", \".join(stock_symbols)"
   ],
   "id": "8c592b3c0bf3034c",
   "outputs": [],
   "execution_count": 131
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get Sentiment",
   "id": "2fa3538f74f436d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:20:37.290116Z",
     "start_time": "2025-07-07T20:20:37.288013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def get_sentiment(text):\n",
    "    \"\"\"\n",
    "    Analyzes the sentiment of a given text and returns 'positive', 'negative', or 'neutral'.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return 'neutral', 0.0\n",
    "\n",
    "    # Create a TextBlob object\n",
    "    blob = TextBlob(text)\n",
    "    # Get the polarity score\n",
    "    polarity = blob.sentiment.polarity\n",
    "    # Classify the sentiment\n",
    "    if polarity > 0:\n",
    "        sentiment = 'positive'\n",
    "    elif polarity < 0:\n",
    "        sentiment = 'negative'\n",
    "    else:\n",
    "        sentiment = 'neutral'\n",
    "    return sentiment, polarity"
   ],
   "id": "1246e533d88955fa",
   "outputs": [],
   "execution_count": 132
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Apply Function To Data Frame",
   "id": "40c4822fa3d922fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:32:45.785880Z",
     "start_time": "2025-07-07T20:20:37.296777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ensure 'full_description' column exists and handle potential missing values\n",
    "df = df.iloc[:10,:]\n",
    "\n",
    "if 'full_description' in df.columns:\n",
    "    df['full_description'] = df['full_description'].astype(str) # Ensure all values are strings\n",
    "    df['company_name'] = df['full_description'].apply(get_company_names)\n",
    "    df[['validated_companies', 'stock_symbols']] = df.apply(find_and_validate_companies, axis=1, result_type='expand')\n",
    "    sentiment_results = df['full_description'].apply(get_sentiment)\n",
    "    df['news_sentiment'] = sentiment_results.apply(lambda x: x[0])\n",
    "    df['sentiment_score'] = sentiment_results.apply(lambda x: x[1])\n",
    "else:\n",
    "    print(\"The 'full_description' column was not found in the CSV file.\")\n",
    "    exit()"
   ],
   "id": "7bd4706017d8f4d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for: {'q': 'Yara', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Yara', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Yara', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Yara', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Max Try Reached: {'q': 'Yara', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'EXPLAINED', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'EXPLAINED', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Yara International', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Yara International', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Yara International', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Yara International', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'BBC', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Nutrients', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Nutrients', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Fears of UK', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Fears of UK', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Fears of UK', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Fears of UK', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'the White House', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'EU', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'FTSE', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Dow Jones', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'AA', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'AA', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'AA', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'AA', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Max Try Reached: {'q': 'AA', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Dow', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Dow', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Dow', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Dow', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Shell', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Shell', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Shell', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Portland Fuel', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Portland Fuel', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Netflix', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Netflix', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Netflix', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'State', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Visa', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'giantShell', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'giantShell', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Mastercard', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Mastercard', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Olaf Scholz', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Olaf Scholz', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Olaf Scholz', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Olaf Scholz', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Max Try Reached: {'q': 'Olaf Scholz', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'American Express', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'American Express', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Meta', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Kremlin', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Kremlin', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Kremlin', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Kremlin', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Max Try Reached: {'q': 'Kremlin', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Apple', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Apple', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Apple', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Variety', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Variety', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Variety', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Variety', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Max Try Reached: {'q': 'Variety', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Facebook and Instagram', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'H&M', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'H&M', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'H&M', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'TikTok', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'PricewaterhouseCoopers LLP', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'KPMG', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'KPMG', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'KPMG', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'KPMG', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Max Try Reached: {'q': 'KPMG', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Volkswagen', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Volkswagen', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Toyota', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Toyota', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'the US Federal Reserve', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'the Bank of England', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'the Bank of England', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'the Bank of England', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'the Bank of England', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Max Try Reached: {'q': 'the Bank of England', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Widespread', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'LME', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'the London Metals Exchange', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'the London Metals Exchange', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'the London Metals Exchange', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'the London Metals Exchange', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Stellantis', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Stellantis', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': \"the Bank of England's\", 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': \"the Bank of England's\", 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'AA', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'Olaf Scholz', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Olaf Scholz', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Olaf Scholz', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n",
      "Searching for: {'q': 'Olaf Scholz', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Searching for: {'q': 'the Bank of England', 'quotes_count': 1, 'country': 'United Kingdom'}\n",
      "Failed to retrieve data: 429\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[133], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfull_description\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfull_description\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mstr\u001B[39m) \u001B[38;5;66;03m# Ensure all values are strings\u001B[39;00m\n\u001B[1;32m      6\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcompany_name\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfull_description\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(get_company_names)\n\u001B[0;32m----> 7\u001B[0m df[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalidated_companies\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstock_symbols\u001B[39m\u001B[38;5;124m'\u001B[39m]] \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mapply(find_and_validate_companies, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, result_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexpand\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      8\u001B[0m sentiment_results \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfull_description\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(get_sentiment)\n\u001B[1;32m      9\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnews_sentiment\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m sentiment_results\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: x[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:10374\u001B[0m, in \u001B[0;36mDataFrame.apply\u001B[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001B[0m\n\u001B[1;32m  10360\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapply\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m frame_apply\n\u001B[1;32m  10362\u001B[0m op \u001B[38;5;241m=\u001B[39m frame_apply(\n\u001B[1;32m  10363\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m  10364\u001B[0m     func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m  10372\u001B[0m     kwargs\u001B[38;5;241m=\u001B[39mkwargs,\n\u001B[1;32m  10373\u001B[0m )\n\u001B[0;32m> 10374\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m op\u001B[38;5;241m.\u001B[39mapply()\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapply\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:916\u001B[0m, in \u001B[0;36mFrameApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    913\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw:\n\u001B[1;32m    914\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_raw(engine\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine, engine_kwargs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine_kwargs)\n\u001B[0;32m--> 916\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_standard()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1063\u001B[0m, in \u001B[0;36mFrameApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1061\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_standard\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m   1062\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpython\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m-> 1063\u001B[0m         results, res_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_series_generator()\n\u001B[1;32m   1064\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1065\u001B[0m         results, res_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_series_numba()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1081\u001B[0m, in \u001B[0;36mFrameApply.apply_series_generator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1078\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m option_context(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode.chained_assignment\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   1079\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(series_gen):\n\u001B[1;32m   1080\u001B[0m         \u001B[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001B[39;00m\n\u001B[0;32m-> 1081\u001B[0m         results[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc(v, \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwargs)\n\u001B[1;32m   1082\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(results[i], ABCSeries):\n\u001B[1;32m   1083\u001B[0m             \u001B[38;5;66;03m# If we have a view on v, we need to make a copy because\u001B[39;00m\n\u001B[1;32m   1084\u001B[0m             \u001B[38;5;66;03m#  series_generator will swap out the underlying data\u001B[39;00m\n\u001B[1;32m   1085\u001B[0m             results[i] \u001B[38;5;241m=\u001B[39m results[i]\u001B[38;5;241m.\u001B[39mcopy(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Cell \u001B[0;32mIn[131], line 19\u001B[0m, in \u001B[0;36mfind_and_validate_companies\u001B[0;34m(row)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mglobal\u001B[39;00m max_try\n\u001B[1;32m     18\u001B[0m max_try \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m\n\u001B[0;32m---> 19\u001B[0m symbol \u001B[38;5;241m=\u001B[39m get_ticker(company)\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m symbol:\n\u001B[1;32m     22\u001B[0m     validated_companies\u001B[38;5;241m.\u001B[39mappend(company)\n",
      "Cell \u001B[0;32mIn[130], line 43\u001B[0m, in \u001B[0;36mget_ticker\u001B[0;34m(company_name)\u001B[0m\n\u001B[1;32m     41\u001B[0m     max_try \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to retrieve data: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 43\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m10\u001B[39m)  \u001B[38;5;66;03m# Wait 10 seconds before retrying\u001B[39;00m\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m get_ticker(company_name)  \u001B[38;5;66;03m# Retry the request\u001B[39;00m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;66;03m# Parse the response data\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Save CSV",
   "id": "6a13112974def88c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:32:45.799565Z",
     "start_time": "2025-07-07T19:45:53.900680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 6: Save the new DataFrame to a CSV file\n",
    "output_filename = 'bbc_news_with_sentiment_and_companies.csv'\n",
    "save_dataframe(df, output_filename)"
   ],
   "id": "f3fed6be0c0227c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News DataFrame saved to bbc_news_with_sentiment_and_companies.csv\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:32:45.814839Z",
     "start_time": "2025-07-07T19:45:53.928422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Successfully processed the data and saved it to '{output_filename}'\")\n",
    "print(\"\\nHere are the first 5 rows of the updated data with company names and sentiment:\")\n",
    "print(df[['title', 'company_name', 'news_sentiment']].head())"
   ],
   "id": "a4a33fc7a3f5d071",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed the data and saved it to 'bbc_news_with_sentiment_and_companies.csv'\n",
      "\n",
      "Here are the first 5 rows of the updated data with company names and sentiment:\n",
      "                                               title                                       company_name news_sentiment\n",
      "0         Ukraine war 'catastrophic for global food'  Yara, EXPLAINED, Yara International, BBC, Nutr...       positive\n",
      "1  Ukraine conflict: Oil price soars to highest l...  EXPLAINED, the White House, EU, BBC, FTSE, Dow...       positive\n",
      "2  TikTok limits services as Netflix pulls out of...  American Express, EXPLAINED, Meta, BBC, Kremli...       negative\n",
      "3     Five ways the Ukraine war could push up prices  Volkswagen, Toyota, the US Federal Reserve, EU...       negative\n",
      "4  The sophisticated tech predicting if an advert...                                                           neutral\n"
     ]
    }
   ],
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
