{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Stock Price Prediction with Sentiment Analysis",
   "id": "24165cb5f142b848"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# %%time\n",
    "# !pip install charset-normalizer pandas_ta yfinance statsmodels tqdm scikit-learn tensorflow"
   ],
   "id": "633dfb4d4df73ccd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# To reload the imported modules automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "869d673cc31e2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# Import the necessary libraries and modules\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Import modules\n",
    "import config as cfg\n",
    "import data_processing as dp\n",
    "import sentiment_analysis as sa\n",
    "import model as mdl\n",
    "import utils as ut\n",
    "import time\n",
    "import keras_tuner as kt\n",
    "from tqdm import tqdm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import pandas_datareader.data as web"
   ],
   "id": "a9c4a3f610ba7a09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "os.makedirs(cfg.DATASET_DIR, exist_ok=True)\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ],
   "id": "ee296d4792db4f4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        # Set memory growth to be the same for all GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "        logical_gpus = tf.config.list_logical_devices(\"GPU\")\n",
    "        print(\n",
    "            f\"✅ {len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs configured with memory growth.\"\n",
    "        )\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(f\"Error setting memory growth: {e}\")\n",
    "else:\n",
    "    print(\"🤷 No GPU detected. TensorFlow will run on CPU.\")"
   ],
   "id": "fc22f2ef730def9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load and Analyze News Data",
   "id": "39e06cd6c56a89c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "sentiment_csv_path = f\"{cfg.DATASET_DIR}/{cfg.STOCK_SYMBOL}_daily_sentiment.csv\"\n",
    "\n",
    "if cfg.UPDATE_SENTIMENT_CSV or not os.path.exists(sentiment_csv_path):\n",
    "    print(\"Generating new sentiment data and saving to CSV...\")\n",
    "    news_df = dp.load_and_analyze_news_data(cfg.NEWS_DATA_FILE, cfg.STOCK_SYMBOL)\n",
    "    company_sentiment_df = sa.process_news_sentiment(news_df, cfg.STOCK_SYMBOL)\n",
    "    daily_sentiment_df = sa.aggregate_daily_sentiment(company_sentiment_df)\n",
    "    ut.save_dataframe(daily_sentiment_df, sentiment_csv_path)\n",
    "else:\n",
    "    print(f\"Loading existing sentiment data from {sentiment_csv_path}...\")\n",
    "    daily_sentiment_df = pd.read_csv(\n",
    "        sentiment_csv_path, index_col=\"Date\", parse_dates=True\n",
    "    )\n",
    "\n",
    "print(\"Sentiment data ready.\")"
   ],
   "id": "c230321709e7c2dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Fetch Stock Data and Calculate Technical Indicators",
   "id": "89798ad36fff0bb0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "START_DATE, END_DATE = ut.calculate_dynamic_date_range(daily_sentiment_df)\n",
    "\n",
    "stock_filename = f\"{cfg.STOCK_SYMBOL}_stock_data_{START_DATE}_to_{END_DATE}.csv\"\n",
    "stock_csv_path = os.path.join(cfg.DATASET_DIR, stock_filename)\n",
    "\n",
    "if cfg.UPDATE_STOCK_CSV or not os.path.exists(stock_csv_path):\n",
    "    print(f\"Fetching new stock data from yfinance ({START_DATE} to {END_DATE})...\")\n",
    "    stock_data = dp.fetch_stock_data(cfg.STOCK_SYMBOL, START_DATE, END_DATE)\n",
    "    if stock_data is not None:\n",
    "        stock_data.to_csv(stock_csv_path)\n",
    "        print(f\"Stock data saved to {stock_csv_path}\")\n",
    "else:\n",
    "    print(f\"Loading existing stock data from {stock_csv_path}...\")\n",
    "    stock_data = pd.read_csv(stock_csv_path, index_col=\"Date\", parse_dates=True)\n",
    "    stock_data.index = stock_data.index.tz_localize(\"UTC\")\n",
    "\n",
    "if stock_data.index.tz is None:\n",
    "    # If index is naive (from CSV), localize it to UTC\n",
    "    print(\"Localizing naive index to UTC...\")\n",
    "    stock_data.index = stock_data.index.tz_localize(\"UTC\")\n",
    "else:\n",
    "    # If index is already aware (from yfinance), convert it to UTC\n",
    "    print(\"Converting timezone-aware index to UTC...\")\n",
    "    stock_data.index = stock_data.index.tz_convert(\"UTC\")"
   ],
   "id": "458744d744fbeab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Add Return Column (Percentage Change)",
   "id": "aa560d106fefec3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# Calculate daily returns, which will be our new target variable\n",
    "print(\"--- Calculating Daily Returns ---\")\n",
    "stock_data[\"Returns\"] = stock_data[\"Close\"].pct_change()\n",
    "tech_data = stock_data.dropna()  # Drop the first row which will have a NaN return\n",
    "print(\"'Returns' column created.\")"
   ],
   "id": "e852cd2b64b45d8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prepare data for the Baseline model",
   "id": "b21ab89f015dd29b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# Prepare data for the Baseline model\n",
    "X_train_base, X_test_base, y_train_base, y_test_base, scaler_base = (\n",
    "    mdl.prepare_data_for_lstm(\n",
    "        tech_data,\n",
    "        cfg.BASELINE_FEATURES,\n",
    "        cfg.BASELINE_TARGET,\n",
    "        cfg.SEQUENCE_LENGTH,\n",
    "        cfg.TEST_SIZE,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Baseline data shapes: X_train={X_train_base.shape}, y_train={y_train_base.shape}, X_test={X_test_base.shape}, y_test={y_test_base.shape}\"\n",
    ")"
   ],
   "id": "46a25ad24d24e99c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Macroeconomic Data from FRED",
   "id": "46b45e0dce3d0777"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "if stock_data is not None:\n",
    "    print(\"\\n--- Fetching and Merging Macroeconomic Data ---\")\n",
    "\n",
    "    # Define the FRED series codes and their new column names\n",
    "    fred_series = {\n",
    "        \"CPIAUCSL\": \"Inflation_CPI\",\n",
    "        \"FEDFUNDS\": \"Interest_Rate\",\n",
    "        \"UNRATE\": \"Unemployment_Rate\",\n",
    "    }\n",
    "\n",
    "    # Fetch the data from FRED\n",
    "    macro_data = web.DataReader(list(fred_series.keys()), \"fred\", START_DATE, END_DATE)\n",
    "    macro_data = macro_data.rename(columns=fred_series)\n",
    "\n",
    "    stock_data.index = stock_data.index.tz_localize(None)\n",
    "\n",
    "    # Forward-fill the macroeconomic data, as it's released monthly and is assumed\n",
    "    # to be constant until the next release period.\n",
    "    macro_data_daily = macro_data.reindex(stock_data.index, method=\"ffill\")\n",
    "\n",
    "    # Merge the data\n",
    "    stock_data = stock_data.join(macro_data_daily)\n",
    "\n",
    "    # Fill any NaNs at the beginning\n",
    "    stock_data.bfill(inplace=True)\n",
    "    print(\"Macroeconomic features merged successfully.\")"
   ],
   "id": "a52598f78c3c2ac0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate technical indicators from the loaded/fetched data\n",
    "tech_data = dp.calculate_technical_indicators(stock_data)\n",
    "print(\"Technical indicators calculated.\")"
   ],
   "id": "78640f7be84104f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### VIX (Volatility Index) Data",
   "id": "7597fed0f2b1e597"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Add VIX (Volatility Index) Data\n",
    "print(\"--- Applying Final Fix: Normalizing Dates ---\")\n",
    "try:\n",
    "    # 1. Standardize tech_data index to UTC\n",
    "    if tech_data.index.tz is None:\n",
    "        tech_data.index = tech_data.index.tz_localize(\"UTC\")\n",
    "    else:\n",
    "        tech_data.index = tech_data.index.tz_convert(\"UTC\")\n",
    "\n",
    "    # 2. Standardize VIX data index to UTC\n",
    "    vix_data = yf.Ticker(\"^VIX\").history(start=START_DATE, end=END_DATE)\n",
    "    vix_data.index = vix_data.index.tz_convert(\"UTC\")\n",
    "\n",
    "    # --- NEW FIX: NORMALIZE BOTH INDEXES TO MIDNIGHT ---\n",
    "    print(\"\\nNormalizing indexes to match on date alone...\")\n",
    "    tech_data.index = tech_data.index.normalize()\n",
    "    vix_data.index = vix_data.index.normalize()\n",
    "    print(f\"-> Normalized tech_data index starts: {tech_data.index[0]}\")\n",
    "    print(f\"-> Normalized VIX index starts:    {vix_data.index[0]}\")\n",
    "\n",
    "    # 3. Perform the join on the normalized indexes\n",
    "    print(\"\\nJoining dataframes...\")\n",
    "    vix_close = vix_data[[\"Close\"]].rename(columns={\"Close\": \"VIX_Close\"})\n",
    "    tech_data = tech_data.join(vix_close)\n",
    "\n",
    "    # 4. Check the result\n",
    "    nan_count = tech_data[\"VIX_Close\"].isna().sum()\n",
    "    total_count = len(tech_data)\n",
    "    print(\n",
    "        f\"\\nAfter join, VIX_Close has {nan_count} NaN values out of {total_count} rows.\"\n",
    "    )\n",
    "\n",
    "    if nan_count == total_count:\n",
    "        print(\"-> WARNING: Join still resulted in all NaN values.\")\n",
    "    else:\n",
    "        print(\"-> SUCCESS: Join completed with matching dates.\")\n",
    "\n",
    "    # Fill any remaining NaNs (from non-trading days)\n",
    "    tech_data.ffill(inplace=True)\n",
    "    tech_data.bfill(inplace=True)\n",
    "\n",
    "    print(\"\\n--- VIX Feature Added Successfully ---\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n--- AN ERROR OCCURRED ---\")\n",
    "    import traceback\n",
    "\n",
    "    traceback.print_exc()"
   ],
   "id": "fede162c81742d4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T20:33:19.191407Z",
     "start_time": "2025-07-30T20:33:19.106983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "print(\"--- Checking for Stationarity of the 'Returns' ---\")\n",
    "\n",
    "adf_result = adfuller(tech_data[\"Returns\"])\n",
    "\n",
    "print(f\"ADF Statistic: {adf_result[0]}\")\n",
    "print(f\"p-value: {adf_result[1]}\")\n",
    "\n",
    "if adf_result[1] > 0.05:\n",
    "    print(\n",
    "        \"Result: The 'Returns' price series is likely non-stationary (p-value > 0.05)\"\n",
    "    )\n",
    "else:\n",
    "    print(\"Result: The 'Returns' price series is likely stationary (p-value <= 0.05)\")"
   ],
   "id": "b5d048c21fed0a08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Checking for Stationarity of the 'Returns' ---\n",
      "ADF Statistic: -15.45735169698088\n",
      "p-value: 2.7342391548873083e-28\n",
      "Result: The 'Returns' price series is likely stationary (p-value <= 0.05)\n",
      "CPU times: user 32.2 ms, sys: 10.4 ms, total: 42.5 ms\n",
      "Wall time: 43.5 ms\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ut.save_dataframe(\n",
    "    tech_data, f\"{cfg.OUTPUT_DIR}/\" + cfg.STOCK_SYMBOL + \"_technical_indicators.csv\"\n",
    ")"
   ],
   "id": "b3b187f761c182c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prepare Data for LSTM & SVM Models",
   "id": "3e9a3eaaf9f6d2ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# Prepare data for models using only technical indicators\n",
    "X_train_tech, X_test_tech, y_train_tech, y_test_tech, scaler_tech = (\n",
    "    mdl.prepare_data_for_lstm(\n",
    "        tech_data,\n",
    "        cfg.TECHNICAL_FEATURES,\n",
    "        cfg.TECHNICAL_TARGET,\n",
    "        cfg.SEQUENCE_LENGTH,\n",
    "        cfg.TEST_SIZE,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Prepare data for models using sentiment + technical indicators\n",
    "enhanced_full_data = dp.create_enhanced_dataset(tech_data, daily_sentiment_df)\n",
    "X_train_enh, X_test_enh, y_train_enh, y_test_enh, scaler_enh = (\n",
    "    mdl.prepare_data_for_lstm(\n",
    "        enhanced_full_data,\n",
    "        cfg.HYBRID_FEATURES,\n",
    "        cfg.HYBRID_TARGET,\n",
    "        cfg.SEQUENCE_LENGTH,\n",
    "        cfg.TEST_SIZE,\n",
    "    )\n",
    ")"
   ],
   "id": "7491b5608b8ec297",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Single Layer Baseline LSTM Model",
   "id": "1d9d699bdc06d0a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "print(\"\\n--- Tuning Baseline Single-Layer LSTM Model ---\")\n",
    "\n",
    "# Define the input shape from your baseline training data\n",
    "input_shape_base = (X_train_base.shape[1], X_train_base.shape[2])\n",
    "\n",
    "# Instantiate the tuner for the baseline model\n",
    "tuner_baseline_lstm = kt.Hyperband(\n",
    "    hypermodel=lambda hp: mdl.build_single_layer_lstm(hp, input_shape=input_shape_base),\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory=\"tuner_results\",\n",
    "    project_name=\"baseline_single_layer_lstm\",  # Use a new project name\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "# Define a callback to stop training early\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "# Run the hyperparameter search on the baseline data\n",
    "print(\"Starting hyperparameter search for the baseline model...\")\n",
    "tuner_baseline_lstm.search(\n",
    "    X_train_base,\n",
    "    y_train_base,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[stop_early],\n",
    "    verbose=2,\n",
    ")\n",
    "print(\"\\nBaseline hyperparameter search complete.\")\n",
    "\n",
    "# Get the optimal hyperparameters and the best model for the baseline\n",
    "best_hps_baseline_lstm = tuner_baseline_lstm.get_best_hyperparameters(num_trials=1)[0]\n",
    "baseline_lstm_model = tuner_baseline_lstm.get_best_models(num_models=1)[0]\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "---\n",
    "Optimal Hyperparameters for Baseline Single-Layer LSTM:\n",
    "Units: {best_hps_baseline_lstm.get('units')}\n",
    "Dropout: {best_hps_baseline_lstm.get('dropout'):.2f}\n",
    "Learning Rate: {best_hps_baseline_lstm.get('learning_rate')}\n",
    "---\n",
    "\"\"\"\n",
    ")"
   ],
   "id": "e0653d68c9abdf48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- Evaluation ---\n",
    "print(\"\\n--- Evaluating Tuned Baseline LSTM Model ---\")\n",
    "\n",
    "# Generate predictions on the baseline test set\n",
    "baseline_preds = baseline_lstm_model.predict(X_test_base, verbose=0)\n",
    "\n",
    "# --- Correct way to inverse scale the predictions ---\n",
    "# 1. Create a new scaler for the single target column ('Returns')\n",
    "target_scaler = MinMaxScaler()\n",
    "\n",
    "# 2. Fit it ONLY on the 'Returns' column of the TRAINING data\n",
    "#    We use 'tech_data' as it's the source DataFrame before splitting.\n",
    "train_data_len = len(tech_data) - len(y_test_base)\n",
    "target_scaler.fit(tech_data[[\"Returns\"]][:train_data_len])\n",
    "\n",
    "# 3. Now, inverse transform using the correctly fitted scaler\n",
    "y_test_base_scaled = target_scaler.inverse_transform(y_test_base.reshape(-1, 1))\n",
    "baseline_preds_scaled = target_scaler.inverse_transform(baseline_preds)\n",
    "\n",
    "\n",
    "# Calculate and print the performance metrics\n",
    "baseline_lstm_metrics = ut.calculate_metrics(\n",
    "    y_test_base_scaled, baseline_preds_scaled, \"Baseline LSTM\", y_train_base\n",
    ")\n",
    "print(baseline_lstm_metrics)\n",
    "\n",
    "\n",
    "# Plot the prediction results against the actual values\n",
    "test_dates_base = tech_data.index[-len(y_test_base_scaled) :]\n",
    "ut.plot_non_keras_results(\n",
    "    y_test_base_scaled,\n",
    "    baseline_preds_scaled,\n",
    "    test_dates_base,\n",
    "    cfg.STOCK_SYMBOL,\n",
    "    \"Baseline LSTM\",\n",
    ")"
   ],
   "id": "2b211c583fb6fd50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Single Layer Technical LSTM Model",
   "id": "2d462adaea8d5c81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "print(\"\\n--- Tuning Single-Layer Technical LSTM Model ---\")\n",
    "\n",
    "# Define the input shape from your technical training data\n",
    "input_shape_tech = (X_train_tech.shape[1], X_train_tech.shape[2])\n",
    "\n",
    "# Instantiate the tuner for the technical model\n",
    "tuner_single_lstm_tech = kt.Hyperband(\n",
    "    hypermodel=lambda hp: mdl.build_single_layer_lstm(hp, input_shape=input_shape_tech),\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory=\"tuner_results\",\n",
    "    project_name=\"technical_single_layer_lstm\",  # More descriptive project name\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "# Define a callback to stop training early\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "# Run the hyperparameter search on the technical data\n",
    "print(\"Starting hyperparameter search for the technical model...\")\n",
    "tuner_single_lstm_tech.search(\n",
    "    X_train_tech,\n",
    "    y_train_tech,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[stop_early],\n",
    "    verbose=2,\n",
    ")\n",
    "print(\"\\nTechnical model hyperparameter search complete.\")\n",
    "\n",
    "# Get the optimal hyperparameters and the best model\n",
    "best_hps_single_lstm_tech = tuner_single_lstm_tech.get_best_hyperparameters(\n",
    "    num_trials=1\n",
    ")[0]\n",
    "single_lstm_model_tech = tuner_single_lstm_tech.get_best_models(num_models=1)[0]\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "---\n",
    "Optimal Hyperparameters for Single-Layer Technical LSTM:\n",
    "Units: {best_hps_single_lstm_tech.get('units')}\n",
    "Dropout: {best_hps_single_lstm_tech.get('dropout'):.2f}\n",
    "Learning Rate: {best_hps_single_lstm_tech.get('learning_rate')}\n",
    "---\n",
    "\"\"\"\n",
    ")"
   ],
   "id": "34b9373e1ccfb81a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# --- Evaluation using the best technical model ---\n",
    "print(\"\\n--- Evaluating Best Single-Layer Technical LSTM Model ---\")\n",
    "\n",
    "# Generate predictions on the technical test set\n",
    "single_layer_lstm_preds_tech = single_lstm_model_tech.predict(X_test_tech, verbose=0)\n",
    "\n",
    "# --- Correct way to inverse scale the predictions ---\n",
    "# 1. Create a new scaler for the single target column ('Returns')\n",
    "target_scaler_tech = MinMaxScaler()\n",
    "\n",
    "# 2. Fit it ONLY on the 'Returns' column of the TRAINING data\n",
    "train_data_len_tech = len(tech_data) - len(y_test_tech)\n",
    "target_scaler_tech.fit(tech_data[[\"Returns\"]][:train_data_len_tech])\n",
    "\n",
    "# 3. Now, inverse transform using the correctly fitted scaler\n",
    "y_test_tech_scaled = target_scaler_tech.inverse_transform(y_test_tech.reshape(-1, 1))\n",
    "tech_preds_scaled = target_scaler_tech.inverse_transform(single_layer_lstm_preds_tech)\n",
    "\n",
    "\n",
    "# Calculate and print metrics for the technical model\n",
    "tech_metrics = ut.calculate_metrics(\n",
    "    y_test_tech_scaled, tech_preds_scaled, \"Single-Layer Technical LSTM\", y_train_tech\n",
    ")\n",
    "print(tech_metrics)\n",
    "\n",
    "# Plot the results\n",
    "test_dates_tech = tech_data.index[-len(y_test_tech_scaled) :]\n",
    "ut.plot_non_keras_results(\n",
    "    y_test_tech_scaled,\n",
    "    tech_preds_scaled,\n",
    "    test_dates_tech,\n",
    "    cfg.STOCK_SYMBOL,\n",
    "    \"Single-Layer Technical LSTM\",\n",
    ")"
   ],
   "id": "738ac9d89da4c20e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Single-Layer Enhanced LSTM Model",
   "id": "a353a37a1b1584c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "print(\"\\n--- Tuning Single-Layer Hybrid/Enhanced LSTM Model ---\")\n",
    "\n",
    "# Define the input shape from your hybrid/enhanced training data\n",
    "input_shape_enh = (X_train_enh.shape[1], X_train_enh.shape[2])\n",
    "\n",
    "# Instantiate the tuner for the hybrid/enhanced model\n",
    "tuner_single_lstm_enh = kt.Hyperband(\n",
    "    hypermodel=lambda hp: mdl.build_single_layer_lstm(hp, input_shape=input_shape_enh),\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory=\"tuner_results\",\n",
    "    project_name=\"hybrid_enhanced_single_layer_lstm\",  # Made name more specific\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "# Define a callback for early stopping\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "# Run the hyperparameter search on the hybrid/enhanced data\n",
    "print(\"Starting hyperparameter search on hybrid/enhanced data...\")\n",
    "tuner_single_lstm_enh.search(\n",
    "    X_train_enh,\n",
    "    y_train_enh,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[stop_early],\n",
    "    verbose=2,\n",
    ")\n",
    "print(\"\\nHybrid/Enhanced model hyperparameter search complete.\")\n",
    "\n",
    "# Get the optimal hyperparameters and the best model\n",
    "best_hps_single_lstm_enh = tuner_single_lstm_enh.get_best_hyperparameters(num_trials=1)[\n",
    "    0\n",
    "]\n",
    "single_lstm_model_enh = tuner_single_lstm_enh.get_best_models(num_models=1)[0]\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "---\n",
    "Optimal Hyperparameters for Single-Layer Hybrid/Enhanced LSTM:\n",
    "Units: {best_hps_single_lstm_enh.get('units')}\n",
    "Dropout: {best_hps_single_lstm_enh.get('dropout'):.2f}\n",
    "Learning Rate: {best_hps_single_lstm_enh.get('learning_rate')}\n",
    "---\n",
    "\"\"\"\n",
    ")"
   ],
   "id": "7009912ce83d04e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# --- Evaluation using the best hybrid/enhanced model ---\n",
    "print(\"\\n--- Evaluating Best Single-Layer Hybrid/Enhanced LSTM Model ---\")\n",
    "\n",
    "# Generate predictions on the hybrid/enhanced test set\n",
    "single_layer_lstm_preds_enh = single_lstm_model_enh.predict(X_test_enh, verbose=0)\n",
    "\n",
    "# --- Correct way to inverse scale the predictions ---\n",
    "# 1. Create a new scaler for the single target column ('Returns')\n",
    "target_scaler_enh = MinMaxScaler()\n",
    "\n",
    "# 2. Fit it ONLY on the 'Returns' column of the TRAINING data\n",
    "train_data_len_enh = len(enhanced_full_data) - len(y_test_enh)\n",
    "target_scaler_enh.fit(enhanced_full_data[[\"Returns\"]][:train_data_len_enh])\n",
    "\n",
    "# 3. Now, inverse transform using the correctly fitted scaler\n",
    "y_test_enh_scaled = target_scaler_enh.inverse_transform(y_test_enh.reshape(-1, 1))\n",
    "enh_preds_scaled = target_scaler_enh.inverse_transform(single_layer_lstm_preds_enh)\n",
    "\n",
    "# Calculate and print metrics for the hybrid/enhanced model\n",
    "enh_metrics = ut.calculate_metrics(\n",
    "    y_test_enh_scaled, enh_preds_scaled, \"Single-Layer Hybrid LSTM\", y_train_enh\n",
    ")\n",
    "print(enh_metrics)\n",
    "\n",
    "# Plot the results\n",
    "test_dates_enh = enhanced_full_data.index[-len(y_test_enh_scaled) :]\n",
    "ut.plot_non_keras_results(\n",
    "    y_test_enh_scaled,\n",
    "    enh_preds_scaled,\n",
    "    test_dates_enh,\n",
    "    cfg.STOCK_SYMBOL,\n",
    "    \"Single-Layer Hybrid LSTM\",\n",
    ")"
   ],
   "id": "2ab20c4a5d361762",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Compare Single Layer LSTM Model",
   "id": "7fe4fac7d21ed98d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "plot_data = {\n",
    "    \"Actual\": {\"dates\": test_dates_enh, \"values\": y_test_enh_scaled},\n",
    "    \"Baseline LSTM\": {\"dates\": test_dates_base, \"values\": baseline_preds_scaled},\n",
    "    \"Technical LSTM\": {\"dates\": test_dates_tech, \"values\": tech_preds_scaled},\n",
    "    \"Hybrid LSTM\": {\"dates\": test_dates_enh, \"values\": enh_preds_scaled},\n",
    "}\n",
    "\n",
    "ut.plot_final_comparison(\n",
    "    plot_data,\n",
    "    cfg.STOCK_SYMBOL,\n",
    "    f\"{cfg.STOCK_SYMBOL} LSTM Model Predictions Comparison (Daily Returns)\",\n",
    ")"
   ],
   "id": "a749fd5b43546ce9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Multi-Layer Baseline LSTM Models",
   "id": "571de2628dc61ad7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "print(\"\\n--- Tuning Baseline Multi-Layer LSTM Model ---\")\n",
    "\n",
    "# Define the input shape from your baseline training data\n",
    "input_shape_base = (X_train_base.shape[1], X_train_base.shape[2])\n",
    "\n",
    "# Instantiate the tuner for the baseline multi-layer model\n",
    "tuner_multi_lstm_base = kt.Hyperband(\n",
    "    hypermodel=lambda hp: mdl.build_multi_layer_lstm(hp, input_shape=input_shape_base),\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory=\"tuner_results\",\n",
    "    project_name=\"baseline_multi_layer_lstm\",  # New project name\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "# Define a callback to stop training early\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "# Run the hyperparameter search on the baseline data\n",
    "print(\"Starting hyperparameter search for the baseline multi-layer model...\")\n",
    "tuner_multi_lstm_base.search(\n",
    "    X_train_base,\n",
    "    y_train_base,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[stop_early],\n",
    "    verbose=2,\n",
    ")\n",
    "print(\"\\nBaseline multi-layer hyperparameter search complete.\")\n",
    "\n",
    "# Get the optimal hyperparameters and the best model\n",
    "best_hps_multi_lstm_base = tuner_multi_lstm_base.get_best_hyperparameters(num_trials=1)[\n",
    "    0\n",
    "]\n",
    "multi_layer_model_base = tuner_multi_lstm_base.get_best_models(num_models=1)[0]\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "---\n",
    "Optimal Hyperparameters for Baseline Multi-Layer LSTM:\n",
    "Units Layer 1: {best_hps_multi_lstm_base.get('units_1')}\n",
    "Units Layer 2: {best_hps_multi_lstm_base.get('units_2')}\n",
    "Dropout: {best_hps_multi_lstm_base.get('dropout'):.2f}\n",
    "Learning Rate: {best_hps_multi_lstm_base.get('learning_rate')}\n",
    "---\n",
    "\"\"\"\n",
    ")"
   ],
   "id": "4169821de7c0dd8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# --- Evaluation using the best baseline multi-layer model ---\n",
    "print(\"\\n--- Evaluating Best Baseline Multi-Layer LSTM Model ---\")\n",
    "\n",
    "# Generate predictions on the baseline test set\n",
    "multi_layer_preds_base = multi_layer_model_base.predict(X_test_base, verbose=0)\n",
    "\n",
    "# --- Correct way to inverse scale the predictions ---\n",
    "# 1. Create a new scaler for the single target column ('Returns')\n",
    "target_scaler_base_ml = MinMaxScaler()  # Use a unique name to avoid conflicts\n",
    "\n",
    "# 2. Fit it ONLY on the 'Returns' column of the TRAINING data\n",
    "train_data_len_base = len(tech_data) - len(y_test_base)\n",
    "target_scaler_base_ml.fit(tech_data[[\"Returns\"]][:train_data_len_base])\n",
    "\n",
    "# 3. Now, inverse transform using the correctly fitted scaler\n",
    "y_test_base_scaled = target_scaler_base_ml.inverse_transform(y_test_base.reshape(-1, 1))\n",
    "multi_preds_scaled_base = target_scaler_base_ml.inverse_transform(\n",
    "    multi_layer_preds_base\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate and print metrics\n",
    "multi_layer_metrics_base = ut.calculate_metrics(\n",
    "    y_test_base_scaled,\n",
    "    multi_preds_scaled_base,\n",
    "    \"Multi-Layer Baseline LSTM\",\n",
    "    y_train_base,\n",
    ")\n",
    "print(multi_layer_metrics_base)\n",
    "\n",
    "# Plot the results\n",
    "test_dates_base = tech_data.index[-len(y_test_base_scaled) :]\n",
    "ut.plot_non_keras_results(\n",
    "    y_test_base_scaled,\n",
    "    multi_preds_scaled_base,\n",
    "    test_dates_base,\n",
    "    cfg.STOCK_SYMBOL,\n",
    "    \"Multi-Layer Baseline LSTM\",\n",
    ")"
   ],
   "id": "3ca04383d2fe57c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Multi-Layer Technical LSTM Model",
   "id": "942020112a861ea6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "print(\"\\n--- Tuning Multi-Layer Technical LSTM Model ---\")\n",
    "\n",
    "# Define the input shape from your technical training data\n",
    "input_shape_tech = (X_train_tech.shape[1], X_train_tech.shape[2])\n",
    "\n",
    "# Instantiate the tuner for the technical multi-layer model\n",
    "tuner_multi_lstm_tech = kt.Hyperband(\n",
    "    hypermodel=lambda hp: mdl.build_multi_layer_lstm(hp, input_shape=input_shape_tech),\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory=\"tuner_results\",\n",
    "    project_name=\"technical_multi_layer_lstm\",  # Specific project name\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "# Define a callback to stop training early\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "# Run the hyperparameter search on the technical data\n",
    "print(\"Starting hyperparameter search for the technical multi-layer model...\")\n",
    "tuner_multi_lstm_tech.search(\n",
    "    X_train_tech,\n",
    "    y_train_tech,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[stop_early],\n",
    "    verbose=2,\n",
    ")\n",
    "print(\"\\nTechnical multi-layer hyperparameter search complete.\")\n",
    "\n",
    "# Get the optimal hyperparameters and the best model\n",
    "best_hps_multi_lstm_tech = tuner_multi_lstm_tech.get_best_hyperparameters(num_trials=1)[\n",
    "    0\n",
    "]\n",
    "multi_layer_model_tech = tuner_multi_lstm_tech.get_best_models(num_models=1)[0]\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "---\n",
    "Optimal Hyperparameters for Multi-Layer Technical LSTM:\n",
    "Units Layer 1: {best_hps_multi_lstm_tech.get('units_1')}\n",
    "Units Layer 2: {best_hps_multi_lstm_tech.get('units_2')}\n",
    "Dropout: {best_hps_multi_lstm_tech.get('dropout'):.2f}\n",
    "Learning Rate: {best_hps_multi_lstm_tech.get('learning_rate')}\n",
    "---\n",
    "\"\"\"\n",
    ")"
   ],
   "id": "3ddcd228757eed3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# --- Evaluation using the best technical multi-layer model ---\n",
    "print(\"\\n--- Evaluating Best Multi-Layer Technical LSTM Model ---\")\n",
    "\n",
    "# Generate predictions on the technical test set\n",
    "multi_layer_preds_tech = multi_layer_model_tech.predict(X_test_tech, verbose=0)\n",
    "\n",
    "# --- Correct way to inverse scale the predictions ---\n",
    "# 1. Create a new scaler for the single target column ('Returns')\n",
    "target_scaler_tech_ml = MinMaxScaler()  # Use a unique name\n",
    "\n",
    "# 2. Fit it ONLY on the 'Returns' column of the TRAINING data\n",
    "train_data_len_tech = len(tech_data) - len(y_test_tech)\n",
    "target_scaler_tech_ml.fit(tech_data[[\"Returns\"]][:train_data_len_tech])\n",
    "\n",
    "# 3. Now, inverse transform using the correctly fitted scaler\n",
    "y_test_tech_scaled = target_scaler_tech_ml.inverse_transform(y_test_tech.reshape(-1, 1))\n",
    "multi_preds_scaled_tech = target_scaler_tech_ml.inverse_transform(\n",
    "    multi_layer_preds_tech\n",
    ")\n",
    "\n",
    "# Calculate and print metrics\n",
    "multi_layer_metrics_tech = ut.calculate_metrics(\n",
    "    y_test_tech_scaled,\n",
    "    multi_preds_scaled_tech,\n",
    "    \"Multi-Layer Technical LSTM\",\n",
    "    y_train_tech,\n",
    ")\n",
    "print(multi_layer_metrics_tech)\n",
    "\n",
    "# Plot the results\n",
    "test_dates_tech = tech_data.index[-len(y_test_tech_scaled) :]\n",
    "ut.plot_non_keras_results(\n",
    "    y_test_tech_scaled,\n",
    "    multi_preds_scaled_tech,\n",
    "    test_dates_tech,\n",
    "    cfg.STOCK_SYMBOL,\n",
    "    \"Multi-Layer Technical LSTM\",\n",
    ")"
   ],
   "id": "e58ca92f2ae5037",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Multi-Layer Enhanced LSTM Model",
   "id": "f91581cd43291e50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "print(\"\\n--- Tuning Multi-Layer Hybrid/Enhanced LSTM Model ---\")\n",
    "\n",
    "# Define the input shape from your hybrid/enhanced training data\n",
    "input_shape_enh = (X_train_enh.shape[1], X_train_enh.shape[2])\n",
    "\n",
    "# Instantiate the tuner for the hybrid/enhanced multi-layer model\n",
    "tuner_multi_lstm_enh = kt.Hyperband(\n",
    "    hypermodel=lambda hp: mdl.build_multi_layer_lstm(hp, input_shape=input_shape_enh),\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory=\"tuner_results\",\n",
    "    project_name=\"hybrid_enhanced_multi_layer_lstm\",  # Specific project name\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "# Define a callback to stop training early\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "# Run the hyperparameter search on the hybrid/enhanced data\n",
    "print(\"Starting hyperparameter search for the hybrid/enhanced multi-layer model...\")\n",
    "tuner_multi_lstm_enh.search(\n",
    "    X_train_enh,\n",
    "    y_train_enh,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[stop_early],\n",
    "    verbose=2,\n",
    ")\n",
    "print(\"\\nHybrid/Enhanced multi-layer hyperparameter search complete.\")\n",
    "\n",
    "# Get the optimal hyperparameters and the best model\n",
    "best_hps_multi_lstm_enh = tuner_multi_lstm_enh.get_best_hyperparameters(num_trials=1)[0]\n",
    "multi_layer_model_enh = tuner_multi_lstm_enh.get_best_models(num_models=1)[0]\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "---\n",
    "Optimal Hyperparameters for Multi-Layer Hybrid/Enhanced LSTM:\n",
    "Units Layer 1: {best_hps_multi_lstm_enh.get('units_1')}\n",
    "Units Layer 2: {best_hps_multi_lstm_enh.get('units_2')}\n",
    "Dropout: {best_hps_multi_lstm_enh.get('dropout'):.2f}\n",
    "Learning Rate: {best_hps_multi_lstm_enh.get('learning_rate')}\n",
    "---\n",
    "\"\"\"\n",
    ")"
   ],
   "id": "e3586d967056c838",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# --- Evaluation using the best hybrid/enhanced multi-layer model ---\n",
    "print(\"\\n--- Evaluating Best Multi-Layer Hybrid/Enhanced LSTM Model ---\")\n",
    "\n",
    "# Generate predictions on the hybrid/enhanced test set\n",
    "multi_layer_preds_enh = multi_layer_model_enh.predict(X_test_enh, verbose=0)\n",
    "\n",
    "# --- Correct way to inverse scale the predictions ---\n",
    "# 1. Create a new scaler for the single target column ('Returns')\n",
    "target_scaler_enh_ml = MinMaxScaler()  # Use a unique name\n",
    "\n",
    "# 2. Fit it ONLY on the 'Returns' column of the TRAINING data\n",
    "train_data_len_enh = len(enhanced_full_data) - len(y_test_enh)\n",
    "target_scaler_enh_ml.fit(enhanced_full_data[[\"Returns\"]][:train_data_len_enh])\n",
    "\n",
    "# 3. Now, inverse transform using the correctly fitted scaler\n",
    "y_test_enh_scaled = target_scaler_enh_ml.inverse_transform(y_test_enh.reshape(-1, 1))\n",
    "multi_preds_scaled_enh = target_scaler_enh_ml.inverse_transform(multi_layer_preds_enh)\n",
    "\n",
    "# Calculate and print metrics\n",
    "multi_layer_metrics_enh = ut.calculate_metrics(\n",
    "    y_test_enh_scaled, multi_preds_scaled_enh, \"Multi-Layer Hybrid LSTM\", y_train_enh\n",
    ")\n",
    "print(multi_layer_metrics_enh)\n",
    "\n",
    "# Plot the results\n",
    "test_dates_enh = enhanced_full_data.index[-len(y_test_enh_scaled) :]\n",
    "ut.plot_non_keras_results(\n",
    "    y_test_enh_scaled,\n",
    "    multi_preds_scaled_enh,\n",
    "    test_dates_enh,\n",
    "    cfg.STOCK_SYMBOL,\n",
    "    \"Multi-Layer Hybrid LSTM\",\n",
    ")"
   ],
   "id": "1ef17ee4008e88c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Baseline GRU Model",
   "id": "89544c25baabbae7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "print(\"\\n--- Tuning Baseline GRU Model ---\")\n",
    "\n",
    "# Define the input shape from your BASELINE training data\n",
    "input_shape_base = (X_train_base.shape[1], X_train_base.shape[2])\n",
    "\n",
    "# Instantiate the tuner for the GRU model\n",
    "tuner_base_gru = kt.Hyperband(\n",
    "    # Ensure the model builder uses the correct input shape\n",
    "    hypermodel=lambda hp: mdl.build_gru(hp, input_shape=input_shape_base),\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory=\"tuner_results\",\n",
    "    project_name=\"baseline_gru\",\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "# Define a callback to stop training early\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "# Run the hyperparameter search on the BASELINE data\n",
    "print(\"Starting GRU hyperparameter search on baseline data...\")\n",
    "tuner_base_gru.search(\n",
    "    X_train_base,\n",
    "    y_train_base,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[stop_early],\n",
    "    verbose=2,\n",
    ")\n",
    "print(\"\\nHyperparameter search complete.\")\n",
    "\n",
    "# Get the optimal hyperparameters and the best model\n",
    "best_hps_base_gru = tuner_base_gru.get_best_hyperparameters(num_trials=1)[0]\n",
    "baseline_gru_model = tuner_base_gru.get_best_models(num_models=1)[0]\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "---\n",
    "Optimal Hyperparameters for Baseline GRU:\n",
    "Units Layer 1: {best_hps_base_gru.get('units_1')}\n",
    "Units Layer 2: {best_hps_base_gru.get('units_2')}\n",
    "Dropout: {best_hps_base_gru.get('dropout'):.2f}\n",
    "Learning Rate: {best_hps_base_gru.get('learning_rate')}\n",
    "---\n",
    "\"\"\"\n",
    ")"
   ],
   "id": "51f4716d797e8ad2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# --- Evaluation using the best baseline GRU model ---\n",
    "print(\"\\n--- Evaluating Best Baseline GRU Model ---\")\n",
    "\n",
    "# Generate predictions on the BASELINE test set\n",
    "base_gru_preds = baseline_gru_model.predict(X_test_base, verbose=0)\n",
    "\n",
    "# --- Correct way to inverse scale the predictions ---\n",
    "# 1. Create a new scaler for the single target column ('Returns')\n",
    "target_scaler_base_gru = MinMaxScaler()  # Use a unique name\n",
    "\n",
    "# 2. Fit it ONLY on the 'Returns' column of the TRAINING data\n",
    "train_data_len_base = len(tech_data) - len(y_test_base)\n",
    "target_scaler_base_gru.fit(tech_data[[\"Returns\"]][:train_data_len_base])\n",
    "\n",
    "# 3. Now, inverse transform using the correctly fitted scaler\n",
    "y_test_base_scaled = target_scaler_base_gru.inverse_transform(\n",
    "    y_test_base.reshape(-1, 1)\n",
    ")\n",
    "base_gru_preds_scaled = target_scaler_base_gru.inverse_transform(base_gru_preds)\n",
    "\n",
    "\n",
    "# Calculate and print metrics for the baseline GRU model\n",
    "baseline_gru_metrics = ut.calculate_metrics(\n",
    "    y_test_base_scaled, base_gru_preds_scaled, \"Baseline GRU\", y_train_base\n",
    ")\n",
    "print(baseline_gru_metrics)\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "test_dates_base = tech_data.index[-len(y_test_base_scaled) :]\n",
    "ut.plot_non_keras_results(\n",
    "    y_test_base_scaled,\n",
    "    base_gru_preds_scaled,\n",
    "    test_dates_base,\n",
    "    cfg.STOCK_SYMBOL,\n",
    "    \"Baseline GRU\",\n",
    ")"
   ],
   "id": "7e25770979ce8a13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Technical GRU Model",
   "id": "1ccef1249af118ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "print(\"\\n--- Tuning Technical GRU Model ---\")\n",
    "\n",
    "# Define the input shape from your TECHNICAL training data\n",
    "input_shape_tech = (X_train_tech.shape[1], X_train_tech.shape[2])\n",
    "\n",
    "# Instantiate the tuner for the technical GRU model\n",
    "tuner_tech_gru = kt.Hyperband(\n",
    "    hypermodel=lambda hp: mdl.build_gru(hp, input_shape=input_shape_tech),\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory=\"tuner_results\",\n",
    "    project_name=\"technical_gru\",\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "# Define a callback to stop training early\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "# Run the hyperparameter search on the TECHNICAL data\n",
    "print(\"Starting GRU hyperparameter search on technical data...\")\n",
    "tuner_tech_gru.search(\n",
    "    X_train_tech,\n",
    "    y_train_tech,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[stop_early],\n",
    "    verbose=2,\n",
    ")\n",
    "print(\"\\nHyperparameter search complete.\")\n",
    "\n",
    "# Get the optimal hyperparameters and the best model\n",
    "best_hps_tech_gru = tuner_tech_gru.get_best_hyperparameters(num_trials=1)[0]\n",
    "technical_gru_model = tuner_tech_gru.get_best_models(num_models=1)[0]\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "---\n",
    "Optimal Hyperparameters for Technical GRU:\n",
    "Units Layer 1: {best_hps_tech_gru.get('units_1')}\n",
    "Units Layer 2: {best_hps_tech_gru.get('units_2')}\n",
    "Dropout: {best_hps_tech_gru.get('dropout'):.2f}\n",
    "Learning Rate: {best_hps_tech_gru.get('learning_rate')}\n",
    "---\n",
    "\"\"\"\n",
    ")"
   ],
   "id": "4ff8fe9d0fdbc726",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# --- Evaluation using the best technical GRU model ---\n",
    "print(\"\\n--- Evaluating Best Technical GRU Model ---\")\n",
    "\n",
    "# Generate predictions on the TECHNICAL test set\n",
    "tech_gru_preds = technical_gru_model.predict(X_test_tech, verbose=0)\n",
    "\n",
    "# --- Correct way to inverse scale the predictions ---\n",
    "# 1. Create a new scaler for the single target column ('Returns')\n",
    "target_scaler_tech_gru = MinMaxScaler()  # Use a unique name\n",
    "\n",
    "# 2. Fit it ONLY on the 'Returns' column of the TRAINING data\n",
    "train_data_len_tech = len(tech_data) - len(y_test_tech)\n",
    "target_scaler_tech_gru.fit(tech_data[[\"Returns\"]][:train_data_len_tech])\n",
    "\n",
    "# 3. Now, inverse transform using the correctly fitted scaler\n",
    "y_test_tech_scaled = target_scaler_tech_gru.inverse_transform(\n",
    "    y_test_tech.reshape(-1, 1)\n",
    ")\n",
    "tech_gru_preds_scaled = target_scaler_tech_gru.inverse_transform(tech_gru_preds)\n",
    "\n",
    "# Calculate and print metrics for the technical GRU model\n",
    "technical_gru_metrics = ut.calculate_metrics(\n",
    "    y_test_tech_scaled, tech_gru_preds_scaled, \"Technical GRU\", y_train_tech\n",
    ")\n",
    "print(technical_gru_metrics)\n",
    "\n",
    "# Plot the results\n",
    "test_dates_tech = tech_data.index[-len(y_test_tech_scaled) :]\n",
    "ut.plot_non_keras_results(\n",
    "    y_test_tech_scaled,\n",
    "    tech_gru_preds_scaled,\n",
    "    test_dates_tech,\n",
    "    cfg.STOCK_SYMBOL,\n",
    "    \"Technical GRU\",\n",
    ")"
   ],
   "id": "38641d40c3035d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Enhanced GRU Model",
   "id": "34b5c46dc0b2f42f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "print(\"\\n--- Tuning Hybrid/Enhanced GRU Model ---\")\n",
    "\n",
    "# Define the input shape from your HYBRID/ENHANCED training data\n",
    "input_shape_enh = (X_train_enh.shape[1], X_train_enh.shape[2])\n",
    "\n",
    "# Instantiate the tuner for the hybrid/enhanced GRU model\n",
    "tuner_enh_gru = kt.Hyperband(\n",
    "    hypermodel=lambda hp: mdl.build_gru(hp, input_shape=input_shape_enh),\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory=\"tuner_results\",\n",
    "    project_name=\"enhanced_gru\",\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "# Define a callback to stop training early\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "# Run the hyperparameter search on the HYBRID/ENHANCED data\n",
    "print(\"Starting GRU hyperparameter search on enhanced data...\")\n",
    "tuner_enh_gru.search(\n",
    "    X_train_enh,\n",
    "    y_train_enh,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[stop_early],\n",
    "    verbose=2,\n",
    ")\n",
    "print(\"\\nHyperparameter search complete.\")\n",
    "\n",
    "# Get the optimal hyperparameters and the best model\n",
    "best_hps_enh_gru = tuner_enh_gru.get_best_hyperparameters(num_trials=1)[0]\n",
    "enhanced_gru_model = tuner_enh_gru.get_best_models(num_models=1)[0]\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "---\n",
    "Optimal Hyperparameters for Hybrid/Enhanced GRU:\n",
    "Units Layer 1: {best_hps_enh_gru.get('units_1')}\n",
    "Units Layer 2: {best_hps_enh_gru.get('units_2')}\n",
    "Dropout: {best_hps_enh_gru.get('dropout'):.2f}\n",
    "Learning Rate: {best_hps_enh_gru.get('learning_rate')}\n",
    "---\n",
    "\"\"\"\n",
    ")"
   ],
   "id": "78c7d7348a7c16fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# --- Evaluation using the best hybrid/enhanced GRU model ---\n",
    "print(\"\\n--- Evaluating Best Hybrid/Enhanced GRU Model ---\")\n",
    "\n",
    "# Generate predictions on the HYBRID/ENHANCED test set\n",
    "enh_gru_preds = enhanced_gru_model.predict(X_test_enh, verbose=0)\n",
    "\n",
    "# --- Correct way to inverse scale the predictions ---\n",
    "# 1. Create a new scaler for the single target column ('Returns')\n",
    "target_scaler_enh_gru = MinMaxScaler()  # Use a unique name\n",
    "\n",
    "# 2. Fit it ONLY on the 'Returns' column of the TRAINING data\n",
    "train_data_len_enh = len(enhanced_full_data) - len(y_test_enh)\n",
    "target_scaler_enh_gru.fit(enhanced_full_data[[\"Returns\"]][:train_data_len_enh])\n",
    "\n",
    "# 3. Now, inverse transform using the correctly fitted scaler\n",
    "y_test_enh_scaled = target_scaler_enh_gru.inverse_transform(y_test_enh.reshape(-1, 1))\n",
    "enh_gru_preds_scaled = target_scaler_enh_gru.inverse_transform(enh_gru_preds)\n",
    "\n",
    "# Calculate and print metrics for the hybrid/enhanced GRU model\n",
    "enhanced_gru_metrics = ut.calculate_metrics(\n",
    "    y_test_enh_scaled, enh_gru_preds_scaled, \"Enhanced GRU\", y_train_enh\n",
    ")\n",
    "print(enhanced_gru_metrics)\n",
    "\n",
    "# Plot the results\n",
    "test_dates_enh = enhanced_full_data.index[-len(y_test_enh_scaled) :]\n",
    "ut.plot_non_keras_results(\n",
    "    y_test_enh_scaled,\n",
    "    enh_gru_preds_scaled,\n",
    "    test_dates_enh,\n",
    "    cfg.STOCK_SYMBOL,\n",
    "    \"Enhanced GRU\",\n",
    ")"
   ],
   "id": "9b44101be65a9d1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Baseline SVM Model",
   "id": "80614440b76921f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# --- Preparing Data for Baseline SVM Model ---\n",
    "print(\"\\n--- Preparing Data for Baseline SVM Model ---\")\n",
    "\n",
    "# SVM requires 2D input, so we flatten the sequence data from the baseline dataset\n",
    "nsamples, nx, ny = X_train_base.shape\n",
    "X_train_svm_base = X_train_base.reshape((nsamples, nx * ny))\n",
    "\n",
    "nsamples, nx, ny = X_test_base.shape\n",
    "X_test_svm_base = X_test_base.reshape((nsamples, nx * ny))\n",
    "\n",
    "# We'll use the original y_train and y_test, but we need to flatten y_train for the model's fit method\n",
    "y_train_svm_base = y_train_base.ravel()\n",
    "y_test_svm_base = y_test_base.ravel()\n",
    "\n",
    "print(\n",
    "    f\"Reshaped Baseline data for SVM: X_train={X_train_svm_base.shape}, y_train={y_train_svm_base.shape}\"\n",
    ")"
   ],
   "id": "7ee415a97eb2a9b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# --- Build and train the SVM using the baseline data ---\n",
    "print(\"\\n--- Tuning and Training Baseline SVM Model ---\")\n",
    "baseline_svm_model = mdl.build_and_train_svm(X_train_svm_base, y_train_svm_base)\n",
    "\n",
    "# --- Evaluate the best model found ---\n",
    "print(\"\\n--- Evaluating Best Baseline SVM Model ---\")\n",
    "base_svm_preds = baseline_svm_model.predict(X_test_svm_base)\n",
    "\n",
    "# --- Correct way to inverse scale the predictions ---\n",
    "# 1. Create a new scaler for the single target column ('Returns')\n",
    "target_scaler_svm_base = MinMaxScaler()  # Use a unique name\n",
    "\n",
    "# 2. Fit it ONLY on the 'Returns' column of the TRAINING data\n",
    "train_data_len_base = len(tech_data) - len(y_test_base)\n",
    "target_scaler_svm_base.fit(tech_data[[\"Returns\"]][:train_data_len_base])\n",
    "\n",
    "# 3. Now, inverse transform using the correctly fitted scaler\n",
    "y_test_svm_base_scaled = target_scaler_svm_base.inverse_transform(\n",
    "    y_test_base.reshape(-1, 1)\n",
    ")\n",
    "base_svm_preds_scaled = target_scaler_svm_base.inverse_transform(\n",
    "    base_svm_preds.reshape(-1, 1)\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate and print metrics\n",
    "baseline_svm_metrics = ut.calculate_metrics(\n",
    "    y_test_svm_base_scaled, base_svm_preds_scaled, \"Baseline SVM\", y_train_base\n",
    ")\n",
    "print(baseline_svm_metrics)\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "test_dates_base = tech_data.index[-len(y_test_svm_base_scaled) :]\n",
    "ut.plot_non_keras_results(\n",
    "    y_test_svm_base_scaled,\n",
    "    base_svm_preds_scaled,\n",
    "    test_dates_base,\n",
    "    cfg.STOCK_SYMBOL,\n",
    "    \"Baseline SVM\",\n",
    ")"
   ],
   "id": "2b9b1ddffb135dc6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Technical SVM Model",
   "id": "9710cdfb91c6c399"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# --- Preparing Data for Technical SVM Model ---\n",
    "print(\"\\n--- Preparing Data for Technical SVM Model ---\")\n",
    "\n",
    "# SVM requires 2D input, so we flatten the sequence data from the technical dataset\n",
    "nsamples, nx, ny = X_train_tech.shape\n",
    "X_train_svm_tech = X_train_tech.reshape((nsamples, nx * ny))\n",
    "\n",
    "nsamples, nx, ny = X_test_tech.shape\n",
    "X_test_svm_tech = X_test_tech.reshape((nsamples, nx * ny))\n",
    "\n",
    "# Flatten the y_train and y_test arrays for the SVM's fit method\n",
    "y_train_svm_tech = y_train_tech.ravel()\n",
    "y_test_svm_tech = y_test_tech.ravel()\n",
    "\n",
    "print(\n",
    "    f\"Reshaped Technical data for SVM: X_train={X_train_svm_tech.shape}, y_train={y_train_svm_tech.shape}\"\n",
    ")"
   ],
   "id": "5447e50e8f4685b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# --- Build and train the SVM using the technical data ---\n",
    "print(\"\\n--- Tuning and Training Technical SVM Model ---\")\n",
    "technical_svm_model = mdl.build_and_train_svm(X_train_svm_tech, y_train_svm_tech)\n",
    "\n",
    "# --- Evaluate the best model found ---\n",
    "print(\"\\n--- Evaluating Best Technical SVM Model ---\")\n",
    "tech_svm_preds = technical_svm_model.predict(X_test_svm_tech)\n",
    "\n",
    "# --- Correct way to inverse scale the predictions ---\n",
    "# 1. Create a new scaler for the single target column ('Returns')\n",
    "target_scaler_svm_tech = MinMaxScaler()  # Use a unique name\n",
    "\n",
    "# 2. Fit it ONLY on the 'Returns' column of the TRAINING data\n",
    "train_data_len_tech = len(tech_data) - len(y_test_tech)\n",
    "target_scaler_svm_tech.fit(tech_data[[\"Returns\"]][:train_data_len_tech])\n",
    "\n",
    "# 3. Now, inverse transform using the correctly fitted scaler\n",
    "y_test_svm_tech_scaled = target_scaler_svm_tech.inverse_transform(\n",
    "    y_test_tech.reshape(-1, 1)\n",
    ")\n",
    "tech_svm_preds_scaled = target_scaler_svm_tech.inverse_transform(\n",
    "    tech_svm_preds.reshape(-1, 1)\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate and print metrics\n",
    "technical_svm_metrics = ut.calculate_metrics(\n",
    "    y_test_svm_tech_scaled, tech_svm_preds_scaled, \"Technical SVM\", y_train_tech\n",
    ")\n",
    "print(technical_svm_metrics)\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "test_dates_tech = tech_data.index[-len(y_test_svm_tech_scaled) :]\n",
    "ut.plot_non_keras_results(\n",
    "    y_test_svm_tech_scaled,\n",
    "    tech_svm_preds_scaled,\n",
    "    test_dates_tech,\n",
    "    cfg.STOCK_SYMBOL,\n",
    "    \"Technical SVM\",\n",
    ")"
   ],
   "id": "cdf6ebb819702256",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Enhanced SVM Model",
   "id": "b0bf1d2d3cf8815f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# --- Preparing Data for Hybrid/Enhanced SVM Model ---\n",
    "print(\"\\n--- Preparing Data for Hybrid/Enhanced SVM Model ---\")\n",
    "\n",
    "# SVM requires 2D input, so we flatten the sequence data from the enhanced dataset\n",
    "nsamples, nx, ny = X_train_enh.shape\n",
    "X_train_svm_enh = X_train_enh.reshape((nsamples, nx * ny))\n",
    "\n",
    "nsamples, nx, ny = X_test_enh.shape\n",
    "X_test_svm_enh = X_test_enh.reshape((nsamples, nx * ny))\n",
    "\n",
    "# Flatten the y_train and y_test arrays for the SVM's fit method\n",
    "y_train_svm_enh = y_train_enh.ravel()\n",
    "y_test_svm_enh = y_test_enh.ravel()\n",
    "\n",
    "print(\n",
    "    f\"Reshaped Enhanced data for SVM: X_train={X_train_svm_enh.shape}, y_train={y_train_svm_enh.shape}\"\n",
    ")"
   ],
   "id": "8123a42dc0f58d2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# --- Build and train the SVM using the hybrid/enhanced data ---\n",
    "print(\"\\n--- Tuning and Training Hybrid/Enhanced SVM Model ---\")\n",
    "enhanced_svm_model = mdl.build_and_train_svm(X_train_svm_enh, y_train_svm_enh)\n",
    "\n",
    "# --- Evaluate the best model found ---\n",
    "print(\"\\n--- Evaluating Best Hybrid/Enhanced SVM Model ---\")\n",
    "enh_svm_preds = enhanced_svm_model.predict(X_test_svm_enh)\n",
    "\n",
    "# --- Correct way to inverse scale the predictions ---\n",
    "# 1. Create a new scaler for the single target column ('Returns')\n",
    "target_scaler_svm_enh = MinMaxScaler()  # Use a unique name\n",
    "\n",
    "# 2. Fit it ONLY on the 'Returns' column of the TRAINING data\n",
    "train_data_len_enh = len(enhanced_full_data) - len(y_test_enh)\n",
    "target_scaler_svm_enh.fit(enhanced_full_data[[\"Returns\"]][:train_data_len_enh])\n",
    "\n",
    "# 3. Now, inverse transform using the correctly fitted scaler\n",
    "y_test_svm_enh_scaled = target_scaler_svm_enh.inverse_transform(\n",
    "    y_test_enh.reshape(-1, 1)\n",
    ")\n",
    "enh_svm_preds_scaled = target_scaler_svm_enh.inverse_transform(\n",
    "    enh_svm_preds.reshape(-1, 1)\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate and print metrics\n",
    "enhanced_svm_metrics = ut.calculate_metrics(\n",
    "    y_test_svm_enh_scaled, enh_svm_preds_scaled, \"Enhanced SVM\", y_train_enh\n",
    ")\n",
    "print(enhanced_svm_metrics)\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "test_dates_enh = enhanced_full_data.index[-len(y_test_svm_enh_scaled) :]\n",
    "ut.plot_non_keras_results(\n",
    "    y_test_svm_enh_scaled,\n",
    "    enh_svm_preds_scaled,\n",
    "    test_dates_enh,\n",
    "    cfg.STOCK_SYMBOL,\n",
    "    \"Enhanced SVM\",\n",
    ")"
   ],
   "id": "69446869dd46a216",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ARIMA Model",
   "id": "ec42e3a789edbd85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "print(\"\\n--- Preparing Data and Finding Best ARIMA Order ---\")\n",
    "\n",
    "# ARIMA works on a single (univariate) time series. We'll use the target variable directly.\n",
    "# Using 'enhanced_full_data' ensures we have the longest consistent timeseries available.\n",
    "target_series = enhanced_full_data[cfg.HYBRID_TARGET].dropna()\n",
    "\n",
    "# Split the data for training and testing\n",
    "train_size = int(len(target_series) * (1 - cfg.TEST_SIZE))\n",
    "train_arima, test_arima = target_series[0:train_size], target_series[train_size:]\n",
    "\n",
    "print(f\"ARIMA Training Data Size: {len(train_arima)}\")\n",
    "print(f\"ARIMA Test Data Size: {len(test_arima)}\")\n",
    "\n",
    "\n",
    "# Find the best (p,d,q) order using the auto-ARIMA function\n",
    "# This might take a few minutes depending on the data size.\n",
    "best_arima_order = mdl.find_best_arima_order(train_arima)\n",
    "\n",
    "\n",
    "# Plot ACF and PACF for visual inspection to help verify the p and q values.\n",
    "print(\"\\nPlotting ACF and PACF of the differenced series...\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
    "plot_acf(train_arima.diff().dropna(), ax=axes[0], title=\"Autocorrelation (ACF)\")\n",
    "plot_pacf(\n",
    "    train_arima.diff().dropna(),\n",
    "    ax=axes[1],\n",
    "    title=\"Partial Autocorrelation (PACF)\",\n",
    "    method=\"ywm\",\n",
    ")\n",
    "plt.show()"
   ],
   "id": "c2b56257bdda75da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "print(f\"\\n--- Running ARIMA Model with best order {best_arima_order} ---\")\n",
    "\n",
    "# Initialize a list with the training data, which will be updated at each step\n",
    "history = [x for x in train_arima]\n",
    "arima_predictions = []\n",
    "\n",
    "print(f\"Performing rolling forecast for {len(test_arima)} steps...\")\n",
    "\n",
    "# Use tqdm for a progress bar, which is helpful for long-running loops\n",
    "for t in tqdm(range(len(test_arima)), desc=\"ARIMA Rolling Forecast\"):\n",
    "    # Build and train the ARIMA model on the current history\n",
    "    # The model is retrained at each step to incorporate the latest data\n",
    "    model_arima = mdl.build_and_train_arima(history, order=best_arima_order)\n",
    "\n",
    "    # Forecast one step ahead\n",
    "    output = model_arima.forecast()\n",
    "    yhat = output[0]\n",
    "    arima_predictions.append(yhat)\n",
    "\n",
    "    # Append the actual observed value to history for the next iteration\n",
    "    obs = test_arima.iloc[t]\n",
    "    history.append(obs)\n",
    "\n",
    "print(\"ARIMA forecast complete.\")"
   ],
   "id": "998c9e84a32d3b19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# --- Evaluate the ARIMA Model ---\n",
    "print(\"\\n--- Evaluating ARIMA Model ---\")\n",
    "\n",
    "# Convert predictions to a NumPy array for calculations\n",
    "arima_predictions_np = np.array(arima_predictions)\n",
    "\n",
    "# The data is already in its original scale, so no inverse transform is needed.\n",
    "arima_metrics = ut.calculate_metrics(\n",
    "    test_arima.values, arima_predictions_np, \"ARIMA\", train_arima.values\n",
    ")\n",
    "print(arima_metrics)\n",
    "\n",
    "# --- Plot the Results ---\n",
    "# Get the dates corresponding to the test set for the x-axis\n",
    "test_dates_arima = target_series.index[train_size:]\n",
    "\n",
    "ut.plot_non_keras_results(\n",
    "    test_arima.values,\n",
    "    arima_predictions_np,\n",
    "    test_dates_arima,\n",
    "    cfg.STOCK_SYMBOL,\n",
    "    f\"ARIMA{best_arima_order}\",\n",
    ")"
   ],
   "id": "33a6297792b684d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 7. Final Performance Comparison",
   "id": "eca26eebba5eee00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "# --- 1. Create a Naive Baseline for Comparison ---\n",
    "# A naive forecast simply uses the previous day's value as the prediction for the current day.\n",
    "# We use the scaled baseline data for a fair comparison.\n",
    "print(\"--- Calculating Naive Baseline ---\")\n",
    "naive_preds = np.roll(y_test_base_scaled, 1)\n",
    "# The first element has no prior value, so we'll just use its own value, resulting in zero error for that step.\n",
    "naive_preds[0] = y_test_base_scaled[0]\n",
    "naive_metrics = ut.calculate_metrics(\n",
    "    y_test_base_scaled, naive_preds, \"Naive Baseline\", y_train_base\n",
    ")\n",
    "\n",
    "\n",
    "# --- 2. Consolidate All Model Metrics ---\n",
    "# Gather all the metric dictionaries we created into a single list.\n",
    "all_metrics_list = [\n",
    "    naive_metrics,\n",
    "    # Single-Layer LSTMs\n",
    "    baseline_lstm_metrics,\n",
    "    tech_metrics,  # Renamed from baseline_metrics for clarity\n",
    "    enh_metrics,\n",
    "    # Multi-Layer LSTMs\n",
    "    multi_layer_metrics_base,\n",
    "    multi_layer_metrics_tech,\n",
    "    multi_layer_metrics_enh,\n",
    "    # GRUs\n",
    "    baseline_gru_metrics,\n",
    "    technical_gru_metrics,\n",
    "    enhanced_gru_metrics,\n",
    "    # SVMs\n",
    "    baseline_svm_metrics,\n",
    "    technical_svm_metrics,\n",
    "    enhanced_svm_metrics,\n",
    "    # ARIMA\n",
    "    arima_metrics,\n",
    "]\n",
    "\n",
    "# Create a DataFrame for easy viewing and analysis\n",
    "all_metrics_df = pd.DataFrame(all_metrics_list).round(4)\n",
    "\n",
    "\n",
    "# --- 3. Print the Comprehensive Performance Table ---\n",
    "print(\"\\n📊 COMPREHENSIVE PERFORMANCE COMPARISON\")\n",
    "print(\"-\" * 75)\n",
    "# Use to_string() to ensure all columns are displayed without truncation\n",
    "print(all_metrics_df.to_string())\n",
    "print(\"-\" * 75)\n",
    "\n",
    "\n",
    "# --- 4. Determine and Announce the Best Model for Each Metric ---\n",
    "metrics_to_evaluate = {\n",
    "    \"RMSE\": \"min\",\n",
    "    \"MAE\": \"min\",\n",
    "    \"MAPE (%)\": \"min\",\n",
    "    \"MASE\": \"min\",\n",
    "    \"R-squared\": \"max\",\n",
    "    \"Directional_Accuracy\": \"max\",\n",
    "}\n",
    "\n",
    "print(\"\\n🏆 Best Model for Each Metric\")\n",
    "print(\"-\" * 75)\n",
    "for metric, method in metrics_to_evaluate.items():\n",
    "    if method == \"min\":\n",
    "        # For metrics where lower is better (e.g., RMSE, MAE)\n",
    "        winner_idx = all_metrics_df[metric].idxmin()\n",
    "    else:\n",
    "        # For metrics where higher is better (e.g., R-squared)\n",
    "        winner_idx = all_metrics_df[metric].idxmax()\n",
    "\n",
    "    winner_row = all_metrics_df.loc[winner_idx]\n",
    "    print(f\"{metric:<22}: {winner_row['Model']} (Score: {winner_row[metric]:.4f})\")\n",
    "print(\"-\" * 75)"
   ],
   "id": "7e42c5c76be8f928",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "# --- 5. Rank Models Based on Overall Performance ---\n",
    "print(\"\\n--- Ranking All Models ---\")\n",
    "ranking_df = all_metrics_df.copy()\n",
    "\n",
    "# Define which metrics to rank. True means \"lower is better\" (ascending).\n",
    "ranking_criteria = {\n",
    "    \"RMSE\": True,\n",
    "    \"MAE\": True,\n",
    "    \"MAPE (%)\": True,\n",
    "    \"MASE\": True,\n",
    "    \"R-squared\": False,  # False means \"higher is better\" (descending)\n",
    "    \"Directional_Accuracy\": False,\n",
    "}\n",
    "\n",
    "# Generate rank columns dynamically based on the criteria\n",
    "for metric, ascending_order in ranking_criteria.items():\n",
    "    ranking_df[f\"{metric}_Rank\"] = ranking_df[metric].rank(\n",
    "        method=\"min\", ascending=ascending_order\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Create a Final Score ---\n",
    "# Define which ranks contribute to the total score. You can easily change this.\n",
    "# For example, you might decide RMSE is more important than MAE.\n",
    "rank_components = [\"MASE_Rank\", \"MAPE (%)_Rank\", \"Directional_Accuracy_Rank\"]\n",
    "ranking_df[\"Total_Rank\"] = ranking_df[rank_components].sum(axis=1)\n",
    "\n",
    "# Sort by the final rank to find the best overall model\n",
    "final_ranking = ranking_df.sort_values(by=\"Total_Rank\", ascending=True)\n",
    "\n",
    "# Define the columns you want to see in the final table\n",
    "display_cols = [\n",
    "    \"Model\",\n",
    "    \"Total_Rank\",\n",
    "    \"RMSE\",\n",
    "    \"MAPE (%)\",\n",
    "    \"MASE\",\n",
    "    \"R-squared\",\n",
    "    \"Directional_Accuracy\",\n",
    "]\n",
    "\n",
    "# --- Display Final Ranking Table ---\n",
    "print(\"\\n🏆🏆🏆 OVERALL MODEL RANKING (Lower Total_Rank is Better) 🏆🏆🏆\")\n",
    "print(\"-\" * 115)\n",
    "print(final_ranking[display_cols].reset_index(drop=True).to_string())\n",
    "print(\"-\" * 115)\n",
    "\n",
    "# --- Announce the Winner ---\n",
    "winner = final_ranking.iloc[0]\n",
    "print(\n",
    "    f\"\\n🎉 The overall best performing model is: '{winner['Model']}' with a Total Rank score of {winner['Total_Rank']:.0f}.\"\n",
    ")"
   ],
   "id": "4c752b4e5702d6ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "# --- 6. Plot Final Comparison of All Major Models ---\n",
    "\n",
    "# Create a dictionary containing the data for the final plot.\n",
    "# Each entry needs the date series and the corresponding predicted values.\n",
    "plot_data = {\n",
    "    # The 'Actual' values from the longest available dataset (enhanced)\n",
    "    \"Actual\": {\"dates\": test_dates_enh, \"values\": y_test_enh_scaled},\n",
    "    # --- Best Models from Each Category for Clarity ---\n",
    "    # You can uncomment more models, but the plot may become cluttered.\n",
    "    # We'll start by plotting the best-ranked models.\n",
    "    # Best Overall Model (Example: replace with your actual winner)\n",
    "    \"Tuned Multi-Layer Hybrid LSTM\": {\n",
    "        \"dates\": test_dates_enh,\n",
    "        \"values\": multi_preds_scaled_enh,\n",
    "    },\n",
    "    # Best Technical Model (Example)\n",
    "    \"Tuned Multi-Layer Technical LSTM\": {\n",
    "        \"dates\": test_dates_tech,\n",
    "        \"values\": multi_preds_scaled_tech,\n",
    "    },\n",
    "    # Best Baseline Model (Example)\n",
    "    \"Tuned Baseline GRU\": {\"dates\": test_dates_base, \"values\": base_gru_preds_scaled},\n",
    "    # Classical Benchmark\n",
    "    \"ARIMA\": {\"dates\": test_dates_arima, \"values\": arima_predictions_np},\n",
    "}\n",
    "\n",
    "# --- Optional: Uncomment the block below to plot ALL models ---\n",
    "# plot_data = {\n",
    "#     \"Actual\": {\"dates\": test_dates_enh, \"values\": y_test_enh_scaled},\n",
    "#     \"Baseline LSTM\": {\"dates\": test_dates_base, \"values\": base_preds_scaled},\n",
    "#     \"Technical LSTM\": {\"dates\": test_dates_tech, \"values\": tech_preds_scaled},\n",
    "#     \"Hybrid LSTM\": {\"dates\": test_dates_enh, \"values\": enh_preds_scaled},\n",
    "#     \"Baseline Multi-Layer LSTM\": {\"dates\": test_dates_base, \"values\": multi_preds_scaled_base},\n",
    "#     \"Technical Multi-Layer LSTM\": {\"dates\": test_dates_tech, \"values\": multi_preds_scaled_tech},\n",
    "#     \"Hybrid Multi-Layer LSTM\": {\"dates\": test_dates_enh, \"values\": multi_preds_scaled_enh},\n",
    "#     \"Baseline GRU\": {\"dates\": test_dates_base, \"values\": base_gru_preds_scaled},\n",
    "#     \"Technical GRU\": {\"dates\": test_dates_tech, \"values\": tech_gru_preds_scaled},\n",
    "#     \"Hybrid GRU\": {\"dates\": test_dates_enh, \"values\": enh_gru_preds_scaled},\n",
    "#     \"Baseline SVM\": {\"dates\": test_dates_base, \"values\": base_svm_preds_scaled},\n",
    "#     \"Technical SVM\": {\"dates\": test_dates_tech, \"values\": tech_svm_preds_scaled},\n",
    "#     \"Hybrid SVM\": {\"dates\": test_dates_enh, \"values\": enh_svm_preds_scaled},\n",
    "#     \"ARIMA\": {\"dates\": test_dates_arima, \"values\": arima_predictions_np},\n",
    "# }\n",
    "\n",
    "# Call the plotting function from your utils file\n",
    "ut.plot_final_comparison(\n",
    "    plot_data,\n",
    "    cfg.STOCK_SYMBOL,\n",
    "    f\"{cfg.STOCK_SYMBOL} All Model Predictions Comparison (Daily Returns)\",\n",
    ")"
   ],
   "id": "2adcd3c995d0f2ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "try:\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"--- Total Notebook Runtime: {ut.format_runtime(total_time)} seconds ---\")\n",
    "except NameError:\n",
    "    print(\"⚠️ --- Timer could not be stopped because 'start_time' was not defined.\")"
   ],
   "id": "d00b3f4f8c64953b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9a586ecbd15619c3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
